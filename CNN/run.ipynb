{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "run.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGoAP5Dn3DwQ"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os, re, sys\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import gc\n",
        "import skimage.transform"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYucCZeH_dHH",
        "outputId": "1ed6727c-c339-45c8-dfda-d6046022c481"
      },
      "source": [
        "# test if GPUs are available\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUiMh4isCHnS",
        "outputId": "5dabbf13-81ad-4d6f-91fe-32029790ebc4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJQvxwJFDmYk"
      },
      "source": [
        "# set project root, maybe you need to firstly \n",
        "# add shortcut of CS 766 Project to drive.\n",
        "project_root = './drive/MyDrive/CS 766 Project/Project Coding and Data Files'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGJsefpJ-XjF"
      },
      "source": [
        "# class to initialize CNNs\n",
        "class OriginCNN(object):\n",
        "  \"\"\"docstring for OriginCNN\"\"\"\n",
        "  def __init__(self):\n",
        "    self.optimizer = 'adam'\n",
        "    # self.optimizer = tf.keras.optimizers.SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "    # self.loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    # will add more properties\n",
        "\n",
        "\n",
        "  def build(self):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), strides=(3,3), activation='relu', input_shape=(1000, 1000, 3)))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(32, (3, 3), strides=(3,3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(32, (3, 3), strides=(3,3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(32, activation='relu'))\n",
        "    model.add(layers.Dense(2))\n",
        "\n",
        "    model.summary()\n",
        "    model.compile(optimizer=self.optimizer,\n",
        "                loss=self.loss,\n",
        "                metrics=['accuracy'])\n",
        "    self.model = model\n",
        "\n",
        "\n",
        "  def train(self, train_images, train_labels, epochs):\n",
        "    self.history = self.model.fit(train_images, train_labels, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "  def train_on_batch(self, train_images, train_labels):\n",
        "    return self.model.train_on_batch(train_images, train_labels)\n",
        "\n",
        "  def predict(self, test_images):\n",
        "    return self.model.predict(test_images)\n",
        "\n",
        "\n",
        "  def evaluate(self, test_images, test_labels):\n",
        "    _, test_acc = self.model.evaluate(test_images, test_labels, verbose=2)\n",
        "    return test_images.shape[0], test_acc\n",
        "\n",
        "  def save_model(self, filepath):\n",
        "    self.model.save(filepath)\n",
        "\n",
        "  def load_model(self, filepath):\n",
        "    self.model = tf.keras.models.load_model(filepath)\n",
        "\n",
        "  def extract_feature(self, images):\n",
        "    extract = models.Model(self.model.inputs, self.model.layers[-3].output)\n",
        "    return extract.predict(images)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSiCn4VzdaV8"
      },
      "source": [
        "from tensorflow.keras.applications import ResNet50, InceptionV3, VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "class Res50(object):\n",
        "  \"\"\"docstring for OriginCNN\"\"\"\n",
        "  def __init__(self):\n",
        "    self.optimizer = 'adam'\n",
        "    # self.optimizer = tf.keras.optimizers.SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "    # self.loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    # will add more properties\n",
        "\n",
        "\n",
        "  def build(self):\n",
        "    base_model = InceptionV3(\n",
        "      include_top=False,\n",
        "      weights=\"imagenet\",\n",
        "      input_shape=(224, 224, 3)\n",
        "    )\n",
        "\n",
        "    # add a global spatial average pooling layer\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    # let's add a fully-connected layer\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    # and a logistic layer -- let's say we have n classes\n",
        "    predictions = Dense(2)(x)\n",
        "\n",
        "    # this is the model we will train\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "\n",
        "    model.summary()\n",
        "    model.compile(optimizer=self.optimizer,\n",
        "                loss=self.loss,\n",
        "                metrics=['accuracy'])\n",
        "    self.model = model\n",
        "\n",
        "\n",
        "  def train(self, train_images, train_labels, epochs):\n",
        "    self.history = self.model.fit(train_images, train_labels, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "  def train_on_batch(self, train_images, train_labels):\n",
        "    return self.model.train_on_batch(train_images, train_labels)\n",
        "\n",
        "  def predict(self, test_images):\n",
        "    return self.model.predict(test_images)\n",
        "\n",
        "\n",
        "  def evaluate(self, test_images, test_labels):\n",
        "    _, test_acc = self.model.evaluate(test_images, test_labels, verbose=2)\n",
        "    return test_images.shape[0], test_acc\n",
        "\n",
        "  def save_model(self, filepath):\n",
        "    self.model.save(filepath)\n",
        "\n",
        "  def load_model(self, filepath):\n",
        "    self.model = tf.keras.models.load_model(filepath)\n",
        "\n",
        "  def extract_feature(self, images):\n",
        "    extract = models.Model(self.model.inputs, self.model.layers[-2].output)\n",
        "    return extract.predict(images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3suc98v-bRj"
      },
      "source": [
        "class DR_resized(object):\n",
        "  \"\"\"docstring for DR_resized\"\"\"\n",
        "  def __init__(self, is_training, batch_id, batch_size, train_val_split_rate, size=None):\n",
        "    self.batch_size = batch_size\n",
        "    self.train_val_split_rate = train_val_split_rate\n",
        "    if(is_training):\n",
        "      # load images\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Stratified_Random_Sampling_Datasets\", \"Processed_Xtrain_Batch%d.npy\" % batch_id))\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Even_Class_Distribution_Datasets\", \"Processed_Xtrain_Batch%d_even.npy\" % batch_id))\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Color_Even_Class_Distribution_Datasets\", \"Color_Processed_Xtrain_Batch%d_even.npy\" % batch_id))\n",
        "      all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"04_Only_Color_Even_Class_Distribution_Datasets\", \"04_Only_Color_Processed_Xtrain_Batch%d_even.npy\" % batch_id))\n",
        "      \n",
        "      # add a dimension for channels if gray scale images\n",
        "      if (len(all_images[0].shape) == 2):\n",
        "        all_images = np.expand_dims(all_images, axis=-1)\n",
        "\n",
        "      # resize\n",
        "      # gray scale\n",
        "      if(size):\n",
        "        if (len(all_images[0].shape) == 2):\n",
        "          all_images_resize = np.zeros((all_images.shape[0], size[0], size[1], 1));\n",
        "          for i in range(all_images.shape[0]):\n",
        "            all_images_resize[i] = skimage.transform.resize(all_images[i].astype('float64'), (size[0], size[1]));\n",
        "        # color image\n",
        "        else:\n",
        "          all_images_resize = np.zeros((all_images.shape[0], size[0], size[1], 3));\n",
        "          for i in range(all_images.shape[0]):\n",
        "            all_images_resize[i] = skimage.transform.resize(all_images[i].astype('float64'), (size[0], size[1]));\n",
        "        all_images = all_images_resize\n",
        "\n",
        "\n",
        "      # load labels\n",
        "      # all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Stratified Random Sampling Datasets\", \"Ytrain\", \"Ytrain_Batch%d.npy\" % batch_id), allow_pickle=True)\n",
        "      # all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Even Class Distribution Datasets\", \"Ytrain\", \"Ytrain_Batch%d_even.npy\" % batch_id), allow_pickle=True)\n",
        "      all_labels = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"04_Only_Color_Even_Class_Distribution_Datasets\", \"04_Only_Ytrain_Batch%d_even.npy\" % batch_id), allow_pickle=True)\n",
        "      all_labels = np.array([item[1] for item in all_labels])\n",
        "      \n",
        "      # one hot\n",
        "      # all_labels_one_hot = np.zeros((all_labels.size, 5))\n",
        "      # all_labels_one_hot[np.arange(all_labels.size),all_labels] = 1\n",
        "\n",
        "      # without one hot\n",
        "      all_labels_one_hot = np.expand_dims(all_labels, axis=-1)\n",
        "\n",
        "      # shuffle\n",
        "      indices = np.arange(all_images.shape[0])\n",
        "      np.random.shuffle(indices)\n",
        "      all_images = all_images[indices]\n",
        "      all_labels_one_hot = all_labels_one_hot[indices]\n",
        "\n",
        "      self.train_images = all_images\n",
        "      self.train_labels = all_labels_one_hot\n",
        "    \n",
        "    else:\n",
        "      # load images\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Stratified_Random_Sampling_Datasets\", \"Processed_Xtest_Batch%d.npy\") % batch_id)\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Even_Class_Distribution_Datasets\", \"Processed_Xest_Batch%d_even.npy\") % batch_id)\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Color_Even_Class_Distribution_Datasets\", \"Color_Processed_Xest_Batch%d_even.npy\") % batch_id)\n",
        "      all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"04_Only_Color_Even_Class_Distribution_Datasets\", \"04_Only_Color_Processed_Xest_Batch%d_even.npy\" % batch_id))\n",
        "      \n",
        "      # add a dimension for channels if gray scale images\n",
        "      if (len(all_images[0].shape) == 2):\n",
        "        all_images = np.expand_dims(all_images, axis=-1)\n",
        "\n",
        "      # resize\n",
        "      if(size):\n",
        "        # gray scale\n",
        "        if (len(all_images[0].shape) == 2):\n",
        "          all_images_resize = np.zeros((all_images.shape[0], size[0], size[1], 1));\n",
        "          for i in range(all_images.shape[0]):\n",
        "            all_images_resize[i] = skimage.transform.resize(all_images[i].astype('float64'), (size[0], size[1]));\n",
        "        # color image\n",
        "        else:\n",
        "          all_images_resize = np.zeros((all_images.shape[0], size[0], size[1], 3));\n",
        "          for i in range(all_images.shape[0]):\n",
        "            all_images_resize[i] = skimage.transform.resize(all_images[i].astype('float64'), (size[0], size[1]));\n",
        "        all_images = all_images_resize\n",
        "\n",
        "\n",
        "      # load labels\n",
        "      # all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Stratified Random Sampling Datasets\", \"Ytest\", \"Ytest_Batch%d.npy\" % batch_id), allow_pickle=True)\n",
        "      # all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Even Class Distribution Datasets\", \"Ytest\", \"Yest_Batch%d_even.npy\" % batch_id), allow_pickle=True)\n",
        "      all_labels = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"04_Only_Color_Even_Class_Distribution_Datasets\", \"04_Only_Yest_Batch%d_even.npy\" % batch_id), allow_pickle=True)\n",
        "      all_labels = np.array([item[1] for item in all_labels])\n",
        "\n",
        "      # one hot\n",
        "      # all_labels_one_hot = np.zeros((all_labels.size, 5))\n",
        "      # all_labels_one_hot[np.arange(all_labels.size),all_labels] = 1\n",
        "\n",
        "      # without one hot\n",
        "      all_labels_one_hot = np.expand_dims(all_labels, axis=-1)\n",
        "      \n",
        "      self.test_images = all_images\n",
        "      self.test_labels = all_labels_one_hot\n",
        "  \n",
        "  def clear(self):\n",
        "    self.train_images = None\n",
        "    self.validate_images = None\n",
        "    self.test_images = None\n",
        "    self.train_labels = None\n",
        "    self.validate_labels = None\n",
        "    self.test_labels = None\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L57sy6Z02c-"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class Cifar(object):\n",
        "  \"\"\"docstring for DR_resized\"\"\"\n",
        "  def __init__(self, is_training, batch_id, batch_size, train_val_split_rate):\n",
        "    self.batch_size = batch_size\n",
        "    self.train_val_split_rate = train_val_split_rate\n",
        "\n",
        "    if(is_training):\n",
        "      # load images\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Stratified_Random_Sampling_Datasets\", \"Processed_Xtrain_Batch%d.npy\" % batch_id))\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Even_Class_Distribution_Datasets\", \"Processed_Xtrain_Batch%d_even.npy\" % batch_id))\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Color_Even_Class_Distribution_Datasets\", \"Color_Processed_Xtrain_Batch%d_even.npy\" % batch_id))\n",
        "      \n",
        "      # add a dimension for channels if gray scale images\n",
        "      # if (len(all_images[0].shape) == 2):\n",
        "        # all_images = np.expand_dims(all_images, axis=-1)\n",
        "\n",
        "      # load labels\n",
        "      # all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Stratified Random Sampling Datasets\", \"Ytrain\", \"Ytrain_Batch%d.npy\" % batch_id), allow_pickle=True)\n",
        "      # all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Even Class Distribution Datasets\", \"Ytrain\", \"Ytrain_Batch%d_even.npy\" % batch_id), allow_pickle=True)\n",
        "      # all_labels = np.array([item[1] for item in all_labels])\n",
        "\n",
        "      (train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "      train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "      all_images = train_images\n",
        "      all_labels = train_labels\n",
        "      \n",
        "      # one hot\n",
        "      # all_labels_one_hot = np.zeros((all_labels.size, 10))\n",
        "      # all_labels_one_hot[np.arange(all_labels.size),all_labels] = 1\n",
        "\n",
        "      # without one hot\n",
        "      all_labels_one_hot = np.expand_dims(all_labels, axis=-1)\n",
        "\n",
        "      # shuffle\n",
        "      indices = np.arange(all_images.shape[0])\n",
        "      np.random.shuffle(indices)\n",
        "      all_images = all_images[indices]\n",
        "      all_labels_one_hot = all_labels_one_hot[indices]\n",
        "\n",
        "      self.train_images = all_images\n",
        "      self.train_labels = all_labels_one_hot\n",
        "    \n",
        "    else:\n",
        "      # load images\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Stratified_Random_Sampling_Datasets\", \"Processed_Xtest_Batch%d.npy\") % batch_id)\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Even_Class_Distribution_Datasets\", \"Processed_Xest_Batch%d_even.npy\") % batch_id)\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Color_Even_Class_Distribution_Datasets\", \"Color_Processed_Xest_Batch%d_even.npy\") % batch_id)\n",
        "      \n",
        "      # add a dimension for channels if gray scale images\n",
        "      # if (len(all_images[0].shape) == 2):\n",
        "      #   all_images = np.expand_dims(all_images, axis=-1)\n",
        "\n",
        "      # load labels\n",
        "      # all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Stratified Random Sampling Datasets\", \"Ytest\", \"Ytest_Batch%d.npy\" % batch_id), allow_pickle=True)\n",
        "      # all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Even Class Distribution Datasets\", \"Ytest\", \"Yest_Batch%d_even.npy\" % batch_id), allow_pickle=True)\n",
        "      # all_labels = np.array([item[1] for item in all_labels])\n",
        "\n",
        "      (train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "      train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "      all_images = test_images\n",
        "      all_labels = test_labels\n",
        "\n",
        "      # one hot\n",
        "      all_labels_one_hot = np.zeros((all_labels.size, 10))\n",
        "      all_labels_one_hot[np.arange(all_labels.size),all_labels] = 1\n",
        "\n",
        "      # without one hot\n",
        "      # all_labels = np.expand_dims(all_labels, axis=-1)\n",
        "      \n",
        "      self.test_images = all_images\n",
        "      self.test_labels = all_labels_one_hot\n",
        "  \n",
        "  def clear(self):\n",
        "    self.train_images = None\n",
        "    self.validate_images = None\n",
        "    self.test_images = None\n",
        "    self.train_labels = None\n",
        "    self.validate_labels = None\n",
        "    self.test_labels = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOADsxqM3DwR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "572874cc-79c3-4adc-9407-dff657045630"
      },
      "source": [
        "# initialize CNN\n",
        "myModel = OriginCNN()\n",
        "# myModel = Res50()\n",
        "myModel.build()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 333, 333, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 166, 166, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 55, 55, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 27, 27, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 9, 9, 32)          9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 32)                16416     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 35,874\n",
            "Trainable params: 35,874\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrJnfPqP3DwS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c5814bc-ddc7-4f80-d86c-974c9b25f8b9"
      },
      "source": [
        "# training process\n",
        "file_num = 9\n",
        "epoch_num = 30\n",
        "for epoch in range(epoch_num):\n",
        "  print(\"\\n\\nstart epoch %d\" % epoch)\n",
        "  for i in range(file_num):\n",
        "    # load data\n",
        "    # myData = DR_resized(True, i, 32, 0.1, (224, 224))\n",
        "    myData = DR_resized(True, i, 32, 0.1)\n",
        "    print(\"data batch %d loaded\" % i)\n",
        "\n",
        "    myModel.train(myData.train_images, myData.train_labels, epochs=1)\n",
        "    myData.clear()\n",
        "    gc.collect()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "start epoch 0\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 2s 328ms/step - loss: 0.6994 - accuracy: 0.4297 - val_loss: 0.6639 - val_accuracy: 0.6923\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 1s 265ms/step - loss: 0.7068 - accuracy: 0.4234 - val_loss: 0.6971 - val_accuracy: 0.5385\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 1s 276ms/step - loss: 0.6922 - accuracy: 0.5766 - val_loss: 0.7144 - val_accuracy: 0.2308\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 1s 258ms/step - loss: 0.6925 - accuracy: 0.5315 - val_loss: 0.6779 - val_accuracy: 0.6923\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 0.6939 - accuracy: 0.5225 - val_loss: 0.6902 - val_accuracy: 0.5385\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 1s 260ms/step - loss: 0.6899 - accuracy: 0.5946 - val_loss: 0.6983 - val_accuracy: 0.4615\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 1s 250ms/step - loss: 0.6891 - accuracy: 0.5766 - val_loss: 0.6969 - val_accuracy: 0.3846\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 1s 260ms/step - loss: 0.6887 - accuracy: 0.5856 - val_loss: 0.6933 - val_accuracy: 0.4615\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 0.6950 - accuracy: 0.4685 - val_loss: 0.7113 - val_accuracy: 0.4615\n",
            "\n",
            "\n",
            "start epoch 1\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 1s 283ms/step - loss: 0.6880 - accuracy: 0.5315 - val_loss: 0.6651 - val_accuracy: 0.6154\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 0.6952 - accuracy: 0.4775 - val_loss: 0.6910 - val_accuracy: 0.5385\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 1s 261ms/step - loss: 0.6908 - accuracy: 0.5405 - val_loss: 0.6786 - val_accuracy: 0.7692\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 2s 390ms/step - loss: 0.6888 - accuracy: 0.5676 - val_loss: 0.6896 - val_accuracy: 0.4615\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 1s 266ms/step - loss: 0.6960 - accuracy: 0.4955 - val_loss: 0.7017 - val_accuracy: 0.4615\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 1s 263ms/step - loss: 0.6877 - accuracy: 0.5315 - val_loss: 0.6947 - val_accuracy: 0.4615\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 1s 256ms/step - loss: 0.6893 - accuracy: 0.5856 - val_loss: 0.6654 - val_accuracy: 0.7692\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 1s 246ms/step - loss: 0.6862 - accuracy: 0.5405 - val_loss: 0.7061 - val_accuracy: 0.3846\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 1s 288ms/step - loss: 0.6852 - accuracy: 0.5676 - val_loss: 0.7105 - val_accuracy: 0.3077\n",
            "\n",
            "\n",
            "start epoch 2\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 0.6837 - accuracy: 0.5586 - val_loss: 0.6556 - val_accuracy: 0.8462\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 0.6822 - accuracy: 0.5495 - val_loss: 0.7566 - val_accuracy: 0.3846\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 0.6858 - accuracy: 0.5225 - val_loss: 0.6768 - val_accuracy: 0.4615\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 1s 265ms/step - loss: 0.6802 - accuracy: 0.5405 - val_loss: 0.6502 - val_accuracy: 0.7692\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 0.6857 - accuracy: 0.5495 - val_loss: 0.7030 - val_accuracy: 0.3846\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 1s 250ms/step - loss: 0.6852 - accuracy: 0.5315 - val_loss: 0.6285 - val_accuracy: 0.9231\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 1s 237ms/step - loss: 0.6748 - accuracy: 0.6757 - val_loss: 0.6719 - val_accuracy: 0.6154\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 0.6717 - accuracy: 0.6396 - val_loss: 0.6352 - val_accuracy: 0.6923\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 1s 236ms/step - loss: 0.6886 - accuracy: 0.5766 - val_loss: 0.6583 - val_accuracy: 0.6923\n",
            "\n",
            "\n",
            "start epoch 3\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 1s 230ms/step - loss: 0.6532 - accuracy: 0.6757 - val_loss: 0.8943 - val_accuracy: 0.0769\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 1s 230ms/step - loss: 0.6850 - accuracy: 0.5586 - val_loss: 0.7942 - val_accuracy: 0.3077\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 0.6759 - accuracy: 0.5405 - val_loss: 0.6594 - val_accuracy: 0.6923\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 1s 249ms/step - loss: 0.6657 - accuracy: 0.6396 - val_loss: 0.7725 - val_accuracy: 0.2308\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 1s 246ms/step - loss: 0.6887 - accuracy: 0.5676 - val_loss: 0.6892 - val_accuracy: 0.6923\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 1s 238ms/step - loss: 0.6543 - accuracy: 0.6937 - val_loss: 0.6477 - val_accuracy: 0.6923\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 0.6562 - accuracy: 0.6486 - val_loss: 0.7171 - val_accuracy: 0.4615\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 0.6759 - accuracy: 0.5225 - val_loss: 0.5930 - val_accuracy: 0.8462\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 1s 284ms/step - loss: 0.6750 - accuracy: 0.6036 - val_loss: 0.7299 - val_accuracy: 0.5385\n",
            "\n",
            "\n",
            "start epoch 4\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 0.6566 - accuracy: 0.6396 - val_loss: 0.6104 - val_accuracy: 0.9231\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.7150 - accuracy: 0.5676 - val_loss: 0.6860 - val_accuracy: 0.6154\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 0.6443 - accuracy: 0.6396 - val_loss: 0.6758 - val_accuracy: 0.6154\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 1s 271ms/step - loss: 0.6612 - accuracy: 0.6396 - val_loss: 0.6280 - val_accuracy: 0.7692\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 0.6834 - accuracy: 0.5405 - val_loss: 0.6749 - val_accuracy: 0.6154\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 0.6555 - accuracy: 0.6937 - val_loss: 0.7345 - val_accuracy: 0.3077\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 1s 234ms/step - loss: 0.6605 - accuracy: 0.6216 - val_loss: 0.6803 - val_accuracy: 0.4615\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.6630 - accuracy: 0.6216 - val_loss: 0.7421 - val_accuracy: 0.5385\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 1s 234ms/step - loss: 0.6527 - accuracy: 0.5946 - val_loss: 0.7109 - val_accuracy: 0.5385\n",
            "\n",
            "\n",
            "start epoch 5\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 0.6535 - accuracy: 0.6396 - val_loss: 0.6479 - val_accuracy: 0.6923\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 0.6640 - accuracy: 0.5586 - val_loss: 0.6689 - val_accuracy: 0.6154\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.6174 - accuracy: 0.6577 - val_loss: 0.6332 - val_accuracy: 0.6923\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 0.6284 - accuracy: 0.6757 - val_loss: 0.7319 - val_accuracy: 0.3846\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 1s 260ms/step - loss: 0.6882 - accuracy: 0.5946 - val_loss: 0.6682 - val_accuracy: 0.5385\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 0.6111 - accuracy: 0.6757 - val_loss: 0.5905 - val_accuracy: 0.7692\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 0.6635 - accuracy: 0.5495 - val_loss: 0.5825 - val_accuracy: 0.6923\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 0.6337 - accuracy: 0.6216 - val_loss: 0.6702 - val_accuracy: 0.6923\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 1s 248ms/step - loss: 0.6282 - accuracy: 0.6757 - val_loss: 0.6981 - val_accuracy: 0.5385\n",
            "\n",
            "\n",
            "start epoch 6\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 1s 229ms/step - loss: 0.6350 - accuracy: 0.6396 - val_loss: 0.5573 - val_accuracy: 0.7692\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 0.6413 - accuracy: 0.6486 - val_loss: 0.7290 - val_accuracy: 0.5385\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 1s 263ms/step - loss: 0.6318 - accuracy: 0.6306 - val_loss: 0.7206 - val_accuracy: 0.3846\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 0.6570 - accuracy: 0.5946 - val_loss: 0.5427 - val_accuracy: 0.6923\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 1s 230ms/step - loss: 0.6883 - accuracy: 0.5495 - val_loss: 0.6020 - val_accuracy: 0.7692\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 0.6410 - accuracy: 0.7027 - val_loss: 0.6875 - val_accuracy: 0.6154\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 0.6521 - accuracy: 0.6216 - val_loss: 0.6758 - val_accuracy: 0.7692\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 1s 261ms/step - loss: 0.6565 - accuracy: 0.6847 - val_loss: 0.6458 - val_accuracy: 0.6923\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 1s 234ms/step - loss: 0.6506 - accuracy: 0.6667 - val_loss: 0.6724 - val_accuracy: 0.3846\n",
            "\n",
            "\n",
            "start epoch 7\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 1s 276ms/step - loss: 0.6495 - accuracy: 0.6126 - val_loss: 0.6021 - val_accuracy: 0.6923\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 0.6497 - accuracy: 0.6577 - val_loss: 0.5996 - val_accuracy: 0.5385\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 1s 262ms/step - loss: 0.6147 - accuracy: 0.6396 - val_loss: 0.5834 - val_accuracy: 0.6923\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 0.6066 - accuracy: 0.6667 - val_loss: 0.6545 - val_accuracy: 0.6154\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 1s 238ms/step - loss: 0.7083 - accuracy: 0.5676 - val_loss: 0.6363 - val_accuracy: 0.6923\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 0.6100 - accuracy: 0.6757 - val_loss: 0.6443 - val_accuracy: 0.6154\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.6353 - accuracy: 0.6847 - val_loss: 0.6049 - val_accuracy: 0.7692\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 0.6549 - accuracy: 0.5586 - val_loss: 0.6004 - val_accuracy: 0.6154\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 0.6099 - accuracy: 0.6757 - val_loss: 0.7901 - val_accuracy: 0.2308\n",
            "\n",
            "\n",
            "start epoch 8\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 1s 241ms/step - loss: 0.6187 - accuracy: 0.6757 - val_loss: 0.7113 - val_accuracy: 0.6154\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 0.6260 - accuracy: 0.6486 - val_loss: 0.6174 - val_accuracy: 0.8462\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 1s 241ms/step - loss: 0.5944 - accuracy: 0.6126 - val_loss: 0.6306 - val_accuracy: 0.6923\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 0.6012 - accuracy: 0.6757 - val_loss: 0.6651 - val_accuracy: 0.6154\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 1s 248ms/step - loss: 0.6730 - accuracy: 0.5766 - val_loss: 0.5409 - val_accuracy: 0.8462\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 1s 234ms/step - loss: 0.6059 - accuracy: 0.6667 - val_loss: 0.6155 - val_accuracy: 0.6923\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 1s 243ms/step - loss: 0.6109 - accuracy: 0.6577 - val_loss: 0.7496 - val_accuracy: 0.4615\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 1s 264ms/step - loss: 0.6315 - accuracy: 0.6306 - val_loss: 0.6509 - val_accuracy: 0.3846\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 1s 246ms/step - loss: 0.6179 - accuracy: 0.6396 - val_loss: 0.6036 - val_accuracy: 0.8462\n",
            "\n",
            "\n",
            "start epoch 9\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 1s 234ms/step - loss: 0.6169 - accuracy: 0.6937 - val_loss: 0.5604 - val_accuracy: 0.6923\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.6277 - accuracy: 0.6577 - val_loss: 0.5749 - val_accuracy: 0.6923\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 1s 233ms/step - loss: 0.5602 - accuracy: 0.7027 - val_loss: 0.5468 - val_accuracy: 0.7692\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 0.5901 - accuracy: 0.6847 - val_loss: 0.5446 - val_accuracy: 0.6154\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 0.6103 - accuracy: 0.6757 - val_loss: 1.0148 - val_accuracy: 0.3846\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 1s 237ms/step - loss: 0.5376 - accuracy: 0.7207 - val_loss: 0.5026 - val_accuracy: 0.7692\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 0.5870 - accuracy: 0.6847 - val_loss: 0.5277 - val_accuracy: 0.6923\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 1s 232ms/step - loss: 0.6508 - accuracy: 0.6216 - val_loss: 0.5106 - val_accuracy: 0.7692\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 0.6537 - accuracy: 0.6396 - val_loss: 0.6357 - val_accuracy: 0.6923\n",
            "\n",
            "\n",
            "start epoch 10\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.6005 - accuracy: 0.6937 - val_loss: 0.6542 - val_accuracy: 0.5385\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 1s 231ms/step - loss: 0.6221 - accuracy: 0.6757 - val_loss: 0.5545 - val_accuracy: 0.9231\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 0.5951 - accuracy: 0.6667 - val_loss: 0.5238 - val_accuracy: 0.8462\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 1s 231ms/step - loss: 0.6307 - accuracy: 0.5946 - val_loss: 0.4599 - val_accuracy: 0.8462\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 1s 250ms/step - loss: 0.6314 - accuracy: 0.6126 - val_loss: 0.7014 - val_accuracy: 0.5385\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 0.5461 - accuracy: 0.7477 - val_loss: 0.6166 - val_accuracy: 0.5385\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 0.5931 - accuracy: 0.7117 - val_loss: 0.5265 - val_accuracy: 0.7692\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 0.6110 - accuracy: 0.6577 - val_loss: 0.5751 - val_accuracy: 0.5385\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 1s 243ms/step - loss: 0.5497 - accuracy: 0.7658 - val_loss: 0.6143 - val_accuracy: 0.6154\n",
            "\n",
            "\n",
            "start epoch 11\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 1s 242ms/step - loss: 0.6251 - accuracy: 0.6847 - val_loss: 0.5778 - val_accuracy: 0.6923\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 0.5851 - accuracy: 0.6937 - val_loss: 0.7421 - val_accuracy: 0.4615\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 0.5650 - accuracy: 0.6847 - val_loss: 0.4987 - val_accuracy: 0.7692\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 1s 243ms/step - loss: 0.5508 - accuracy: 0.7297 - val_loss: 0.7596 - val_accuracy: 0.5385\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 1s 230ms/step - loss: 0.6520 - accuracy: 0.6216 - val_loss: 0.5885 - val_accuracy: 0.5385\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 1s 258ms/step - loss: 0.5187 - accuracy: 0.7838 - val_loss: 0.6343 - val_accuracy: 0.6923\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 0.5952 - accuracy: 0.6396 - val_loss: 0.5081 - val_accuracy: 0.6923\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 1s 249ms/step - loss: 0.6166 - accuracy: 0.6757 - val_loss: 0.4997 - val_accuracy: 0.8462\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 0.5576 - accuracy: 0.7117 - val_loss: 0.6069 - val_accuracy: 0.6154\n",
            "\n",
            "\n",
            "start epoch 12\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 1s 238ms/step - loss: 0.6155 - accuracy: 0.6306 - val_loss: 0.4766 - val_accuracy: 0.6923\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 1s 248ms/step - loss: 0.6307 - accuracy: 0.6306 - val_loss: 0.5737 - val_accuracy: 0.7692\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 1s 234ms/step - loss: 0.5445 - accuracy: 0.6937 - val_loss: 0.6087 - val_accuracy: 0.6923\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 0.5934 - accuracy: 0.6577 - val_loss: 0.5372 - val_accuracy: 0.6923\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 1s 246ms/step - loss: 0.6593 - accuracy: 0.6216 - val_loss: 0.5095 - val_accuracy: 0.9231\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 0.5369 - accuracy: 0.7568 - val_loss: 0.5093 - val_accuracy: 0.8462\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 0.5459 - accuracy: 0.7477 - val_loss: 0.5573 - val_accuracy: 0.7692\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 1s 245ms/step - loss: 0.5534 - accuracy: 0.7027 - val_loss: 0.7845 - val_accuracy: 0.4615\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 1s 246ms/step - loss: 0.5508 - accuracy: 0.7387 - val_loss: 0.5488 - val_accuracy: 0.6154\n",
            "\n",
            "\n",
            "start epoch 13\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 1s 234ms/step - loss: 0.5524 - accuracy: 0.7207 - val_loss: 0.6361 - val_accuracy: 0.6154\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 1s 236ms/step - loss: 0.5695 - accuracy: 0.6937 - val_loss: 0.8485 - val_accuracy: 0.5385\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 1s 238ms/step - loss: 0.5298 - accuracy: 0.7207 - val_loss: 0.4656 - val_accuracy: 0.6923\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 1s 260ms/step - loss: 0.6110 - accuracy: 0.6667 - val_loss: 0.5268 - val_accuracy: 0.7692\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 1s 258ms/step - loss: 0.6699 - accuracy: 0.5676 - val_loss: 0.5924 - val_accuracy: 0.6923\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 0.5525 - accuracy: 0.7117 - val_loss: 0.4891 - val_accuracy: 0.6923\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 0.5905 - accuracy: 0.7117 - val_loss: 0.5899 - val_accuracy: 0.6923\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 1s 248ms/step - loss: 0.6052 - accuracy: 0.6486 - val_loss: 0.5451 - val_accuracy: 0.6923\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 0.5615 - accuracy: 0.7658 - val_loss: 0.6832 - val_accuracy: 0.5385\n",
            "\n",
            "\n",
            "start epoch 14\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 1s 231ms/step - loss: 0.5704 - accuracy: 0.7387 - val_loss: 0.5297 - val_accuracy: 0.7692\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 0.5981 - accuracy: 0.7027 - val_loss: 0.6931 - val_accuracy: 0.5385\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 1s 244ms/step - loss: 0.5299 - accuracy: 0.7387 - val_loss: 0.5291 - val_accuracy: 0.7692\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 1s 261ms/step - loss: 0.5702 - accuracy: 0.6757 - val_loss: 0.5168 - val_accuracy: 0.8462\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 0.6039 - accuracy: 0.6486 - val_loss: 0.9322 - val_accuracy: 0.4615\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 1s 246ms/step - loss: 0.5077 - accuracy: 0.7838 - val_loss: 0.5945 - val_accuracy: 0.6154\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 0.5491 - accuracy: 0.7297 - val_loss: 0.6395 - val_accuracy: 0.6923\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 1s 243ms/step - loss: 0.5754 - accuracy: 0.7027 - val_loss: 0.6748 - val_accuracy: 0.7692\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 1s 245ms/step - loss: 0.5496 - accuracy: 0.6937 - val_loss: 0.4958 - val_accuracy: 0.7692\n",
            "\n",
            "\n",
            "start epoch 15\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 1s 229ms/step - loss: 0.5357 - accuracy: 0.7387 - val_loss: 0.6385 - val_accuracy: 0.6154\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.5943 - accuracy: 0.6937 - val_loss: 0.6758 - val_accuracy: 0.6154\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 1s 231ms/step - loss: 0.5139 - accuracy: 0.6847 - val_loss: 0.5633 - val_accuracy: 0.7692\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 1s 234ms/step - loss: 0.5795 - accuracy: 0.6937 - val_loss: 0.4309 - val_accuracy: 1.0000\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 0.5812 - accuracy: 0.6757 - val_loss: 0.6063 - val_accuracy: 0.6923\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 1s 230ms/step - loss: 0.4909 - accuracy: 0.7838 - val_loss: 0.6365 - val_accuracy: 0.6154\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 1s 270ms/step - loss: 0.5407 - accuracy: 0.7027 - val_loss: 0.5687 - val_accuracy: 0.7692\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 1s 231ms/step - loss: 0.5821 - accuracy: 0.6757 - val_loss: 0.4554 - val_accuracy: 0.8462\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 1s 242ms/step - loss: 0.5333 - accuracy: 0.7387 - val_loss: 0.4260 - val_accuracy: 0.8462\n",
            "\n",
            "\n",
            "start epoch 16\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 1s 237ms/step - loss: 0.5228 - accuracy: 0.7117 - val_loss: 0.5862 - val_accuracy: 0.7692\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.5755 - accuracy: 0.7207 - val_loss: 0.6407 - val_accuracy: 0.6154\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 1s 232ms/step - loss: 0.5067 - accuracy: 0.7207 - val_loss: 0.4510 - val_accuracy: 0.6923\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.5500 - accuracy: 0.7027 - val_loss: 0.5718 - val_accuracy: 0.6923\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 1s 250ms/step - loss: 0.6106 - accuracy: 0.6396 - val_loss: 0.5286 - val_accuracy: 0.7692\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 0.4895 - accuracy: 0.7928 - val_loss: 0.4902 - val_accuracy: 0.8462\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.5583 - accuracy: 0.7117 - val_loss: 0.3594 - val_accuracy: 0.9231\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 0.5415 - accuracy: 0.7297 - val_loss: 0.5113 - val_accuracy: 0.7692\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 1s 261ms/step - loss: 0.4877 - accuracy: 0.7387 - val_loss: 0.6154 - val_accuracy: 0.6154\n",
            "\n",
            "\n",
            "start epoch 17\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 0.5221 - accuracy: 0.7658 - val_loss: 0.5378 - val_accuracy: 0.6923\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 1s 259ms/step - loss: 0.5711 - accuracy: 0.7027 - val_loss: 0.6723 - val_accuracy: 0.7692\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 1s 264ms/step - loss: 0.4947 - accuracy: 0.7387 - val_loss: 0.4554 - val_accuracy: 0.7692\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 1s 248ms/step - loss: 0.5609 - accuracy: 0.7207 - val_loss: 0.5846 - val_accuracy: 0.6923\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 1s 231ms/step - loss: 0.5990 - accuracy: 0.7387 - val_loss: 0.9499 - val_accuracy: 0.5385\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 0.5198 - accuracy: 0.7838 - val_loss: 0.3403 - val_accuracy: 0.9231\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 0.4926 - accuracy: 0.7838 - val_loss: 0.5733 - val_accuracy: 0.5385\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 0.5809 - accuracy: 0.7027 - val_loss: 0.6899 - val_accuracy: 0.6154\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 0.5603 - accuracy: 0.7207 - val_loss: 0.4428 - val_accuracy: 0.7692\n",
            "\n",
            "\n",
            "start epoch 18\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 1s 248ms/step - loss: 0.5706 - accuracy: 0.7207 - val_loss: 0.4649 - val_accuracy: 0.7692\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 1s 234ms/step - loss: 0.5640 - accuracy: 0.6937 - val_loss: 0.5152 - val_accuracy: 0.7692\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 1s 249ms/step - loss: 0.4819 - accuracy: 0.7658 - val_loss: 0.3761 - val_accuracy: 0.8462\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 1s 231ms/step - loss: 0.5498 - accuracy: 0.7117 - val_loss: 0.4758 - val_accuracy: 0.7692\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 1s 249ms/step - loss: 0.5748 - accuracy: 0.7027 - val_loss: 0.6394 - val_accuracy: 0.7692\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 0.4722 - accuracy: 0.7568 - val_loss: 0.5259 - val_accuracy: 0.6923\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.4862 - accuracy: 0.7658 - val_loss: 0.4378 - val_accuracy: 0.7692\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 1s 231ms/step - loss: 0.5393 - accuracy: 0.7207 - val_loss: 0.5722 - val_accuracy: 0.6923\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 1s 242ms/step - loss: 0.4856 - accuracy: 0.7748 - val_loss: 0.5361 - val_accuracy: 0.6923\n",
            "\n",
            "\n",
            "start epoch 19\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 0.4915 - accuracy: 0.7387 - val_loss: 0.5422 - val_accuracy: 0.6923\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 1s 237ms/step - loss: 0.5942 - accuracy: 0.7117 - val_loss: 0.4175 - val_accuracy: 0.8462\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 1s 232ms/step - loss: 0.4908 - accuracy: 0.7387 - val_loss: 0.4360 - val_accuracy: 0.6923\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.5261 - accuracy: 0.6937 - val_loss: 0.5609 - val_accuracy: 0.6154\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 0.5402 - accuracy: 0.7387 - val_loss: 0.5217 - val_accuracy: 0.6923\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.4633 - accuracy: 0.7658 - val_loss: 0.4220 - val_accuracy: 0.9231\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 1s 230ms/step - loss: 0.5040 - accuracy: 0.7568 - val_loss: 0.4632 - val_accuracy: 0.7692\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 1s 238ms/step - loss: 0.5349 - accuracy: 0.6937 - val_loss: 0.5953 - val_accuracy: 0.6923\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.4633 - accuracy: 0.7928 - val_loss: 0.6006 - val_accuracy: 0.6154\n",
            "\n",
            "\n",
            "start epoch 20\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 1s 258ms/step - loss: 0.4973 - accuracy: 0.7568 - val_loss: 0.7335 - val_accuracy: 0.5385\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 0.5304 - accuracy: 0.7207 - val_loss: 0.6152 - val_accuracy: 0.6923\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.4536 - accuracy: 0.7658 - val_loss: 0.5939 - val_accuracy: 0.6923\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 1s 234ms/step - loss: 0.5435 - accuracy: 0.7297 - val_loss: 0.5803 - val_accuracy: 0.6923\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 0.6149 - accuracy: 0.6577 - val_loss: 0.5705 - val_accuracy: 0.6923\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 0.4323 - accuracy: 0.8198 - val_loss: 0.5834 - val_accuracy: 0.7692\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 1s 242ms/step - loss: 0.4798 - accuracy: 0.7387 - val_loss: 0.6086 - val_accuracy: 0.6923\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 0.5141 - accuracy: 0.7207 - val_loss: 0.6873 - val_accuracy: 0.6154\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 1s 232ms/step - loss: 0.4594 - accuracy: 0.7928 - val_loss: 0.5507 - val_accuracy: 0.7692\n",
            "\n",
            "\n",
            "start epoch 21\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 1s 241ms/step - loss: 0.4703 - accuracy: 0.7748 - val_loss: 0.4861 - val_accuracy: 0.7692\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 1s 230ms/step - loss: 0.5339 - accuracy: 0.7117 - val_loss: 0.5896 - val_accuracy: 0.6923\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 1s 247ms/step - loss: 0.4511 - accuracy: 0.7658 - val_loss: 0.4957 - val_accuracy: 0.7692\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 1s 244ms/step - loss: 0.4754 - accuracy: 0.7658 - val_loss: 0.7272 - val_accuracy: 0.5385\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 1s 279ms/step - loss: 0.5498 - accuracy: 0.6847 - val_loss: 0.5282 - val_accuracy: 0.7692\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 0.4317 - accuracy: 0.8468 - val_loss: 0.4442 - val_accuracy: 0.7692\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 1s 274ms/step - loss: 0.4640 - accuracy: 0.7838 - val_loss: 0.5465 - val_accuracy: 0.6154\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 0.5243 - accuracy: 0.7477 - val_loss: 0.5996 - val_accuracy: 0.6154\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 0.4794 - accuracy: 0.7477 - val_loss: 0.3579 - val_accuracy: 0.9231\n",
            "\n",
            "\n",
            "start epoch 22\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 0.4368 - accuracy: 0.8108 - val_loss: 0.6343 - val_accuracy: 0.5385\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 0.4955 - accuracy: 0.7297 - val_loss: 0.7729 - val_accuracy: 0.6154\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 0.4185 - accuracy: 0.8108 - val_loss: 0.5197 - val_accuracy: 0.7692\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 1s 256ms/step - loss: 0.4946 - accuracy: 0.7477 - val_loss: 0.4337 - val_accuracy: 0.8462\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 0.5120 - accuracy: 0.7297 - val_loss: 0.3740 - val_accuracy: 0.8462\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 1s 250ms/step - loss: 0.4142 - accuracy: 0.8378 - val_loss: 0.3273 - val_accuracy: 0.8462\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 0.4478 - accuracy: 0.7748 - val_loss: 0.5847 - val_accuracy: 0.6154\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 1s 291ms/step - loss: 0.5554 - accuracy: 0.7387 - val_loss: 0.3729 - val_accuracy: 0.9231\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 1s 234ms/step - loss: 0.4489 - accuracy: 0.7568 - val_loss: 0.4976 - val_accuracy: 0.6923\n",
            "\n",
            "\n",
            "start epoch 23\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.4742 - accuracy: 0.8108 - val_loss: 0.3584 - val_accuracy: 0.8462\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 1s 269ms/step - loss: 0.5269 - accuracy: 0.7387 - val_loss: 0.3144 - val_accuracy: 0.8462\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 1s 232ms/step - loss: 0.4001 - accuracy: 0.8378 - val_loss: 0.3728 - val_accuracy: 0.7692\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 1s 230ms/step - loss: 0.4914 - accuracy: 0.7477 - val_loss: 0.3100 - val_accuracy: 0.9231\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 1s 243ms/step - loss: 0.5070 - accuracy: 0.7477 - val_loss: 0.4275 - val_accuracy: 0.8462\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 0.3785 - accuracy: 0.8468 - val_loss: 0.6630 - val_accuracy: 0.6154\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 1s 233ms/step - loss: 0.4222 - accuracy: 0.8378 - val_loss: 0.4774 - val_accuracy: 0.7692\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 1s 248ms/step - loss: 0.4414 - accuracy: 0.8018 - val_loss: 0.4863 - val_accuracy: 0.7692\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 0.4262 - accuracy: 0.8288 - val_loss: 0.4361 - val_accuracy: 0.7692\n",
            "\n",
            "\n",
            "start epoch 24\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 1s 273ms/step - loss: 0.4558 - accuracy: 0.7838 - val_loss: 0.2315 - val_accuracy: 1.0000\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 0.5053 - accuracy: 0.7027 - val_loss: 0.4766 - val_accuracy: 0.7692\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 1s 247ms/step - loss: 0.4964 - accuracy: 0.7928 - val_loss: 0.3921 - val_accuracy: 0.8462\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 0.5026 - accuracy: 0.7207 - val_loss: 0.6741 - val_accuracy: 0.5385\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 1s 268ms/step - loss: 0.4996 - accuracy: 0.7477 - val_loss: 0.4751 - val_accuracy: 0.7692\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 0.4000 - accuracy: 0.8559 - val_loss: 0.3816 - val_accuracy: 0.8462\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 1s 234ms/step - loss: 0.4760 - accuracy: 0.7658 - val_loss: 0.5002 - val_accuracy: 0.8462\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 0.4839 - accuracy: 0.7117 - val_loss: 0.7361 - val_accuracy: 0.6154\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 1s 241ms/step - loss: 0.4223 - accuracy: 0.8288 - val_loss: 0.4109 - val_accuracy: 0.9231\n",
            "\n",
            "\n",
            "start epoch 25\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 0.4023 - accuracy: 0.8108 - val_loss: 0.4588 - val_accuracy: 0.8462\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 0.5460 - accuracy: 0.6667 - val_loss: 0.3200 - val_accuracy: 0.8462\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 0.4107 - accuracy: 0.8198 - val_loss: 0.3308 - val_accuracy: 0.8462\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 1s 250ms/step - loss: 0.4584 - accuracy: 0.7658 - val_loss: 0.5808 - val_accuracy: 0.5385\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 0.5153 - accuracy: 0.6937 - val_loss: 0.4246 - val_accuracy: 0.9231\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 0.3570 - accuracy: 0.8378 - val_loss: 0.3839 - val_accuracy: 0.8462\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 0.4433 - accuracy: 0.7838 - val_loss: 0.3378 - val_accuracy: 0.8462\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.5773 - accuracy: 0.7117 - val_loss: 0.3843 - val_accuracy: 0.6923\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 0.4001 - accuracy: 0.8288 - val_loss: 0.4087 - val_accuracy: 0.8462\n",
            "\n",
            "\n",
            "start epoch 26\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 0.4549 - accuracy: 0.7928 - val_loss: 0.3789 - val_accuracy: 0.7692\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 1s 258ms/step - loss: 0.4615 - accuracy: 0.7928 - val_loss: 0.4922 - val_accuracy: 0.6923\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 1s 250ms/step - loss: 0.4200 - accuracy: 0.7838 - val_loss: 0.4444 - val_accuracy: 0.7692\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 1s 234ms/step - loss: 0.4757 - accuracy: 0.7568 - val_loss: 0.3570 - val_accuracy: 0.7692\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 1s 237ms/step - loss: 0.4345 - accuracy: 0.8018 - val_loss: 0.3911 - val_accuracy: 0.8462\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 1s 229ms/step - loss: 0.3829 - accuracy: 0.8468 - val_loss: 0.4801 - val_accuracy: 0.7692\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 1s 248ms/step - loss: 0.3846 - accuracy: 0.8198 - val_loss: 0.3588 - val_accuracy: 0.9231\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 0.4441 - accuracy: 0.7568 - val_loss: 0.7875 - val_accuracy: 0.6923\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 0.3788 - accuracy: 0.8378 - val_loss: 0.5531 - val_accuracy: 0.6923\n",
            "\n",
            "\n",
            "start epoch 27\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 1s 234ms/step - loss: 0.3829 - accuracy: 0.8378 - val_loss: 0.5095 - val_accuracy: 0.8462\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.4575 - accuracy: 0.7658 - val_loss: 0.3917 - val_accuracy: 0.7692\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 0.3476 - accuracy: 0.8829 - val_loss: 0.4229 - val_accuracy: 0.7692\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.4370 - accuracy: 0.7838 - val_loss: 0.5550 - val_accuracy: 0.5385\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 0.4324 - accuracy: 0.7748 - val_loss: 0.4098 - val_accuracy: 0.8462\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 1s 265ms/step - loss: 0.3750 - accuracy: 0.8468 - val_loss: 0.3563 - val_accuracy: 0.7692\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 0.3687 - accuracy: 0.8288 - val_loss: 0.3183 - val_accuracy: 0.8462\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 1s 246ms/step - loss: 0.3889 - accuracy: 0.8378 - val_loss: 0.4773 - val_accuracy: 0.7692\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 0.3722 - accuracy: 0.8559 - val_loss: 0.3313 - val_accuracy: 0.9231\n",
            "\n",
            "\n",
            "start epoch 28\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.3617 - accuracy: 0.8559 - val_loss: 0.4527 - val_accuracy: 0.7692\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 0.4419 - accuracy: 0.7658 - val_loss: 0.5668 - val_accuracy: 0.6923\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 1s 259ms/step - loss: 0.3281 - accuracy: 0.8559 - val_loss: 0.4717 - val_accuracy: 0.8462\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 1s 237ms/step - loss: 0.5060 - accuracy: 0.7477 - val_loss: 0.3273 - val_accuracy: 0.8462\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 1s 256ms/step - loss: 0.3986 - accuracy: 0.7928 - val_loss: 0.5307 - val_accuracy: 0.6923\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 0.3742 - accuracy: 0.8288 - val_loss: 0.2179 - val_accuracy: 1.0000\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 0.3673 - accuracy: 0.8468 - val_loss: 0.4080 - val_accuracy: 0.8462\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 0.4471 - accuracy: 0.8018 - val_loss: 0.4880 - val_accuracy: 0.7692\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 1s 284ms/step - loss: 0.4401 - accuracy: 0.8018 - val_loss: 0.3484 - val_accuracy: 0.9231\n",
            "\n",
            "\n",
            "start epoch 29\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 0.3610 - accuracy: 0.8108 - val_loss: 0.5527 - val_accuracy: 0.7692\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 0.4896 - accuracy: 0.7477 - val_loss: 0.2977 - val_accuracy: 0.8462\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 0.3775 - accuracy: 0.8288 - val_loss: 0.3277 - val_accuracy: 0.8462\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 1s 262ms/step - loss: 0.4675 - accuracy: 0.7568 - val_loss: 0.3522 - val_accuracy: 0.8462\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 1s 229ms/step - loss: 0.4259 - accuracy: 0.7658 - val_loss: 0.3852 - val_accuracy: 0.8462\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 1s 256ms/step - loss: 0.3158 - accuracy: 0.8919 - val_loss: 0.7069 - val_accuracy: 0.7692\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 0.3715 - accuracy: 0.8288 - val_loss: 0.4851 - val_accuracy: 0.7692\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 1s 250ms/step - loss: 0.3733 - accuracy: 0.8378 - val_loss: 0.4902 - val_accuracy: 0.8462\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 0.3842 - accuracy: 0.8468 - val_loss: 0.5881 - val_accuracy: 0.6154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0svWpVPkiUsK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43f5d039-1602-4b9c-b253-3bc2287b6f82"
      },
      "source": [
        "# testing process\n",
        "file_num = 2\n",
        "num_list = []\n",
        "acc_list = []\n",
        "m = tf.keras.metrics.CategoricalAccuracy()\n",
        "for i in range(file_num):\n",
        "  # myData = DR_resized(False, i, 32, 0.1, (224, 224))\n",
        "  myData = DR_resized(False, i, 32, 0.1)\n",
        "  num, acc = myModel.evaluate(myData.test_images, myData.test_labels)\n",
        "  print(num, acc)\n",
        "  # p = myModel.model.predict(myData.test_images)\n",
        "  # print(p)\n",
        "  # m.update_state(p, myData.test_labels)\n",
        "  # num_list.append(num)\n",
        "  # acc_list.append(acc)\n",
        "  myData.clear()\n",
        "  gc.collect()\n",
        "\n",
        "print(m.result().numpy())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 - 1s - loss: 0.6947 - accuracy: 0.4758\n",
            "124 0.47580644488334656\n",
            "6/6 - 1s - loss: 0.6938 - accuracy: 0.5000\n",
            "176 0.5\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao-XE2iuqBwV"
      },
      "source": [
        "myData = DR_resized(True, 1, 32, 0.1, (224, 224))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka-Jb5ksq_BL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7790eb8e-7d8c-4e83-b85c-883da3ecf999"
      },
      "source": [
        "all_labels_one_hot = myData.train_labels\n",
        "# all_labels_one_hot = np.zeros((myData.test_labels.size, 2))\n",
        "# all_labels_one_hot[np.arange(myData.test_labels.size),myData.test_labels] = 1\n",
        "\n",
        "p = myModel.model.predict(myData.train_images)\n",
        "m = tf.keras.metrics.CategoricalAccuracy()\n",
        "m.update_state(p[-10:], all_labels_one_hot[-10:])\n",
        "m.result().numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x5SZXUUyzNB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a09464ae-b964-4bc2-8963-f8ce1dfb4191"
      },
      "source": [
        "p.argmax(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f71I1uqy1P2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34f356ec-c457-45d1-9eba-e7253ffcaf7d"
      },
      "source": [
        "all_labels_one_hot[-10:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqL9za1Dkqjy"
      },
      "source": [
        "# compute overall accuracy\n",
        "num_list = np.array(num_list)\n",
        "acc_list = np.array(acc_list)\n",
        "acc_overall = (num_list * acc_list).sum() / num_list.sum()\n",
        "print(acc_overall)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBuQpdk7vC25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "653121d9-7c0b-4cfb-b23e-6775ec21f7c6"
      },
      "source": [
        "from datetime import datetime\n",
        "now = datetime.now()\n",
        "dt_string = now.strftime(\"%d-%m-%Y %H:%M:%S\")\n",
        "print(\"date and time =\", dt_string)\n",
        "myModel.save_model(os.path.join(project_root, \"Trained Models\", dt_string))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "date and time = 09-04-2021 06:55:46\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/CS 766 Project/Project Coding and Data Files/Trained Models/09-04-2021 06:55:46/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2QDEecGwGTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df8c0af3-334a-4e3b-f0d0-f7737c153ad9"
      },
      "source": [
        "# this part is for loading parameters and extracting features\n",
        "# load parameters\n",
        "parameter_version = \"09-04-2021 06:55:46\"\n",
        "if not os.path.exists(os.path.join(project_root, \"features\", parameter_version)):\n",
        "    os.mkdir(os.path.join(project_root, \"features\", parameter_version))\n",
        "\n",
        "my_model_pretrained = OriginCNN()\n",
        "# my_model_pretrained = Res50()\n",
        "my_model_pretrained.build()\n",
        "my_model_pretrained.load_model(os.path.join(project_root, \"Trained Models\", parameter_version))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 333, 333, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 166, 166, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 55, 55, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 27, 27, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 9, 9, 32)          9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 32)                16416     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 35,874\n",
            "Trainable params: 35,874\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dC4KT0HjTqe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "294b98c9-c954-4dfd-a6a9-61680ccfed32"
      },
      "source": [
        "# load training data, extract features and save to npy files\n",
        "file_num = 9\n",
        "for i in range(file_num):\n",
        "  # myData = DR_resized(True, i, 32, 0.1, (224, 224))\n",
        "  myData = DR_resized(True, i, 32, 0.1)\n",
        "  feature = my_model_pretrained.extract_feature(myData.train_images)\n",
        "  # feature = myModel.extract_feature(myData.train_images)\n",
        "  np.save(os.path.join(project_root, \"features\", parameter_version, \"Xtrain_feature%d.npy\" % i), feature)\n",
        "  print(\"Xtrain_feature%d.npy\" % i)\n",
        "  print(feature.shape)\n",
        "  myData.clear()\n",
        "  gc.collect()\n",
        "\n",
        "# load testing data, extract features and save to npy files\n",
        "file_num = 2\n",
        "for i in range(file_num):\n",
        "  # myData = DR_resized(False, i, 32, 0.1, (224, 224))\n",
        "  myData = DR_resized(False, i, 32, 0.1)\n",
        "  feature = my_model_pretrained.extract_feature(myData.test_images)\n",
        "  np.save(os.path.join(project_root, \"features\", parameter_version, \"Xtest_feature%d.npy\" % i), feature)\n",
        "  print(\"Xtest_feature%d.npy\" % i)\n",
        "  myData.clear()\n",
        "  gc.collect()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Xtrain_feature0.npy\n",
            "(124, 512)\n",
            "Xtrain_feature1.npy\n",
            "(124, 512)\n",
            "Xtrain_feature2.npy\n",
            "(124, 512)\n",
            "Xtrain_feature3.npy\n",
            "(124, 512)\n",
            "Xtrain_feature4.npy\n",
            "(124, 512)\n",
            "Xtrain_feature5.npy\n",
            "(124, 512)\n",
            "Xtrain_feature6.npy\n",
            "(124, 512)\n",
            "Xtrain_feature7.npy\n",
            "(124, 512)\n",
            "Xtrain_feature8.npy\n",
            "(124, 512)\n",
            "Xtest_feature0.npy\n",
            "Xtest_feature1.npy\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}