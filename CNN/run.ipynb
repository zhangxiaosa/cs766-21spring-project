{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "run.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGoAP5Dn3DwQ"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os, re, sys\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import gc\n",
        "import skimage.transform"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYucCZeH_dHH",
        "outputId": "9c5597d3-4491-44ee-f1dc-db0ee0ebd536"
      },
      "source": [
        "# test if GPUs are available\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUiMh4isCHnS",
        "outputId": "8cd88f74-7b0c-47b7-c2f6-9dda3b5e43be"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJQvxwJFDmYk"
      },
      "source": [
        "# set project root, maybe you need to firstly \n",
        "# add shortcut of CS 766 Project to drive.\n",
        "project_root = './drive/MyDrive/CS 766 Project/Project Coding and Data Files'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGJsefpJ-XjF"
      },
      "source": [
        "# class to initialize CNNs\n",
        "class OriginCNN(object):\n",
        "  \"\"\"docstring for OriginCNN\"\"\"\n",
        "  def __init__(self):\n",
        "    self.optimizer = 'adam'\n",
        "    # self.optimizer = tf.keras.optimizers.SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "    # self.loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    # will add more properties\n",
        "\n",
        "\n",
        "  def build(self):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), strides=(3,3), activation='relu', input_shape=(1000, 1000, 3)))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(32, (3, 3), strides=(3,3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(32, (3, 3), strides=(3,3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(32, activation='relu'))\n",
        "    model.add(layers.Dense(5))\n",
        "\n",
        "    model.summary()\n",
        "    model.compile(optimizer=self.optimizer,\n",
        "                loss=self.loss,\n",
        "                metrics=['accuracy'])\n",
        "    self.model = model\n",
        "\n",
        "\n",
        "  def train(self, train_images, train_labels, epochs):\n",
        "    self.history = self.model.fit(train_images, train_labels, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "  def train_on_batch(self, train_images, train_labels):\n",
        "    return self.model.train_on_batch(train_images, train_labels)\n",
        "\n",
        "  def predict(self, test_images):\n",
        "    return self.model.predict(test_images)\n",
        "\n",
        "\n",
        "  def evaluate(self, test_images, test_labels):\n",
        "    _, test_acc = self.model.evaluate(test_images, test_labels, verbose=2)\n",
        "    return test_images.shape[0], test_acc\n",
        "\n",
        "  def save_model(self, filepath):\n",
        "    self.model.save(filepath)\n",
        "\n",
        "  def load_model(self, filepath):\n",
        "    self.model = tf.keras.models.load_model(filepath)\n",
        "\n",
        "  def extract_feature(self, images):\n",
        "    extract = models.Model(self.model.inputs, self.model.layers[-3].output)\n",
        "    return extract.predict(images)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSiCn4VzdaV8"
      },
      "source": [
        "from tensorflow.keras.applications import ResNet50, InceptionV3, VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "class Res50(object):\n",
        "  \"\"\"docstring for OriginCNN\"\"\"\n",
        "  def __init__(self):\n",
        "    self.optimizer = 'adam'\n",
        "    # self.optimizer = tf.keras.optimizers.SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "    # self.loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    # will add more properties\n",
        "\n",
        "\n",
        "  def build(self):\n",
        "    base_model = InceptionV3(\n",
        "      include_top=False,\n",
        "      weights=\"imagenet\",\n",
        "      input_shape=(224, 224, 3)\n",
        "    )\n",
        "\n",
        "    # add a global spatial average pooling layer\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    # let's add a fully-connected layer\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    # and a logistic layer -- let's say we have n classes\n",
        "    predictions = Dense(2)(x)\n",
        "\n",
        "    # this is the model we will train\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "\n",
        "    model.summary()\n",
        "    model.compile(optimizer=self.optimizer,\n",
        "                loss=self.loss,\n",
        "                metrics=['accuracy'])\n",
        "    self.model = model\n",
        "\n",
        "\n",
        "  def train(self, train_images, train_labels, epochs):\n",
        "    self.history = self.model.fit(train_images, train_labels, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "  def train_on_batch(self, train_images, train_labels):\n",
        "    return self.model.train_on_batch(train_images, train_labels)\n",
        "\n",
        "  def predict(self, test_images):\n",
        "    return self.model.predict(test_images)\n",
        "\n",
        "\n",
        "  def evaluate(self, test_images, test_labels):\n",
        "    _, test_acc = self.model.evaluate(test_images, test_labels, verbose=2)\n",
        "    return test_images.shape[0], test_acc\n",
        "\n",
        "  def save_model(self, filepath):\n",
        "    self.model.save(filepath)\n",
        "\n",
        "  def load_model(self, filepath):\n",
        "    self.model = tf.keras.models.load_model(filepath)\n",
        "\n",
        "  def extract_feature(self, images):\n",
        "    extract = models.Model(self.model.inputs, self.model.layers[-3].output)\n",
        "    return extract.predict(images)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3suc98v-bRj"
      },
      "source": [
        "class DR_resized(object):\n",
        "  \"\"\"docstring for DR_resized\"\"\"\n",
        "  def __init__(self, is_training, batch_id, batch_size, train_val_split_rate, size=None):\n",
        "    self.batch_size = batch_size\n",
        "    self.train_val_split_rate = train_val_split_rate\n",
        "    if(is_training):\n",
        "      # load images\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Stratified_Random_Sampling_Datasets\", \"Processed_Xtrain_Batch%d.npy\" % batch_id))\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Even_Class_Distribution_Datasets\", \"Processed_Xtrain_Batch%d_even.npy\" % batch_id))\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Color_Even_Class_Distribution_Datasets\", \"Color_Processed_Xtrain_Batch%d_even.npy\" % batch_id))\n",
        "      all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"04_Only_Color_Even_Class_Distribution_Datasets\", \"04_Only_Color_Processed_Xtrain_Batch%d_even.npy\" % batch_id))\n",
        "      \n",
        "      # add a dimension for channels if gray scale images\n",
        "      if (len(all_images[0].shape) == 2):\n",
        "        all_images = np.expand_dims(all_images, axis=-1)\n",
        "\n",
        "      # resize\n",
        "      # gray scale\n",
        "      if (len(all_images[0].shape) == 2):\n",
        "        all_images_resize = np.zeros((all_images.shape[0], size[0], size[1], 1));\n",
        "        for i in range(all_images.shape[0]):\n",
        "          all_images_resize[i] = skimage.transform.resize(all_images[i].astype('float64'), (size[0], size[1]));\n",
        "      # color image\n",
        "      else:\n",
        "        all_images_resize = np.zeros((all_images.shape[0], size[0], size[1], 3));\n",
        "        for i in range(all_images.shape[0]):\n",
        "          all_images_resize[i] = skimage.transform.resize(all_images[i].astype('float64'), (size[0], size[1]));\n",
        "      all_images = all_images_resize\n",
        "\n",
        "\n",
        "      # load labels\n",
        "      # all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Stratified Random Sampling Datasets\", \"Ytrain\", \"Ytrain_Batch%d.npy\" % batch_id), allow_pickle=True)\n",
        "      # all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Even Class Distribution Datasets\", \"Ytrain\", \"Ytrain_Batch%d_even.npy\" % batch_id), allow_pickle=True)\n",
        "      all_labels = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"04_Only_Color_Even_Class_Distribution_Datasets\", \"04_Only_Ytrain_Batch%d_even.npy\" % batch_id), allow_pickle=True)\n",
        "      all_labels = np.array([item[1] for item in all_labels])\n",
        "      \n",
        "      # one hot\n",
        "      # all_labels_one_hot = np.zeros((all_labels.size, 5))\n",
        "      # all_labels_one_hot[np.arange(all_labels.size),all_labels] = 1\n",
        "\n",
        "      # without one hot\n",
        "      all_labels_one_hot = np.expand_dims(all_labels, axis=-1)\n",
        "\n",
        "      # shuffle\n",
        "      indices = np.arange(all_images.shape[0])\n",
        "      np.random.shuffle(indices)\n",
        "      all_images = all_images[indices]\n",
        "      all_labels_one_hot = all_labels_one_hot[indices]\n",
        "\n",
        "      self.train_images = all_images\n",
        "      self.train_labels = all_labels_one_hot\n",
        "    \n",
        "    else:\n",
        "      # load images\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Stratified_Random_Sampling_Datasets\", \"Processed_Xtest_Batch%d.npy\") % batch_id)\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Even_Class_Distribution_Datasets\", \"Processed_Xest_Batch%d_even.npy\") % batch_id)\n",
        "      all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Color_Even_Class_Distribution_Datasets\", \"Color_Processed_Xest_Batch%d_even.npy\") % batch_id)\n",
        "      \n",
        "      # add a dimension for channels if gray scale images\n",
        "      if (len(all_images[0].shape) == 2):\n",
        "        all_images = np.expand_dims(all_images, axis=-1)\n",
        "\n",
        "      # load labels\n",
        "      # all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Stratified Random Sampling Datasets\", \"Ytest\", \"Ytest_Batch%d.npy\" % batch_id), allow_pickle=True)\n",
        "      all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Even Class Distribution Datasets\", \"Ytest\", \"Yest_Batch%d_even.npy\" % batch_id), allow_pickle=True)\n",
        "      all_labels = np.array([item[1] for item in all_labels])\n",
        "\n",
        "      # one hot\n",
        "      # all_labels_one_hot = np.zeros((all_labels.size, 5))\n",
        "      # all_labels_one_hot[np.arange(all_labels.size),all_labels] = 1\n",
        "\n",
        "      # without one hot\n",
        "      all_labels_one_hot = np.expand_dims(all_labels, axis=-1)\n",
        "      \n",
        "      self.test_images = all_images\n",
        "      self.test_labels = all_labels_one_hot\n",
        "  \n",
        "  def clear(self):\n",
        "    self.train_images = None\n",
        "    self.validate_images = None\n",
        "    self.test_images = None\n",
        "    self.train_labels = None\n",
        "    self.validate_labels = None\n",
        "    self.test_labels = None\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L57sy6Z02c-"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class Cifar(object):\n",
        "  \"\"\"docstring for DR_resized\"\"\"\n",
        "  def __init__(self, is_training, batch_id, batch_size, train_val_split_rate):\n",
        "    self.batch_size = batch_size\n",
        "    self.train_val_split_rate = train_val_split_rate\n",
        "\n",
        "    if(is_training):\n",
        "      # load images\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Stratified_Random_Sampling_Datasets\", \"Processed_Xtrain_Batch%d.npy\" % batch_id))\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Even_Class_Distribution_Datasets\", \"Processed_Xtrain_Batch%d_even.npy\" % batch_id))\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Color_Even_Class_Distribution_Datasets\", \"Color_Processed_Xtrain_Batch%d_even.npy\" % batch_id))\n",
        "      \n",
        "      # add a dimension for channels if gray scale images\n",
        "      # if (len(all_images[0].shape) == 2):\n",
        "        # all_images = np.expand_dims(all_images, axis=-1)\n",
        "\n",
        "      # load labels\n",
        "      # all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Stratified Random Sampling Datasets\", \"Ytrain\", \"Ytrain_Batch%d.npy\" % batch_id), allow_pickle=True)\n",
        "      # all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Even Class Distribution Datasets\", \"Ytrain\", \"Ytrain_Batch%d_even.npy\" % batch_id), allow_pickle=True)\n",
        "      # all_labels = np.array([item[1] for item in all_labels])\n",
        "\n",
        "      (train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "      train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "      all_images = train_images\n",
        "      all_labels = train_labels\n",
        "      \n",
        "      # one hot\n",
        "      # all_labels_one_hot = np.zeros((all_labels.size, 10))\n",
        "      # all_labels_one_hot[np.arange(all_labels.size),all_labels] = 1\n",
        "\n",
        "      # without one hot\n",
        "      all_labels_one_hot = np.expand_dims(all_labels, axis=-1)\n",
        "\n",
        "      # shuffle\n",
        "      indices = np.arange(all_images.shape[0])\n",
        "      np.random.shuffle(indices)\n",
        "      all_images = all_images[indices]\n",
        "      all_labels_one_hot = all_labels_one_hot[indices]\n",
        "\n",
        "      self.train_images = all_images\n",
        "      self.train_labels = all_labels_one_hot\n",
        "    \n",
        "    else:\n",
        "      # load images\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Stratified_Random_Sampling_Datasets\", \"Processed_Xtest_Batch%d.npy\") % batch_id)\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Even_Class_Distribution_Datasets\", \"Processed_Xest_Batch%d_even.npy\") % batch_id)\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Color_Even_Class_Distribution_Datasets\", \"Color_Processed_Xest_Batch%d_even.npy\") % batch_id)\n",
        "      \n",
        "      # add a dimension for channels if gray scale images\n",
        "      # if (len(all_images[0].shape) == 2):\n",
        "      #   all_images = np.expand_dims(all_images, axis=-1)\n",
        "\n",
        "      # load labels\n",
        "      # all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Stratified Random Sampling Datasets\", \"Ytest\", \"Ytest_Batch%d.npy\" % batch_id), allow_pickle=True)\n",
        "      # all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Even Class Distribution Datasets\", \"Ytest\", \"Yest_Batch%d_even.npy\" % batch_id), allow_pickle=True)\n",
        "      # all_labels = np.array([item[1] for item in all_labels])\n",
        "\n",
        "      (train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "      train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "      all_images = test_images\n",
        "      all_labels = test_labels\n",
        "\n",
        "      # one hot\n",
        "      all_labels_one_hot = np.zeros((all_labels.size, 10))\n",
        "      all_labels_one_hot[np.arange(all_labels.size),all_labels] = 1\n",
        "\n",
        "      # without one hot\n",
        "      # all_labels = np.expand_dims(all_labels, axis=-1)\n",
        "      \n",
        "      self.test_images = all_images\n",
        "      self.test_labels = all_labels_one_hot\n",
        "  \n",
        "  def clear(self):\n",
        "    self.train_images = None\n",
        "    self.validate_images = None\n",
        "    self.test_images = None\n",
        "    self.train_labels = None\n",
        "    self.validate_labels = None\n",
        "    self.test_labels = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOADsxqM3DwR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0866800c-9bd5-487f-ab66-ebc75a0b51d8"
      },
      "source": [
        "# initialize CNN\n",
        "# myModel = OriginCNN()\n",
        "myModel = Res50()\n",
        "myModel.build()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_376 (Conv2D)             (None, 111, 111, 32) 864         input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_376 (BatchN (None, 111, 111, 32) 96          conv2d_376[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_376 (Activation)     (None, 111, 111, 32) 0           batch_normalization_376[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_377 (Conv2D)             (None, 109, 109, 32) 9216        activation_376[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_377 (BatchN (None, 109, 109, 32) 96          conv2d_377[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_377 (Activation)     (None, 109, 109, 32) 0           batch_normalization_377[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_378 (Conv2D)             (None, 109, 109, 64) 18432       activation_377[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_378 (BatchN (None, 109, 109, 64) 192         conv2d_378[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_378 (Activation)     (None, 109, 109, 64) 0           batch_normalization_378[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling2D) (None, 54, 54, 64)   0           activation_378[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_379 (Conv2D)             (None, 54, 54, 80)   5120        max_pooling2d_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_379 (BatchN (None, 54, 54, 80)   240         conv2d_379[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_379 (Activation)     (None, 54, 54, 80)   0           batch_normalization_379[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_380 (Conv2D)             (None, 52, 52, 192)  138240      activation_379[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_380 (BatchN (None, 52, 52, 192)  576         conv2d_380[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_380 (Activation)     (None, 52, 52, 192)  0           batch_normalization_380[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling2D) (None, 25, 25, 192)  0           activation_380[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_384 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_17[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_384 (BatchN (None, 25, 25, 64)   192         conv2d_384[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_384 (Activation)     (None, 25, 25, 64)   0           batch_normalization_384[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_382 (Conv2D)             (None, 25, 25, 48)   9216        max_pooling2d_17[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_385 (Conv2D)             (None, 25, 25, 96)   55296       activation_384[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_382 (BatchN (None, 25, 25, 48)   144         conv2d_382[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_385 (BatchN (None, 25, 25, 96)   288         conv2d_385[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_382 (Activation)     (None, 25, 25, 48)   0           batch_normalization_382[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_385 (Activation)     (None, 25, 25, 96)   0           batch_normalization_385[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_36 (AveragePo (None, 25, 25, 192)  0           max_pooling2d_17[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_381 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_17[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_383 (Conv2D)             (None, 25, 25, 64)   76800       activation_382[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_386 (Conv2D)             (None, 25, 25, 96)   82944       activation_385[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_387 (Conv2D)             (None, 25, 25, 32)   6144        average_pooling2d_36[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_381 (BatchN (None, 25, 25, 64)   192         conv2d_381[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_383 (BatchN (None, 25, 25, 64)   192         conv2d_383[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_386 (BatchN (None, 25, 25, 96)   288         conv2d_386[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_387 (BatchN (None, 25, 25, 32)   96          conv2d_387[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_381 (Activation)     (None, 25, 25, 64)   0           batch_normalization_381[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_383 (Activation)     (None, 25, 25, 64)   0           batch_normalization_383[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_386 (Activation)     (None, 25, 25, 96)   0           batch_normalization_386[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_387 (Activation)     (None, 25, 25, 32)   0           batch_normalization_387[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_381[0][0]             \n",
            "                                                                 activation_383[0][0]             \n",
            "                                                                 activation_386[0][0]             \n",
            "                                                                 activation_387[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_391 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_391 (BatchN (None, 25, 25, 64)   192         conv2d_391[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_391 (Activation)     (None, 25, 25, 64)   0           batch_normalization_391[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_389 (Conv2D)             (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_392 (Conv2D)             (None, 25, 25, 96)   55296       activation_391[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_389 (BatchN (None, 25, 25, 48)   144         conv2d_389[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_392 (BatchN (None, 25, 25, 96)   288         conv2d_392[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_389 (Activation)     (None, 25, 25, 48)   0           batch_normalization_389[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_392 (Activation)     (None, 25, 25, 96)   0           batch_normalization_392[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_37 (AveragePo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_388 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_390 (Conv2D)             (None, 25, 25, 64)   76800       activation_389[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_393 (Conv2D)             (None, 25, 25, 96)   82944       activation_392[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_394 (Conv2D)             (None, 25, 25, 64)   16384       average_pooling2d_37[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_388 (BatchN (None, 25, 25, 64)   192         conv2d_388[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_390 (BatchN (None, 25, 25, 64)   192         conv2d_390[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_393 (BatchN (None, 25, 25, 96)   288         conv2d_393[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_394 (BatchN (None, 25, 25, 64)   192         conv2d_394[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_388 (Activation)     (None, 25, 25, 64)   0           batch_normalization_388[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_390 (Activation)     (None, 25, 25, 64)   0           batch_normalization_390[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_393 (Activation)     (None, 25, 25, 96)   0           batch_normalization_393[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_394 (Activation)     (None, 25, 25, 64)   0           batch_normalization_394[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_388[0][0]             \n",
            "                                                                 activation_390[0][0]             \n",
            "                                                                 activation_393[0][0]             \n",
            "                                                                 activation_394[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_398 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_398 (BatchN (None, 25, 25, 64)   192         conv2d_398[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_398 (Activation)     (None, 25, 25, 64)   0           batch_normalization_398[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_396 (Conv2D)             (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_399 (Conv2D)             (None, 25, 25, 96)   55296       activation_398[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_396 (BatchN (None, 25, 25, 48)   144         conv2d_396[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_399 (BatchN (None, 25, 25, 96)   288         conv2d_399[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_396 (Activation)     (None, 25, 25, 48)   0           batch_normalization_396[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_399 (Activation)     (None, 25, 25, 96)   0           batch_normalization_399[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_38 (AveragePo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_395 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_397 (Conv2D)             (None, 25, 25, 64)   76800       activation_396[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_400 (Conv2D)             (None, 25, 25, 96)   82944       activation_399[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_401 (Conv2D)             (None, 25, 25, 64)   18432       average_pooling2d_38[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_395 (BatchN (None, 25, 25, 64)   192         conv2d_395[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_397 (BatchN (None, 25, 25, 64)   192         conv2d_397[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_400 (BatchN (None, 25, 25, 96)   288         conv2d_400[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_401 (BatchN (None, 25, 25, 64)   192         conv2d_401[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_395 (Activation)     (None, 25, 25, 64)   0           batch_normalization_395[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_397 (Activation)     (None, 25, 25, 64)   0           batch_normalization_397[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_400 (Activation)     (None, 25, 25, 96)   0           batch_normalization_400[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_401 (Activation)     (None, 25, 25, 64)   0           batch_normalization_401[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_395[0][0]             \n",
            "                                                                 activation_397[0][0]             \n",
            "                                                                 activation_400[0][0]             \n",
            "                                                                 activation_401[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_403 (Conv2D)             (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_403 (BatchN (None, 25, 25, 64)   192         conv2d_403[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_403 (Activation)     (None, 25, 25, 64)   0           batch_normalization_403[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_404 (Conv2D)             (None, 25, 25, 96)   55296       activation_403[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_404 (BatchN (None, 25, 25, 96)   288         conv2d_404[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_404 (Activation)     (None, 25, 25, 96)   0           batch_normalization_404[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_402 (Conv2D)             (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_405 (Conv2D)             (None, 12, 12, 96)   82944       activation_404[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_402 (BatchN (None, 12, 12, 384)  1152        conv2d_402[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_405 (BatchN (None, 12, 12, 96)   288         conv2d_405[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_402 (Activation)     (None, 12, 12, 384)  0           batch_normalization_402[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_405 (Activation)     (None, 12, 12, 96)   0           batch_normalization_405[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling2D) (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_402[0][0]             \n",
            "                                                                 activation_405[0][0]             \n",
            "                                                                 max_pooling2d_18[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_410 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_410 (BatchN (None, 12, 12, 128)  384         conv2d_410[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_410 (Activation)     (None, 12, 12, 128)  0           batch_normalization_410[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_411 (Conv2D)             (None, 12, 12, 128)  114688      activation_410[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_411 (BatchN (None, 12, 12, 128)  384         conv2d_411[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_411 (Activation)     (None, 12, 12, 128)  0           batch_normalization_411[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_407 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_412 (Conv2D)             (None, 12, 12, 128)  114688      activation_411[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_407 (BatchN (None, 12, 12, 128)  384         conv2d_407[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_412 (BatchN (None, 12, 12, 128)  384         conv2d_412[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_407 (Activation)     (None, 12, 12, 128)  0           batch_normalization_407[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_412 (Activation)     (None, 12, 12, 128)  0           batch_normalization_412[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_408 (Conv2D)             (None, 12, 12, 128)  114688      activation_407[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_413 (Conv2D)             (None, 12, 12, 128)  114688      activation_412[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_408 (BatchN (None, 12, 12, 128)  384         conv2d_408[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_413 (BatchN (None, 12, 12, 128)  384         conv2d_413[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_408 (Activation)     (None, 12, 12, 128)  0           batch_normalization_408[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_413 (Activation)     (None, 12, 12, 128)  0           batch_normalization_413[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_39 (AveragePo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_406 (Conv2D)             (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_409 (Conv2D)             (None, 12, 12, 192)  172032      activation_408[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_414 (Conv2D)             (None, 12, 12, 192)  172032      activation_413[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_415 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_39[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_406 (BatchN (None, 12, 12, 192)  576         conv2d_406[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_409 (BatchN (None, 12, 12, 192)  576         conv2d_409[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_414 (BatchN (None, 12, 12, 192)  576         conv2d_414[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_415 (BatchN (None, 12, 12, 192)  576         conv2d_415[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_406 (Activation)     (None, 12, 12, 192)  0           batch_normalization_406[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_409 (Activation)     (None, 12, 12, 192)  0           batch_normalization_409[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_414 (Activation)     (None, 12, 12, 192)  0           batch_normalization_414[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_415 (Activation)     (None, 12, 12, 192)  0           batch_normalization_415[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_406[0][0]             \n",
            "                                                                 activation_409[0][0]             \n",
            "                                                                 activation_414[0][0]             \n",
            "                                                                 activation_415[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_420 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_420 (BatchN (None, 12, 12, 160)  480         conv2d_420[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_420 (Activation)     (None, 12, 12, 160)  0           batch_normalization_420[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_421 (Conv2D)             (None, 12, 12, 160)  179200      activation_420[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_421 (BatchN (None, 12, 12, 160)  480         conv2d_421[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_421 (Activation)     (None, 12, 12, 160)  0           batch_normalization_421[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_417 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_422 (Conv2D)             (None, 12, 12, 160)  179200      activation_421[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_417 (BatchN (None, 12, 12, 160)  480         conv2d_417[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_422 (BatchN (None, 12, 12, 160)  480         conv2d_422[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_417 (Activation)     (None, 12, 12, 160)  0           batch_normalization_417[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_422 (Activation)     (None, 12, 12, 160)  0           batch_normalization_422[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_418 (Conv2D)             (None, 12, 12, 160)  179200      activation_417[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_423 (Conv2D)             (None, 12, 12, 160)  179200      activation_422[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_418 (BatchN (None, 12, 12, 160)  480         conv2d_418[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_423 (BatchN (None, 12, 12, 160)  480         conv2d_423[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_418 (Activation)     (None, 12, 12, 160)  0           batch_normalization_418[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_423 (Activation)     (None, 12, 12, 160)  0           batch_normalization_423[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_40 (AveragePo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_416 (Conv2D)             (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_419 (Conv2D)             (None, 12, 12, 192)  215040      activation_418[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_424 (Conv2D)             (None, 12, 12, 192)  215040      activation_423[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_425 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_40[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_416 (BatchN (None, 12, 12, 192)  576         conv2d_416[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_419 (BatchN (None, 12, 12, 192)  576         conv2d_419[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_424 (BatchN (None, 12, 12, 192)  576         conv2d_424[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_425 (BatchN (None, 12, 12, 192)  576         conv2d_425[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_416 (Activation)     (None, 12, 12, 192)  0           batch_normalization_416[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_419 (Activation)     (None, 12, 12, 192)  0           batch_normalization_419[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_424 (Activation)     (None, 12, 12, 192)  0           batch_normalization_424[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_425 (Activation)     (None, 12, 12, 192)  0           batch_normalization_425[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_416[0][0]             \n",
            "                                                                 activation_419[0][0]             \n",
            "                                                                 activation_424[0][0]             \n",
            "                                                                 activation_425[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_430 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_430 (BatchN (None, 12, 12, 160)  480         conv2d_430[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_430 (Activation)     (None, 12, 12, 160)  0           batch_normalization_430[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_431 (Conv2D)             (None, 12, 12, 160)  179200      activation_430[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_431 (BatchN (None, 12, 12, 160)  480         conv2d_431[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_431 (Activation)     (None, 12, 12, 160)  0           batch_normalization_431[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_427 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_432 (Conv2D)             (None, 12, 12, 160)  179200      activation_431[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_427 (BatchN (None, 12, 12, 160)  480         conv2d_427[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_432 (BatchN (None, 12, 12, 160)  480         conv2d_432[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_427 (Activation)     (None, 12, 12, 160)  0           batch_normalization_427[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_432 (Activation)     (None, 12, 12, 160)  0           batch_normalization_432[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_428 (Conv2D)             (None, 12, 12, 160)  179200      activation_427[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_433 (Conv2D)             (None, 12, 12, 160)  179200      activation_432[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_428 (BatchN (None, 12, 12, 160)  480         conv2d_428[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_433 (BatchN (None, 12, 12, 160)  480         conv2d_433[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_428 (Activation)     (None, 12, 12, 160)  0           batch_normalization_428[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_433 (Activation)     (None, 12, 12, 160)  0           batch_normalization_433[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_41 (AveragePo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_426 (Conv2D)             (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_429 (Conv2D)             (None, 12, 12, 192)  215040      activation_428[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_434 (Conv2D)             (None, 12, 12, 192)  215040      activation_433[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_435 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_41[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_426 (BatchN (None, 12, 12, 192)  576         conv2d_426[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_429 (BatchN (None, 12, 12, 192)  576         conv2d_429[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_434 (BatchN (None, 12, 12, 192)  576         conv2d_434[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_435 (BatchN (None, 12, 12, 192)  576         conv2d_435[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_426 (Activation)     (None, 12, 12, 192)  0           batch_normalization_426[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_429 (Activation)     (None, 12, 12, 192)  0           batch_normalization_429[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_434 (Activation)     (None, 12, 12, 192)  0           batch_normalization_434[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_435 (Activation)     (None, 12, 12, 192)  0           batch_normalization_435[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_426[0][0]             \n",
            "                                                                 activation_429[0][0]             \n",
            "                                                                 activation_434[0][0]             \n",
            "                                                                 activation_435[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_440 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_440 (BatchN (None, 12, 12, 192)  576         conv2d_440[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_440 (Activation)     (None, 12, 12, 192)  0           batch_normalization_440[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_441 (Conv2D)             (None, 12, 12, 192)  258048      activation_440[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_441 (BatchN (None, 12, 12, 192)  576         conv2d_441[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_441 (Activation)     (None, 12, 12, 192)  0           batch_normalization_441[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_437 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_442 (Conv2D)             (None, 12, 12, 192)  258048      activation_441[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_437 (BatchN (None, 12, 12, 192)  576         conv2d_437[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_442 (BatchN (None, 12, 12, 192)  576         conv2d_442[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_437 (Activation)     (None, 12, 12, 192)  0           batch_normalization_437[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_442 (Activation)     (None, 12, 12, 192)  0           batch_normalization_442[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_438 (Conv2D)             (None, 12, 12, 192)  258048      activation_437[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_443 (Conv2D)             (None, 12, 12, 192)  258048      activation_442[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_438 (BatchN (None, 12, 12, 192)  576         conv2d_438[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_443 (BatchN (None, 12, 12, 192)  576         conv2d_443[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_438 (Activation)     (None, 12, 12, 192)  0           batch_normalization_438[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_443 (Activation)     (None, 12, 12, 192)  0           batch_normalization_443[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_42 (AveragePo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_436 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_439 (Conv2D)             (None, 12, 12, 192)  258048      activation_438[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_444 (Conv2D)             (None, 12, 12, 192)  258048      activation_443[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_445 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_42[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_436 (BatchN (None, 12, 12, 192)  576         conv2d_436[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_439 (BatchN (None, 12, 12, 192)  576         conv2d_439[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_444 (BatchN (None, 12, 12, 192)  576         conv2d_444[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_445 (BatchN (None, 12, 12, 192)  576         conv2d_445[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_436 (Activation)     (None, 12, 12, 192)  0           batch_normalization_436[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_439 (Activation)     (None, 12, 12, 192)  0           batch_normalization_439[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_444 (Activation)     (None, 12, 12, 192)  0           batch_normalization_444[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_445 (Activation)     (None, 12, 12, 192)  0           batch_normalization_445[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_436[0][0]             \n",
            "                                                                 activation_439[0][0]             \n",
            "                                                                 activation_444[0][0]             \n",
            "                                                                 activation_445[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_448 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_448 (BatchN (None, 12, 12, 192)  576         conv2d_448[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_448 (Activation)     (None, 12, 12, 192)  0           batch_normalization_448[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_449 (Conv2D)             (None, 12, 12, 192)  258048      activation_448[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_449 (BatchN (None, 12, 12, 192)  576         conv2d_449[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_449 (Activation)     (None, 12, 12, 192)  0           batch_normalization_449[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_446 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_450 (Conv2D)             (None, 12, 12, 192)  258048      activation_449[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_446 (BatchN (None, 12, 12, 192)  576         conv2d_446[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_450 (BatchN (None, 12, 12, 192)  576         conv2d_450[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_446 (Activation)     (None, 12, 12, 192)  0           batch_normalization_446[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_450 (Activation)     (None, 12, 12, 192)  0           batch_normalization_450[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_447 (Conv2D)             (None, 5, 5, 320)    552960      activation_446[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_451 (Conv2D)             (None, 5, 5, 192)    331776      activation_450[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_447 (BatchN (None, 5, 5, 320)    960         conv2d_447[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_451 (BatchN (None, 5, 5, 192)    576         conv2d_451[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_447 (Activation)     (None, 5, 5, 320)    0           batch_normalization_447[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_451 (Activation)     (None, 5, 5, 192)    0           batch_normalization_451[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling2D) (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_447[0][0]             \n",
            "                                                                 activation_451[0][0]             \n",
            "                                                                 max_pooling2d_19[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_456 (Conv2D)             (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_456 (BatchN (None, 5, 5, 448)    1344        conv2d_456[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_456 (Activation)     (None, 5, 5, 448)    0           batch_normalization_456[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_453 (Conv2D)             (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_457 (Conv2D)             (None, 5, 5, 384)    1548288     activation_456[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_453 (BatchN (None, 5, 5, 384)    1152        conv2d_453[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_457 (BatchN (None, 5, 5, 384)    1152        conv2d_457[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_453 (Activation)     (None, 5, 5, 384)    0           batch_normalization_453[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_457 (Activation)     (None, 5, 5, 384)    0           batch_normalization_457[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_454 (Conv2D)             (None, 5, 5, 384)    442368      activation_453[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_455 (Conv2D)             (None, 5, 5, 384)    442368      activation_453[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_458 (Conv2D)             (None, 5, 5, 384)    442368      activation_457[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_459 (Conv2D)             (None, 5, 5, 384)    442368      activation_457[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_43 (AveragePo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_452 (Conv2D)             (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_454 (BatchN (None, 5, 5, 384)    1152        conv2d_454[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_455 (BatchN (None, 5, 5, 384)    1152        conv2d_455[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_458 (BatchN (None, 5, 5, 384)    1152        conv2d_458[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_459 (BatchN (None, 5, 5, 384)    1152        conv2d_459[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_460 (Conv2D)             (None, 5, 5, 192)    245760      average_pooling2d_43[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_452 (BatchN (None, 5, 5, 320)    960         conv2d_452[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_454 (Activation)     (None, 5, 5, 384)    0           batch_normalization_454[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_455 (Activation)     (None, 5, 5, 384)    0           batch_normalization_455[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_458 (Activation)     (None, 5, 5, 384)    0           batch_normalization_458[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_459 (Activation)     (None, 5, 5, 384)    0           batch_normalization_459[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_460 (BatchN (None, 5, 5, 192)    576         conv2d_460[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_452 (Activation)     (None, 5, 5, 320)    0           batch_normalization_452[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_454[0][0]             \n",
            "                                                                 activation_455[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 5, 5, 768)    0           activation_458[0][0]             \n",
            "                                                                 activation_459[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_460 (Activation)     (None, 5, 5, 192)    0           batch_normalization_460[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_452[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_8[0][0]              \n",
            "                                                                 activation_460[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_465 (Conv2D)             (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_465 (BatchN (None, 5, 5, 448)    1344        conv2d_465[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_465 (Activation)     (None, 5, 5, 448)    0           batch_normalization_465[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_462 (Conv2D)             (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_466 (Conv2D)             (None, 5, 5, 384)    1548288     activation_465[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_462 (BatchN (None, 5, 5, 384)    1152        conv2d_462[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_466 (BatchN (None, 5, 5, 384)    1152        conv2d_466[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_462 (Activation)     (None, 5, 5, 384)    0           batch_normalization_462[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_466 (Activation)     (None, 5, 5, 384)    0           batch_normalization_466[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_463 (Conv2D)             (None, 5, 5, 384)    442368      activation_462[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_464 (Conv2D)             (None, 5, 5, 384)    442368      activation_462[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_467 (Conv2D)             (None, 5, 5, 384)    442368      activation_466[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_468 (Conv2D)             (None, 5, 5, 384)    442368      activation_466[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_44 (AveragePo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_461 (Conv2D)             (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_463 (BatchN (None, 5, 5, 384)    1152        conv2d_463[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_464 (BatchN (None, 5, 5, 384)    1152        conv2d_464[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_467 (BatchN (None, 5, 5, 384)    1152        conv2d_467[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_468 (BatchN (None, 5, 5, 384)    1152        conv2d_468[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_469 (Conv2D)             (None, 5, 5, 192)    393216      average_pooling2d_44[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_461 (BatchN (None, 5, 5, 320)    960         conv2d_461[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_463 (Activation)     (None, 5, 5, 384)    0           batch_normalization_463[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_464 (Activation)     (None, 5, 5, 384)    0           batch_normalization_464[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_467 (Activation)     (None, 5, 5, 384)    0           batch_normalization_467[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_468 (Activation)     (None, 5, 5, 384)    0           batch_normalization_468[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_469 (BatchN (None, 5, 5, 192)    576         conv2d_469[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_461 (Activation)     (None, 5, 5, 320)    0           batch_normalization_461[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_463[0][0]             \n",
            "                                                                 activation_464[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 5, 5, 768)    0           activation_467[0][0]             \n",
            "                                                                 activation_468[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_469 (Activation)     (None, 5, 5, 192)    0           batch_normalization_469[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_461[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_9[0][0]              \n",
            "                                                                 activation_469[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_4 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 512)          1049088     global_average_pooling2d_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 2)            1026        dense_8[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 22,852,898\n",
            "Trainable params: 22,818,466\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrJnfPqP3DwS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4a0fc6cd-0512-4d8d-ab74-cff09b7156f6"
      },
      "source": [
        "# training process\n",
        "file_num = 9\n",
        "epoch_num = 5\n",
        "for i in range(file_num):\n",
        "  # load data\n",
        "  myData = DR_resized(True, i, 32, 0.1, (224, 224))\n",
        "  print(\"\\n\\ndata batch %d loaded\" % i)\n",
        "\n",
        "  myModel.train(myData.train_images, myData.train_labels, epochs=epoch_num)\n",
        "  myData.clear()\n",
        "  gc.collect()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "data batch 0 loaded\n",
            "Epoch 1/5\n",
            "4/4 [==============================] - 4s 1s/step - loss: nan - accuracy: 0.4865 - val_loss: nan - val_accuracy: 0.6154\n",
            "Epoch 2/5\n",
            "4/4 [==============================] - 1s 205ms/step - loss: nan - accuracy: 0.4865 - val_loss: nan - val_accuracy: 0.6154\n",
            "Epoch 3/5\n",
            "4/4 [==============================] - 1s 206ms/step - loss: nan - accuracy: 0.4865 - val_loss: nan - val_accuracy: 0.6154\n",
            "Epoch 4/5\n",
            "4/4 [==============================] - 1s 207ms/step - loss: nan - accuracy: 0.4865 - val_loss: nan - val_accuracy: 0.6154\n",
            "Epoch 5/5\n",
            "4/4 [==============================] - 1s 204ms/step - loss: nan - accuracy: 0.4865 - val_loss: nan - val_accuracy: 0.6154\n",
            "\n",
            "\n",
            "data batch 1 loaded\n",
            "Epoch 1/5\n",
            "4/4 [==============================] - 1s 223ms/step - loss: nan - accuracy: 0.5225 - val_loss: nan - val_accuracy: 0.3077\n",
            "Epoch 2/5\n",
            "4/4 [==============================] - 1s 208ms/step - loss: nan - accuracy: 0.5225 - val_loss: nan - val_accuracy: 0.3077\n",
            "Epoch 3/5\n",
            "4/4 [==============================] - 1s 207ms/step - loss: nan - accuracy: 0.5225 - val_loss: nan - val_accuracy: 0.3077\n",
            "Epoch 4/5\n",
            "4/4 [==============================] - 1s 207ms/step - loss: nan - accuracy: 0.5225 - val_loss: nan - val_accuracy: 0.3077\n",
            "Epoch 5/5\n",
            "4/4 [==============================] - 1s 205ms/step - loss: nan - accuracy: 0.5225 - val_loss: nan - val_accuracy: 0.3077\n",
            "\n",
            "\n",
            "data batch 2 loaded\n",
            "Epoch 1/5\n",
            "4/4 [==============================] - 1s 222ms/step - loss: nan - accuracy: 0.5045 - val_loss: nan - val_accuracy: 0.4615\n",
            "Epoch 2/5\n",
            "4/4 [==============================] - 1s 209ms/step - loss: nan - accuracy: 0.5045 - val_loss: nan - val_accuracy: 0.4615\n",
            "Epoch 3/5\n",
            "4/4 [==============================] - 1s 208ms/step - loss: nan - accuracy: 0.5045 - val_loss: nan - val_accuracy: 0.4615\n",
            "Epoch 4/5\n",
            "4/4 [==============================] - 1s 209ms/step - loss: nan - accuracy: 0.5045 - val_loss: nan - val_accuracy: 0.4615\n",
            "Epoch 5/5\n",
            "4/4 [==============================] - 1s 204ms/step - loss: nan - accuracy: 0.5045 - val_loss: nan - val_accuracy: 0.4615\n",
            "\n",
            "\n",
            "data batch 3 loaded\n",
            "Epoch 1/5\n",
            "4/4 [==============================] - 1s 220ms/step - loss: nan - accuracy: 0.4865 - val_loss: nan - val_accuracy: 0.6154\n",
            "Epoch 2/5\n",
            "4/4 [==============================] - 1s 210ms/step - loss: nan - accuracy: 0.4865 - val_loss: nan - val_accuracy: 0.6154\n",
            "Epoch 3/5\n",
            "4/4 [==============================] - 1s 210ms/step - loss: nan - accuracy: 0.4865 - val_loss: nan - val_accuracy: 0.6154\n",
            "Epoch 4/5\n",
            "4/4 [==============================] - 1s 208ms/step - loss: nan - accuracy: 0.4865 - val_loss: nan - val_accuracy: 0.6154\n",
            "Epoch 5/5\n",
            "4/4 [==============================] - 1s 209ms/step - loss: nan - accuracy: 0.4865 - val_loss: nan - val_accuracy: 0.6154\n",
            "\n",
            "\n",
            "data batch 4 loaded\n",
            "Epoch 1/5\n",
            "4/4 [==============================] - 1s 225ms/step - loss: nan - accuracy: 0.5045 - val_loss: nan - val_accuracy: 0.4615\n",
            "Epoch 2/5\n",
            "4/4 [==============================] - 1s 211ms/step - loss: nan - accuracy: 0.5045 - val_loss: nan - val_accuracy: 0.4615\n",
            "Epoch 3/5\n",
            "4/4 [==============================] - 1s 207ms/step - loss: nan - accuracy: 0.5045 - val_loss: nan - val_accuracy: 0.4615\n",
            "Epoch 4/5\n",
            "4/4 [==============================] - 1s 210ms/step - loss: nan - accuracy: 0.5045 - val_loss: nan - val_accuracy: 0.4615\n",
            "Epoch 5/5\n",
            "4/4 [==============================] - 1s 206ms/step - loss: nan - accuracy: 0.5045 - val_loss: nan - val_accuracy: 0.4615\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-1be8064dd7d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mmyData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDR_resized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\ndata batch %d loaded\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-fb2db688ede1>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, is_training, batch_id, batch_size, train_val_split_rate, size)\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0;31m# all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Even_Class_Distribution_Datasets\", \"Processed_Xtrain_Batch%d_even.npy\" % batch_id))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0;31m# all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Color_Even_Class_Distribution_Datasets\", \"Color_Processed_Xtrain_Batch%d_even.npy\" % batch_id))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m       \u001b[0mall_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Processed_Data_Batches\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"04_Only_Color_Even_Class_Distribution_Datasets\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"04_Only_Color_Processed_Xtrain_Batch%d_even.npy\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0;31m# add a dimension for channels if gray scale images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 440\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m             \u001b[0;31m# We can use the fast fromfile() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0;31m# This is not a real file. We have to read it the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0svWpVPkiUsK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5867bbd4-ba93-4446-a9a9-dac21121be66"
      },
      "source": [
        "# testing process\n",
        "file_num = 2\n",
        "num_list = []\n",
        "acc_list = []\n",
        "for i in range(file_num):\n",
        "  myData = DR_resized(False, i, 32, 0.1)\n",
        "  num, acc = myModel.evaluate(myData.test_images, myData.test_labels)\n",
        "  print(num, acc)\n",
        "  num_list.append(num)\n",
        "  acc_list.append(acc)\n",
        "  myData.clear()\n",
        "  gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/10 - 2s - loss: 1.6119 - accuracy: 0.2226\n",
            "310 0.22258064150810242\n",
            "14/14 - 3s - loss: 1.5900 - accuracy: 0.2636\n",
            "440 0.26363635063171387\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqL9za1Dkqjy"
      },
      "source": [
        "# compute overall accuracy\n",
        "num_list = np.array(num_list)\n",
        "acc_list = np.array(acc_list)\n",
        "acc_overall = (num_list * acc_list).sum() / num_list.sum()\n",
        "print(acc_overall)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBuQpdk7vC25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11329b10-2bf3-4f70-e080-94b9837fa877"
      },
      "source": [
        "from datetime import datetime\n",
        "now = datetime.now()\n",
        "dt_string = now.strftime(\"%d-%m-%Y %H:%M:%S\")\n",
        "print(\"date and time =\", dt_string)\n",
        "myModel.save_model(os.path.join(project_root, \"Trained Models\", dt_string))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "date and time = 23-03-2021 19:18:56\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/CS 766 Project/Project Coding and Data Files/Trained Models/23-03-2021 19:18:56/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2QDEecGwGTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "475aaddc-98d7-4ce9-bb79-1748bf08337a"
      },
      "source": [
        "# this part is for loading parameters and extracting features\n",
        "# load parameters\n",
        "parameter_version = \"23-03-2021 19:18:56\"\n",
        "if not os.path.exists(os.path.join(project_root, \"features\", parameter_version)):\n",
        "    os.mkdir(os.path.join(project_root, \"features\", parameter_version))\n",
        "\n",
        "my_model_pretrained = OriginCNN()\n",
        "my_model_pretrained.build()\n",
        "my_model_pretrained.load_model(os.path.join(project_root, \"Trained Models\", parameter_version))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 333, 333, 32)      320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 166, 166, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 55, 55, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 27, 27, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 9, 9, 32)          9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 32)                16416     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 5)                 165       \n",
            "=================================================================\n",
            "Total params: 35,397\n",
            "Trainable params: 35,397\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dC4KT0HjTqe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82e7e0fa-f530-4152-edf2-bf191de684df"
      },
      "source": [
        "# load training data, extract features and save to npy files\n",
        "file_num = 9\n",
        "for i in range(file_num):\n",
        "  myData = DR_resized(True, i, 32, 0.1)\n",
        "  feature = my_model_pretrained.extract_feature(myData.train_images)\n",
        "  # feature = myModel.extract_feature(myData.train_images)\n",
        "  np.save(os.path.join(project_root, \"features\", parameter_version, \"Xtrain_feature%d.npy\" % i), feature)\n",
        "  print(\"Xtrain_feature%d.npy\" % i)\n",
        "  print(feature)\n",
        "  myData.clear()\n",
        "  gc.collect()\n",
        "\n",
        "# load testing data, extract features and save to npy files\n",
        "file_num = 2\n",
        "for i in range(file_num):\n",
        "  myData = DR_resized(False, i, 32, 0.1)\n",
        "  feature = my_model_pretrained.extract_feature(myData.test_images)\n",
        "  np.save(os.path.join(project_root, \"features\", parameter_version, \"Xtest_feature%d.npy\" % i), feature)\n",
        "  print(\"Xtest_feature%d.npy\" % i)\n",
        "  myData.clear()\n",
        "  gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Xtrain_feature0.npy\n",
            "[[0.35830727 0.10113482 0.         ... 0.         0.         0.47119415]\n",
            " [0.35830727 0.04669811 0.         ... 0.         0.         0.200975  ]\n",
            " [0.47821516 0.11293279 0.         ... 0.         0.         0.31759244]\n",
            " ...\n",
            " [0.35830727 0.10821177 0.         ... 0.         0.         0.3621609 ]\n",
            " [0.38736483 0.         0.         ... 0.         0.         0.50423074]\n",
            " [0.35830727 0.12817381 0.         ... 0.         0.         0.16432361]]\n",
            "Xtrain_feature1.npy\n",
            "[[0.31001762 0.08447442 0.         ... 0.         0.         0.54034066]\n",
            " [0.45026395 0.04669811 0.         ... 0.         0.         0.62844735]\n",
            " [0.36011726 0.10609142 0.         ... 0.         0.         0.        ]\n",
            " ...\n",
            " [0.39272144 0.1103986  0.         ... 0.         0.         0.20643379]\n",
            " [0.37816614 0.12638164 0.         ... 0.         0.         0.36818033]\n",
            " [0.48419    0.46840778 0.         ... 0.         0.         1.2397174 ]]\n",
            "Xtrain_feature2.npy\n",
            "[[0.5399451  0.04669811 0.         ... 0.         0.         0.33048525]\n",
            " [0.60250944 0.18666117 0.         ... 0.         0.         0.40565366]\n",
            " [0.27334434 0.14828078 0.         ... 0.         0.         0.452514  ]\n",
            " ...\n",
            " [0.5731983  0.04669811 0.         ... 0.         0.         0.09627229]\n",
            " [0.47941777 0.47430038 0.         ... 0.         0.         0.23661497]\n",
            " [0.37783462 0.09423186 0.         ... 0.         0.         0.24922517]]\n",
            "Xtrain_feature3.npy\n",
            "[[0.32879612 0.         0.         ... 0.         0.         0.4694653 ]\n",
            " [0.6938508  0.05547374 0.         ... 0.         0.         0.91222274]\n",
            " [0.36964494 0.19902071 0.         ... 0.         0.         0.71168756]\n",
            " ...\n",
            " [0.4383259  0.15725595 0.         ... 0.         0.         0.4951031 ]\n",
            " [0.5663408  0.04669811 0.         ... 0.         0.         0.59657353]\n",
            " [0.3189979  0.26821998 0.02016739 ... 0.         0.         0.293995  ]]\n",
            "Xtrain_feature4.npy\n",
            "[[0.5482393  0.08710946 0.         ... 0.         0.         0.5158137 ]\n",
            " [0.35830727 0.09960653 0.         ... 0.         0.         0.54345   ]\n",
            " [0.47943452 0.12549722 0.         ... 0.         0.         0.5850111 ]\n",
            " ...\n",
            " [0.31712344 0.37991413 0.         ... 0.         0.         0.47146785]\n",
            " [0.3831841  0.08544667 0.         ... 0.         0.         0.7459256 ]\n",
            " [0.4939859  0.07166357 0.         ... 0.         0.         0.        ]]\n",
            "Xtrain_feature5.npy\n",
            "[[0.25912037 0.10348704 0.         ... 0.         0.         0.2797989 ]\n",
            " [0.56932783 0.053529   0.         ... 0.         0.         0.7505858 ]\n",
            " [0.34870118 0.04483921 0.         ... 0.         0.         0.547003  ]\n",
            " ...\n",
            " [0.50984347 0.11558133 0.         ... 0.         0.         0.43577933]\n",
            " [0.35830727 0.04669811 0.         ... 0.         0.         0.35837883]\n",
            " [0.35321733 0.04388131 0.         ... 0.         0.         0.63443315]]\n",
            "Xtrain_feature6.npy\n",
            "[[0.3554677  0.2251327  0.         ... 0.         0.         1.0805299 ]\n",
            " [0.34170717 0.10629591 0.         ... 0.         0.         0.16824785]\n",
            " [0.3612893  0.10474242 0.         ... 0.         0.         0.7805975 ]\n",
            " ...\n",
            " [0.5219863  0.22546814 0.         ... 0.         0.         0.7206606 ]\n",
            " [0.52372545 0.19352484 0.         ... 0.         0.         1.0042638 ]\n",
            " [0.47989467 0.11977142 0.         ... 0.         0.         0.89010364]]\n",
            "Xtrain_feature7.npy\n",
            "[[0.46209344 0.04669811 0.         ... 0.         0.         1.5074818 ]\n",
            " [0.35830727 0.14953604 0.         ... 0.         0.         0.7582077 ]\n",
            " [0.6095504  0.09464127 0.         ... 0.         0.         0.19994576]\n",
            " ...\n",
            " [0.8160008  0.06942797 0.         ... 0.         0.         0.40248483]\n",
            " [0.37412393 0.448774   0.         ... 0.         0.         0.27251655]\n",
            " [0.3598394  0.10610101 0.         ... 0.         0.         0.98659545]]\n",
            "Xtrain_feature8.npy\n",
            "[[0.39482647 0.11724132 0.         ... 0.         0.         0.4347384 ]\n",
            " [0.39845127 0.4381626  0.         ... 0.         0.         0.48718914]\n",
            " [0.63168937 0.25750208 0.         ... 0.         0.         1.0495282 ]\n",
            " ...\n",
            " [0.6317685  0.13022763 0.         ... 0.         0.         0.38409802]\n",
            " [0.59687954 0.17956656 0.         ... 0.         0.         1.5910499 ]\n",
            " [0.28515217 0.11274222 0.         ... 0.         0.         0.6627514 ]]\n",
            "Xtest_feature0.npy\n",
            "Xtest_feature1.npy\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}