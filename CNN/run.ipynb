{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "run.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGoAP5Dn3DwQ"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os, re, sys\n",
        "from sklearn.model_selection import train_test_split\n",
        "import skimage.io\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYucCZeH_dHH",
        "outputId": "c507c77b-9413-4991-d52f-c4437253c616"
      },
      "source": [
        "# test if GPUs are available\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUiMh4isCHnS",
        "outputId": "f3dc99b3-70da-4b9d-f628-78368792227b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJQvxwJFDmYk"
      },
      "source": [
        "# set project root, maybe you need to firstly \n",
        "# add shortcut of CS 766 Project to drive.\n",
        "project_root = './drive/MyDrive/CS 766 Project/Project Coding and Data Files'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGJsefpJ-XjF"
      },
      "source": [
        "# class to initialize CNNs\n",
        "class OriginCNN(object):\n",
        "  \"\"\"docstring for OriginCNN\"\"\"\n",
        "  def __init__(self):\n",
        "    # self.optimizer = 'sgd'\n",
        "    self.optimizer = tf.keras.optimizers.SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    # will add more properties\n",
        "\n",
        "\n",
        "  def build(self):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), strides=(3,3), activation='relu', input_shape=(1000, 1000, 1)))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(32, (3, 3), strides=(3,3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(32, (3, 3), strides=(3,3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(32, activation='sigmoid'))\n",
        "    model.add(layers.Dense(5))\n",
        "\n",
        "    model.summary()\n",
        "    model.compile(optimizer=self.optimizer,\n",
        "                loss=self.loss,\n",
        "                metrics=['accuracy'])\n",
        "    self.model = model\n",
        "\n",
        "\n",
        "  def train(self, train_images, train_labels, validate_images, validate_labels, epochs):\n",
        "    self.history = self.model.fit(train_images, train_labels, epochs=epochs, \n",
        "        validation_data=(validate_images, validate_labels))\n",
        "\n",
        "\n",
        "  def evaluate(self, test_images, test_labels):\n",
        "    _, test_acc = self.model.evaluate(test_images, test_labels, verbose=2)\n",
        "    return test_images.shape[0], test_acc\n",
        "\n",
        "  def save_model(self, filepath):\n",
        "    self.model.save(filepath)\n",
        "\n",
        "  def load_model(self, filepath):\n",
        "    self.model = tf.keras.models.load_model(filepath)\n",
        "\n",
        "  def extract_feature(self, images):\n",
        "    extract = models.Model(self.model.inputs, self.model.layers[-3].output)\n",
        "    return extract.predict(images)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3suc98v-bRj"
      },
      "source": [
        "class DR_resized(object):\n",
        "  \"\"\"docstring for DR_resized\"\"\"\n",
        "  def __init__(self, is_training, batch_id):\n",
        "    if(is_training):\n",
        "      # load images\n",
        "      all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Even_Class_Distribution_Datasets\", \"Processed_Xtrain_Batch%d_even.npy\" % batch_id))\n",
        "      # add a dimension for channels\n",
        "      all_images = np.expand_dims(all_images, axis=-1)\n",
        "\n",
        "      # load labels\n",
        "      all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Even Class Distribution Datasets\", \"Ytrain_Batch%d_even.npy\" % batch_id), allow_pickle=True)\n",
        "      all_labels = np.array([item[1] for item in all_labels])\n",
        "      all_labels = np.expand_dims(all_labels, axis=-1)\n",
        "      \n",
        "      self.train_images, self.validate_images, self.train_labels, self.validate_labels \\\n",
        "      = train_test_split(all_images, all_labels, test_size=0.2, random_state=9876)\n",
        "    else:\n",
        "        # load images\n",
        "      all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Even_Class_Distribution_Datasets\", \"Processed_Xtest_Batch%d_even.npy\") % batch_id)\n",
        "      # add a dimension for channels\n",
        "      all_images = np.expand_dims(all_images, axis=-1)\n",
        "\n",
        "      # load labels\n",
        "      all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Even Class Distribution Datasets\", \"Ytest_Batch%d_even.npy\" % batch_id), allow_pickle=True)\n",
        "      all_labels = np.array([item[1] for item in all_labels])\n",
        "      all_labels = np.expand_dims(all_labels, axis=-1)\n",
        "      \n",
        "      self.test_images = all_images\n",
        "      self.test_labels = all_labels\n",
        "  \n",
        "  def clear(self):\n",
        "    self.train_images = None\n",
        "    self.validate_images = None\n",
        "    self.test_images = None\n",
        "    self.train_labels = None\n",
        "    self.validate_labels = None\n",
        "    self.test_labels = None\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOADsxqM3DwR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "995a238b-aae1-4ea8-98e0-5a35e66c217b"
      },
      "source": [
        "# initialize CNN\n",
        "myModel = OriginCNN()\n",
        "myModel.build()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 333, 333, 32)      320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 166, 166, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 55, 55, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 27, 27, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 9, 9, 32)          9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                16416     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 165       \n",
            "=================================================================\n",
            "Total params: 35,397\n",
            "Trainable params: 35,397\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrJnfPqP3DwS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ff26af4-549a-486f-a7cd-c557bceda4ca"
      },
      "source": [
        "# training process\n",
        "file_num = 9\n",
        "epoch_num = 5\n",
        "for i in range(file_num):\n",
        "  myData = DR_resized(True, i)\n",
        "  print(\"data batch %d loaded\" % i)\n",
        "  myModel.train(myData.train_images, myData.train_labels, myData.validate_images, myData.validate_labels, epoch_num)\n",
        "  print(\"data batch %d trained\" % i)\n",
        "  myData.clear()\n",
        "  gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data batch 0 loaded\n",
            "Epoch 1/5\n",
            "8/8 [==============================] - 33s 122ms/step - loss: 1.7316 - accuracy: 0.2242 - val_loss: 1.6324 - val_accuracy: 0.1935\n",
            "Epoch 2/5\n",
            "8/8 [==============================] - 1s 73ms/step - loss: 1.6456 - accuracy: 0.1545 - val_loss: 1.6426 - val_accuracy: 0.1774\n",
            "Epoch 3/5\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 1.6220 - accuracy: 0.1785 - val_loss: 1.6146 - val_accuracy: 0.1935\n",
            "Epoch 4/5\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 1.6197 - accuracy: 0.1742 - val_loss: 1.6177 - val_accuracy: 0.1774\n",
            "Epoch 5/5\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 1.6165 - accuracy: 0.2139 - val_loss: 1.6323 - val_accuracy: 0.1774\n",
            "data batch 0 trained\n",
            "data batch 1 loaded\n",
            "Epoch 1/5\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.6254 - accuracy: 0.2016 - val_loss: 1.6206 - val_accuracy: 0.1774\n",
            "Epoch 2/5\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 1.6142 - accuracy: 0.2016 - val_loss: 1.6260 - val_accuracy: 0.1935\n",
            "Epoch 3/5\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 1.6204 - accuracy: 0.1976 - val_loss: 1.6145 - val_accuracy: 0.1774\n",
            "Epoch 4/5\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 1.6217 - accuracy: 0.1734 - val_loss: 1.6159 - val_accuracy: 0.1774\n",
            "Epoch 5/5\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 1.6313 - accuracy: 0.1855 - val_loss: 1.6206 - val_accuracy: 0.1774\n",
            "data batch 1 trained\n",
            "data batch 2 loaded\n",
            "Epoch 1/5\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.6239 - accuracy: 0.2016 - val_loss: 1.6210 - val_accuracy: 0.1774\n",
            "Epoch 2/5\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 1.6215 - accuracy: 0.1653 - val_loss: 1.6188 - val_accuracy: 0.1774\n",
            "Epoch 3/5\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 1.6263 - accuracy: 0.1734 - val_loss: 1.6135 - val_accuracy: 0.2097\n",
            "Epoch 4/5\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 1.6173 - accuracy: 0.2056 - val_loss: 1.6080 - val_accuracy: 0.1935\n",
            "Epoch 5/5\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 1.6207 - accuracy: 0.1855 - val_loss: 1.6177 - val_accuracy: 0.1774\n",
            "data batch 2 trained\n",
            "data batch 3 loaded\n",
            "Epoch 1/5\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 1.6364 - accuracy: 0.1935 - val_loss: 1.6110 - val_accuracy: 0.1935\n",
            "Epoch 2/5\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 1.6251 - accuracy: 0.1573 - val_loss: 1.6136 - val_accuracy: 0.1774\n",
            "Epoch 3/5\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 1.6195 - accuracy: 0.1976 - val_loss: 1.6274 - val_accuracy: 0.1935\n",
            "Epoch 4/5\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 1.6174 - accuracy: 0.1855 - val_loss: 1.6072 - val_accuracy: 0.2097\n",
            "Epoch 5/5\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 1.6101 - accuracy: 0.2137 - val_loss: 1.6139 - val_accuracy: 0.1452\n",
            "data batch 3 trained\n",
            "data batch 4 loaded\n",
            "Epoch 1/5\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 1.6251 - accuracy: 0.1613 - val_loss: 1.6209 - val_accuracy: 0.1935\n",
            "Epoch 2/5\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 1.6190 - accuracy: 0.2056 - val_loss: 1.6222 - val_accuracy: 0.1774\n",
            "Epoch 3/5\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 1.6201 - accuracy: 0.1694 - val_loss: 1.6193 - val_accuracy: 0.1774\n",
            "Epoch 4/5\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 1.6181 - accuracy: 0.1976 - val_loss: 1.6248 - val_accuracy: 0.1935\n",
            "Epoch 5/5\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 1.6192 - accuracy: 0.1653 - val_loss: 1.6144 - val_accuracy: 0.2258\n",
            "data batch 4 trained\n",
            "data batch 5 loaded\n",
            "Epoch 1/5\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 1.6169 - accuracy: 0.1774 - val_loss: 1.6349 - val_accuracy: 0.1290\n",
            "Epoch 2/5\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 1.6171 - accuracy: 0.1976 - val_loss: 1.6230 - val_accuracy: 0.1935\n",
            "Epoch 3/5\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 1.6190 - accuracy: 0.2097 - val_loss: 1.6129 - val_accuracy: 0.1935\n",
            "Epoch 4/5\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 1.6197 - accuracy: 0.1855 - val_loss: 1.6136 - val_accuracy: 0.2419\n",
            "Epoch 5/5\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 1.6176 - accuracy: 0.1895 - val_loss: 1.6243 - val_accuracy: 0.1613\n",
            "data batch 5 trained\n",
            "data batch 6 loaded\n",
            "Epoch 1/5\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.6241 - accuracy: 0.1653 - val_loss: 1.6141 - val_accuracy: 0.1774\n",
            "Epoch 2/5\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 1.6200 - accuracy: 0.1976 - val_loss: 1.6257 - val_accuracy: 0.2097\n",
            "Epoch 3/5\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 1.6145 - accuracy: 0.2137 - val_loss: 1.6183 - val_accuracy: 0.1935\n",
            "Epoch 4/5\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 1.6130 - accuracy: 0.1895 - val_loss: 1.6195 - val_accuracy: 0.1452\n",
            "Epoch 5/5\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 1.6012 - accuracy: 0.2218 - val_loss: 1.6204 - val_accuracy: 0.1774\n",
            "data batch 6 trained\n",
            "data batch 7 loaded\n",
            "Epoch 1/5\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 1.6219 - accuracy: 0.1653 - val_loss: 1.6194 - val_accuracy: 0.1774\n",
            "Epoch 2/5\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 1.6187 - accuracy: 0.2056 - val_loss: 1.6279 - val_accuracy: 0.1613\n",
            "Epoch 3/5\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 1.6189 - accuracy: 0.2097 - val_loss: 1.6144 - val_accuracy: 0.1774\n",
            "Epoch 4/5\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 1.6054 - accuracy: 0.2339 - val_loss: 1.6172 - val_accuracy: 0.1774\n",
            "Epoch 5/5\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.6000 - accuracy: 0.2419 - val_loss: 1.6152 - val_accuracy: 0.2258\n",
            "data batch 7 trained\n",
            "data batch 8 loaded\n",
            "Epoch 1/5\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.6274 - accuracy: 0.2016 - val_loss: 1.6223 - val_accuracy: 0.2097\n",
            "Epoch 2/5\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 1.6136 - accuracy: 0.1976 - val_loss: 1.6116 - val_accuracy: 0.1935\n",
            "Epoch 3/5\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 1.6038 - accuracy: 0.2056 - val_loss: 1.6117 - val_accuracy: 0.2097\n",
            "Epoch 4/5\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 1.6007 - accuracy: 0.2218 - val_loss: 1.6125 - val_accuracy: 0.2258\n",
            "Epoch 5/5\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 1.5933 - accuracy: 0.2177 - val_loss: 1.5995 - val_accuracy: 0.2258\n",
            "data batch 8 trained\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0svWpVPkiUsK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f139d62-1800-4ba5-eee7-f39a36a9ce5b"
      },
      "source": [
        "# testing process\n",
        "file_num = 2\n",
        "num_list = []\n",
        "acc_list = []\n",
        "for i in range(file_num):\n",
        "  myData = DR_resized(False, i)\n",
        "  num, acc = myModel.evaluate(myData.test_images, myData.test_labels)\n",
        "  print(num, acc)\n",
        "  num_list.append(num)\n",
        "  acc_list.append(acc)\n",
        "  myData.clear()\n",
        "  gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "98/98 - 3s - loss: 0.8625 - accuracy: 0.7354\n",
            "3118 0.735407292842865\n",
            "123/123 - 4s - loss: 0.8743 - accuracy: 0.7312\n",
            "3928 0.7311608791351318\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqL9za1Dkqjy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f96872d5-2f62-4464-df51-e0f2e0f45a8b"
      },
      "source": [
        "# compute overall accuracy\n",
        "num_list = np.array(num_list)\n",
        "acc_list = np.array(acc_list)\n",
        "acc_overall = (num_list * acc_list).sum() / num_list.sum()\n",
        "print(acc_overall)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.733040004587972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBuQpdk7vC25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "687e7799-04ab-4f53-f38e-e295b7a56c72"
      },
      "source": [
        "from datetime import datetime\n",
        "now = datetime.now()\n",
        "dt_string = now.strftime(\"%d-%m-%Y %H:%M:%S\")\n",
        "print(\"date and time =\", dt_string)\n",
        "myModel.save_model(os.path.join(project_root, \"Trained Models\", dt_string))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "date and time = 16-03-2021 01:13:01\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/CS 766 Project/Project Coding and Data Files/Trained Models/16-03-2021 01:13:01/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2QDEecGwGTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df61b508-7425-4ee4-cb0e-a10fba35724f"
      },
      "source": [
        "# this part is for loading parameters and extracting features\n",
        "# load parameters\n",
        "parameter_version = \"16-03-2021 01:13:01\"\n",
        "if not os.path.exists(os.path.join(project_root, \"features\", parameter_version)):\n",
        "    os.mkdir(os.path.join(project_root, \"features\", parameter_version))\n",
        "\n",
        "my_model_pretrained = OriginCNN()\n",
        "my_model_pretrained.build()\n",
        "my_model_pretrained.load_model(os.path.join(project_root, \"Trained Models\", parameter_version))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_30 (Conv2D)           (None, 333, 333, 32)      320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_30 (MaxPooling (None, 166, 166, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 55, 55, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_31 (MaxPooling (None, 27, 27, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 9, 9, 32)          9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_32 (MaxPooling (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 32)                16416     \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 5)                 165       \n",
            "=================================================================\n",
            "Total params: 35,397\n",
            "Trainable params: 35,397\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dC4KT0HjTqe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16e00304-8255-4fb3-eeb4-a1adf2a6da70"
      },
      "source": [
        "# load training data, extract features and save to npy files\n",
        "file_num = 9\n",
        "for i in range(file_num):\n",
        "  myData = DR_resized(True, i)\n",
        "  feature = my_model_pretrained.extract_feature(myData.train_images)\n",
        "  np.save(os.path.join(project_root, \"features\", parameter_version, \"Xtrain_feature%d.npy\" % i), feature)\n",
        "  print(\"Xtrain_feature%d.npy\" % i)\n",
        "  myData.clear()\n",
        "  gc.collect()\n",
        "\n",
        "# load testing data, extract features and save to npy files\n",
        "file_num = 2\n",
        "for i in range(file_num):\n",
        "  myData = DR_resized(False, i)\n",
        "  feature = my_model_pretrained.extract_feature(myData.test_images)\n",
        "  np.save(os.path.join(project_root, \"features\", parameter_version, \"Xtest_feature%d.npy\" % i), feature)\n",
        "  print(\"Xtest_feature%d.npy\" % i)\n",
        "  myData.clear()\n",
        "  gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Xtrain_feature0.npy\n",
            "Xtrain_feature1.npy\n",
            "Xtrain_feature2.npy\n",
            "Xtrain_feature3.npy\n",
            "Xtrain_feature4.npy\n",
            "Xtrain_feature5.npy\n",
            "Xtrain_feature6.npy\n",
            "Xtrain_feature7.npy\n",
            "Xtrain_feature8.npy\n",
            "Xtest_feature0.npy\n",
            "Xtest_feature1.npy\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}