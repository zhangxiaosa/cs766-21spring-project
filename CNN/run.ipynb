{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "run.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGoAP5Dn3DwQ"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os, re, sys\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import gc\n",
        "import skimage.transform"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYucCZeH_dHH",
        "outputId": "1a331718-49fe-4e51-93f6-028fa736a6bf"
      },
      "source": [
        "# test if GPUs are available\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUiMh4isCHnS",
        "outputId": "9a10bf98-7a55-44c1-ac75-d5e71e78be2c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJQvxwJFDmYk"
      },
      "source": [
        "# set project root, maybe you need to firstly \n",
        "# add shortcut of CS 766 Project to drive.\n",
        "project_root = './drive/MyDrive/CS 766 Project/Project Coding and Data Files'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGJsefpJ-XjF"
      },
      "source": [
        "# class to initialize CNNs\n",
        "class OriginCNN(object):\n",
        "  \"\"\"docstring for OriginCNN\"\"\"\n",
        "  def __init__(self):\n",
        "    self.optimizer = 'adam'\n",
        "    # self.optimizer = tf.keras.optimizers.SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "    # self.loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    # will add more properties\n",
        "\n",
        "\n",
        "  def build(self):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), strides=(3,3), activation='relu', input_shape=(1000, 1000, 1)))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(32, (3, 3), strides=(3,3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(32, (3, 3), strides=(3,3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(32, activation='relu'))\n",
        "    model.add(layers.Dense(5))\n",
        "\n",
        "    model.summary()\n",
        "    model.compile(optimizer=self.optimizer,\n",
        "                loss=self.loss,\n",
        "                metrics=['accuracy'])\n",
        "    self.model = model\n",
        "\n",
        "\n",
        "  def train(self, train_images, train_labels, epochs):\n",
        "    self.history = self.model.fit(train_images, train_labels, epochs=epochs, validation_split=0.1)\n",
        "    return self.history\n",
        "\n",
        "  def train_on_batch(self, train_images, train_labels):\n",
        "    return self.model.train_on_batch(train_images, train_labels)\n",
        "\n",
        "  def predict(self, test_images):\n",
        "    return self.model.predict(test_images)\n",
        "\n",
        "\n",
        "  def evaluate(self, test_images, test_labels):\n",
        "    _, test_acc = self.model.evaluate(test_images, test_labels, verbose=2)\n",
        "    return test_images.shape[0], test_acc\n",
        "\n",
        "  def save_model(self, filepath):\n",
        "    self.model.save(filepath)\n",
        "\n",
        "  def load_model(self, filepath):\n",
        "    self.model = tf.keras.models.load_model(filepath)\n",
        "\n",
        "  def extract_feature(self, images):\n",
        "    extract = models.Model(self.model.inputs, self.model.layers[-3].output)\n",
        "    return extract.predict(images)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSiCn4VzdaV8"
      },
      "source": [
        "from tensorflow.keras.applications import ResNet50, InceptionV3, VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "class Res50(object):\n",
        "  \"\"\"docstring for OriginCNN\"\"\"\n",
        "  def __init__(self):\n",
        "    self.optimizer = 'adam'\n",
        "    # self.optimizer = tf.keras.optimizers.SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "    # self.loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    # will add more properties\n",
        "\n",
        "\n",
        "  def build(self):\n",
        "    base_model = InceptionV3(\n",
        "      include_top=False,\n",
        "      weights=\"imagenet\",\n",
        "      input_shape=(224, 224, 3)\n",
        "    )\n",
        "\n",
        "    # add a global spatial average pooling layer\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    # let's add a fully-connected layer\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    # and a logistic layer -- let's say we have n classes\n",
        "    predictions = Dense(2)(x)\n",
        "\n",
        "    # this is the model we will train\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "\n",
        "    model.summary()\n",
        "    model.compile(optimizer=self.optimizer,\n",
        "                loss=self.loss,\n",
        "                metrics=['accuracy'])\n",
        "    self.model = model\n",
        "\n",
        "\n",
        "  def train(self, train_images, train_labels, epochs):\n",
        "    self.history = self.model.fit(train_images, train_labels, epochs=epochs, validation_split=0.1)\n",
        "    return self.history\n",
        "\n",
        "  def train_on_batch(self, train_images, train_labels):\n",
        "    return self.model.train_on_batch(train_images, train_labels)\n",
        "\n",
        "  def predict(self, test_images):\n",
        "    return self.model.predict(test_images)\n",
        "\n",
        "\n",
        "  def evaluate(self, test_images, test_labels):\n",
        "    _, test_acc = self.model.evaluate(test_images, test_labels, verbose=2)\n",
        "    return test_images.shape[0], test_acc\n",
        "\n",
        "  def save_model(self, filepath):\n",
        "    self.model.save(filepath)\n",
        "\n",
        "  def load_model(self, filepath):\n",
        "    self.model = tf.keras.models.load_model(filepath)\n",
        "\n",
        "  def extract_feature(self, images):\n",
        "    extract = models.Model(self.model.inputs, self.model.layers[-2].output)\n",
        "    return extract.predict(images)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3suc98v-bRj"
      },
      "source": [
        "class DR_resized(object):\n",
        "  \"\"\"docstring for DR_resized\"\"\"\n",
        "  def __init__(self, is_training, batch_id, batch_size, train_val_split_rate, size=None):\n",
        "    self.batch_size = batch_size\n",
        "    self.train_val_split_rate = train_val_split_rate\n",
        "    if(is_training):\n",
        "      # load images\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Stratified_Random_Sampling_Datasets\", \"Processed_Xtrain_Batch%d.npy\" % batch_id))\n",
        "      all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Even_Class_Distribution_Datasets\", \"Processed_Xtrain_Batch%d_even.npy\" % batch_id))\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Color_Even_Class_Distribution_Datasets\", \"Color_Processed_Xtrain_Batch%d_even.npy\" % batch_id))\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"04_Only_Color_Even_Class_Distribution_Datasets\", \"Xtrain\", \"04_Only_Color_Processed_Xtrain_Batch%d_even.npy\" % batch_id))\n",
        "      \n",
        "      # add a dimension for channels if gray scale images\n",
        "      if (len(all_images[0].shape) == 2):\n",
        "        all_images = np.expand_dims(all_images, axis=-1)\n",
        "\n",
        "      # resize\n",
        "      # gray scale\n",
        "      if(size):\n",
        "        if (len(all_images[0].shape) == 2):\n",
        "          all_images_resize = np.zeros((all_images.shape[0], size[0], size[1], 1));\n",
        "          for i in range(all_images.shape[0]):\n",
        "            all_images_resize[i] = skimage.transform.resize(all_images[i].astype('float64'), (size[0], size[1]));\n",
        "        # color image\n",
        "        else:\n",
        "          all_images_resize = np.zeros((all_images.shape[0], size[0], size[1], 3));\n",
        "          for i in range(all_images.shape[0]):\n",
        "            all_images_resize[i] = skimage.transform.resize(all_images[i].astype('float64'), (size[0], size[1]));\n",
        "        all_images = all_images_resize\n",
        "\n",
        "\n",
        "      # load labels\n",
        "      # all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Stratified Random Sampling Datasets\", \"Ytrain\", \"Ytrain_Batch%d.npy\" % batch_id), allow_pickle=True)\n",
        "      all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Even Class Distribution Datasets\", \"Ytrain\", \"Ytrain_Batch%d_even.npy\" % batch_id), allow_pickle=True)\n",
        "      # all_labels = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"04_Only_Color_Even_Class_Distribution_Datasets\", \"Ytrain\", \"04_Only_Ytrain_Batch%d_even.npy\" % batch_id), allow_pickle=True)\n",
        "      all_labels = np.array([item[1] for item in all_labels])\n",
        "      \n",
        "      # one hot\n",
        "      # all_labels_one_hot = np.zeros((all_labels.size, 5))\n",
        "      # all_labels_one_hot[np.arange(all_labels.size),all_labels] = 1\n",
        "\n",
        "      # without one hot\n",
        "      all_labels_one_hot = np.expand_dims(all_labels, axis=-1)\n",
        "\n",
        "      # shuffle\n",
        "      np.random.seed(0);\n",
        "      indices = np.arange(all_images.shape[0])\n",
        "      np.random.shuffle(indices)\n",
        "      all_images = all_images[indices]\n",
        "      all_labels_one_hot = all_labels_one_hot[indices]\n",
        "\n",
        "      self.train_images = all_images\n",
        "      self.train_labels = all_labels_one_hot\n",
        "    \n",
        "    else:\n",
        "      # load images\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Stratified_Random_Sampling_Datasets\", \"Processed_Xtest_Batch%d.npy\") % batch_id)\n",
        "      all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Even_Class_Distribution_Datasets\", \"Processed_Xest_Batch%d_even.npy\") % batch_id)\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Color_Even_Class_Distribution_Datasets\", \"Color_Processed_Xest_Batch%d_even.npy\") % batch_id)\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"04_Only_Color_Even_Class_Distribution_Datasets\", \"Xest\", \"04_Only_Color_Processed_Xest_Batch%d_even.npy\" % batch_id))\n",
        "      \n",
        "      # add a dimension for channels if gray scale images\n",
        "      if (len(all_images[0].shape) == 2):\n",
        "        all_images = np.expand_dims(all_images, axis=-1)\n",
        "\n",
        "      # resize\n",
        "      if(size):\n",
        "        # gray scale\n",
        "        if (len(all_images[0].shape) == 2):\n",
        "          all_images_resize = np.zeros((all_images.shape[0], size[0], size[1], 1));\n",
        "          for i in range(all_images.shape[0]):\n",
        "            all_images_resize[i] = skimage.transform.resize(all_images[i].astype('float64'), (size[0], size[1]));\n",
        "        # color image\n",
        "        else:\n",
        "          all_images_resize = np.zeros((all_images.shape[0], size[0], size[1], 3));\n",
        "          for i in range(all_images.shape[0]):\n",
        "            all_images_resize[i] = skimage.transform.resize(all_images[i].astype('float64'), (size[0], size[1]));\n",
        "        all_images = all_images_resize\n",
        "\n",
        "\n",
        "      # load labels\n",
        "      # all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Stratified Random Sampling Datasets\", \"Ytest\", \"Ytest_Batch%d.npy\" % batch_id), allow_pickle=True)\n",
        "      all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Even Class Distribution Datasets\", \"Ytest\", \"Yest_Batch%d_even.npy\" % batch_id), allow_pickle=True)\n",
        "      # all_labels = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"04_Only_Color_Even_Class_Distribution_Datasets\", \"Yest\", \"04_Only_Yest_Batch%d_even.npy\" % batch_id), allow_pickle=True)\n",
        "      all_labels = np.array([item[1] for item in all_labels])\n",
        "\n",
        "      # one hot\n",
        "      # all_labels_one_hot = np.zeros((all_labels.size, 5))\n",
        "      # all_labels_one_hot[np.arange(all_labels.size),all_labels] = 1\n",
        "\n",
        "      # without one hot\n",
        "      all_labels_one_hot = np.expand_dims(all_labels, axis=-1)\n",
        "      \n",
        "      self.test_images = all_images\n",
        "      self.test_labels = all_labels_one_hot\n",
        "  \n",
        "  def clear(self):\n",
        "    self.train_images = None\n",
        "    self.validate_images = None\n",
        "    self.test_images = None\n",
        "    self.train_labels = None\n",
        "    self.validate_labels = None\n",
        "    self.test_labels = None\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L57sy6Z02c-"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class Cifar(object):\n",
        "  \"\"\"docstring for DR_resized\"\"\"\n",
        "  def __init__(self, is_training, batch_id, batch_size, train_val_split_rate):\n",
        "    self.batch_size = batch_size\n",
        "    self.train_val_split_rate = train_val_split_rate\n",
        "\n",
        "    if(is_training):\n",
        "      # load images\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Stratified_Random_Sampling_Datasets\", \"Processed_Xtrain_Batch%d.npy\" % batch_id))\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Even_Class_Distribution_Datasets\", \"Processed_Xtrain_Batch%d_even.npy\" % batch_id))\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Color_Even_Class_Distribution_Datasets\", \"Color_Processed_Xtrain_Batch%d_even.npy\" % batch_id))\n",
        "      \n",
        "      # add a dimension for channels if gray scale images\n",
        "      # if (len(all_images[0].shape) == 2):\n",
        "        # all_images = np.expand_dims(all_images, axis=-1)\n",
        "\n",
        "      # load labels\n",
        "      # all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Stratified Random Sampling Datasets\", \"Ytrain\", \"Ytrain_Batch%d.npy\" % batch_id), allow_pickle=True)\n",
        "      # all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Even Class Distribution Datasets\", \"Ytrain\", \"Ytrain_Batch%d_even.npy\" % batch_id), allow_pickle=True)\n",
        "      # all_labels = np.array([item[1] for item in all_labels])\n",
        "\n",
        "      (train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "      train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "      all_images = train_images\n",
        "      all_labels = train_labels\n",
        "      \n",
        "      # one hot\n",
        "      # all_labels_one_hot = np.zeros((all_labels.size, 10))\n",
        "      # all_labels_one_hot[np.arange(all_labels.size),all_labels] = 1\n",
        "\n",
        "      # without one hot\n",
        "      all_labels_one_hot = np.expand_dims(all_labels, axis=-1)\n",
        "\n",
        "      # shuffle\n",
        "      indices = np.arange(all_images.shape[0])\n",
        "      np.random.shuffle(indices)\n",
        "      all_images = all_images[indices]\n",
        "      all_labels_one_hot = all_labels_one_hot[indices]\n",
        "\n",
        "      self.train_images = all_images\n",
        "      self.train_labels = all_labels_one_hot\n",
        "    \n",
        "    else:\n",
        "      # load images\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Stratified_Random_Sampling_Datasets\", \"Processed_Xtest_Batch%d.npy\") % batch_id)\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Even_Class_Distribution_Datasets\", \"Processed_Xest_Batch%d_even.npy\") % batch_id)\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Color_Even_Class_Distribution_Datasets\", \"Color_Processed_Xest_Batch%d_even.npy\") % batch_id)\n",
        "      \n",
        "      # add a dimension for channels if gray scale images\n",
        "      # if (len(all_images[0].shape) == 2):\n",
        "      #   all_images = np.expand_dims(all_images, axis=-1)\n",
        "\n",
        "      # load labels\n",
        "      # all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Stratified Random Sampling Datasets\", \"Ytest\", \"Ytest_Batch%d.npy\" % batch_id), allow_pickle=True)\n",
        "      # all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Even Class Distribution Datasets\", \"Ytest\", \"Yest_Batch%d_even.npy\" % batch_id), allow_pickle=True)\n",
        "      # all_labels = np.array([item[1] for item in all_labels])\n",
        "\n",
        "      (train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "      train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "      all_images = test_images\n",
        "      all_labels = test_labels\n",
        "\n",
        "      # one hot\n",
        "      all_labels_one_hot = np.zeros((all_labels.size, 10))\n",
        "      all_labels_one_hot[np.arange(all_labels.size),all_labels] = 1\n",
        "\n",
        "      # without one hot\n",
        "      # all_labels = np.expand_dims(all_labels, axis=-1)\n",
        "      \n",
        "      self.test_images = all_images\n",
        "      self.test_labels = all_labels_one_hot\n",
        "  \n",
        "  def clear(self):\n",
        "    self.train_images = None\n",
        "    self.validate_images = None\n",
        "    self.test_images = None\n",
        "    self.train_labels = None\n",
        "    self.validate_labels = None\n",
        "    self.test_labels = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOADsxqM3DwR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23f5587c-f71a-4ccf-c821-caa5c46423f7"
      },
      "source": [
        "# initialize CNN\n",
        "myModel = OriginCNN()\n",
        "# myModel = Res50()\n",
        "myModel.build()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 333, 333, 32)      320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 166, 166, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 55, 55, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 27, 27, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 9, 9, 32)          9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                16416     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 165       \n",
            "=================================================================\n",
            "Total params: 35,397\n",
            "Trainable params: 35,397\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrJnfPqP3DwS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91762f19-097e-4db9-da15-869cdfb5f886"
      },
      "source": [
        "# training process\n",
        "file_num = 9\n",
        "epoch_num = 30\n",
        "history_array = np.zeros((file_num, epoch_num, 4))\n",
        "for epoch in range(epoch_num):\n",
        "  print(\"\\n\\nstart epoch %d\" % epoch)\n",
        "  for i in range(file_num):\n",
        "    # load data\n",
        "    # myData = DR_resized(True, i, 32, 0.1, (224, 224))\n",
        "    myData = DR_resized(True, i, 32, 0.1)\n",
        "    print(\"data batch %d loaded\" % i)\n",
        "\n",
        "    history = myModel.train(myData.train_images, myData.train_labels, epochs=1)\n",
        "    history_array[i, epoch, 0] = history.history['loss'][0]\n",
        "    history_array[i, epoch, 1] = history.history['accuracy'][0]\n",
        "    history_array[i, epoch, 2] = history.history['val_loss'][0]\n",
        "    history_array[i, epoch, 3] = history.history['val_accuracy'][0]\n",
        "    myData.clear()\n",
        "    gc.collect()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "start epoch 0\n",
            "data batch 0 loaded\n",
            "9/9 [==============================] - 33s 110ms/step - loss: 1.6461 - accuracy: 0.1524 - val_loss: 1.6075 - val_accuracy: 0.2258\n",
            "data batch 1 loaded\n",
            "9/9 [==============================] - 1s 74ms/step - loss: 1.6111 - accuracy: 0.1864 - val_loss: 1.6127 - val_accuracy: 0.1935\n",
            "data batch 2 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 1.6096 - accuracy: 0.2186 - val_loss: 1.6140 - val_accuracy: 0.2258\n",
            "data batch 3 loaded\n",
            "9/9 [==============================] - 1s 74ms/step - loss: 1.6090 - accuracy: 0.2222 - val_loss: 1.6140 - val_accuracy: 0.0968\n",
            "data batch 4 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 1.6124 - accuracy: 0.1577 - val_loss: 1.6098 - val_accuracy: 0.2258\n",
            "data batch 5 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 1.6100 - accuracy: 0.2151 - val_loss: 1.6170 - val_accuracy: 0.1290\n",
            "data batch 6 loaded\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 1.6096 - accuracy: 0.2151 - val_loss: 1.6132 - val_accuracy: 0.1290\n",
            "data batch 7 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 1.6094 - accuracy: 0.2079 - val_loss: 1.6173 - val_accuracy: 0.1290\n",
            "data batch 8 loaded\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 1.6092 - accuracy: 0.2079 - val_loss: 1.6161 - val_accuracy: 0.1290\n",
            "\n",
            "\n",
            "start epoch 1\n",
            "data batch 0 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 1.6101 - accuracy: 0.1971 - val_loss: 1.6140 - val_accuracy: 0.2258\n",
            "data batch 1 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 1.6114 - accuracy: 0.2043 - val_loss: 1.6102 - val_accuracy: 0.2258\n",
            "data batch 2 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 1.6087 - accuracy: 0.2258 - val_loss: 1.6139 - val_accuracy: 0.1613\n",
            "data batch 3 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 1.6084 - accuracy: 0.2258 - val_loss: 1.6136 - val_accuracy: 0.1290\n",
            "data batch 4 loaded\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 1.6085 - accuracy: 0.2115 - val_loss: 1.6107 - val_accuracy: 0.1290\n",
            "data batch 5 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 1.6081 - accuracy: 0.2186 - val_loss: 1.6124 - val_accuracy: 0.1290\n",
            "data batch 6 loaded\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 1.6077 - accuracy: 0.2043 - val_loss: 1.6108 - val_accuracy: 0.1290\n",
            "data batch 7 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 1.6066 - accuracy: 0.2043 - val_loss: 1.6215 - val_accuracy: 0.0968\n",
            "data batch 8 loaded\n",
            "9/9 [==============================] - 1s 74ms/step - loss: 1.6058 - accuracy: 0.2186 - val_loss: 1.6123 - val_accuracy: 0.2581\n",
            "\n",
            "\n",
            "start epoch 2\n",
            "data batch 0 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 1.6056 - accuracy: 0.2258 - val_loss: 1.6095 - val_accuracy: 0.0968\n",
            "data batch 1 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 1.6138 - accuracy: 0.2222 - val_loss: 1.6096 - val_accuracy: 0.1613\n",
            "data batch 2 loaded\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 1.6038 - accuracy: 0.2258 - val_loss: 1.6154 - val_accuracy: 0.1290\n",
            "data batch 3 loaded\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 1.6060 - accuracy: 0.2115 - val_loss: 1.5967 - val_accuracy: 0.1935\n",
            "data batch 4 loaded\n",
            "9/9 [==============================] - 1s 68ms/step - loss: 1.6023 - accuracy: 0.2401 - val_loss: 1.6029 - val_accuracy: 0.2258\n",
            "data batch 5 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 1.5913 - accuracy: 0.2724 - val_loss: 1.5802 - val_accuracy: 0.2581\n",
            "data batch 6 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 1.6306 - accuracy: 0.1864 - val_loss: 1.6479 - val_accuracy: 0.2258\n",
            "data batch 7 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 1.6032 - accuracy: 0.2473 - val_loss: 1.6228 - val_accuracy: 0.2903\n",
            "data batch 8 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 1.6058 - accuracy: 0.2473 - val_loss: 1.6150 - val_accuracy: 0.1290\n",
            "\n",
            "\n",
            "start epoch 3\n",
            "data batch 0 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 1.6011 - accuracy: 0.2366 - val_loss: 1.5988 - val_accuracy: 0.2903\n",
            "data batch 1 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 1.6017 - accuracy: 0.2652 - val_loss: 1.6059 - val_accuracy: 0.2581\n",
            "data batch 2 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 1.5988 - accuracy: 0.2616 - val_loss: 1.5926 - val_accuracy: 0.2903\n",
            "data batch 3 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 1.5927 - accuracy: 0.2724 - val_loss: 1.5972 - val_accuracy: 0.2903\n",
            "data batch 4 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 1.5902 - accuracy: 0.2688 - val_loss: 1.5899 - val_accuracy: 0.3548\n",
            "data batch 5 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 1.5793 - accuracy: 0.2760 - val_loss: 1.5678 - val_accuracy: 0.2581\n",
            "data batch 6 loaded\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 1.5958 - accuracy: 0.2258 - val_loss: 1.5815 - val_accuracy: 0.3548\n",
            "data batch 7 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 1.5837 - accuracy: 0.2867 - val_loss: 1.6297 - val_accuracy: 0.0968\n",
            "data batch 8 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 1.5914 - accuracy: 0.2724 - val_loss: 1.6107 - val_accuracy: 0.1935\n",
            "\n",
            "\n",
            "start epoch 4\n",
            "data batch 0 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 1.5834 - accuracy: 0.2545 - val_loss: 1.5647 - val_accuracy: 0.2903\n",
            "data batch 1 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 1.5900 - accuracy: 0.2437 - val_loss: 1.5981 - val_accuracy: 0.2581\n",
            "data batch 2 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 1.5634 - accuracy: 0.3082 - val_loss: 1.5805 - val_accuracy: 0.1290\n",
            "data batch 3 loaded\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 1.5642 - accuracy: 0.2867 - val_loss: 1.5824 - val_accuracy: 0.2903\n",
            "data batch 4 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 1.5422 - accuracy: 0.3441 - val_loss: 1.5435 - val_accuracy: 0.3548\n",
            "data batch 5 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 1.5070 - accuracy: 0.3477 - val_loss: 1.4979 - val_accuracy: 0.3871\n",
            "data batch 6 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 1.5453 - accuracy: 0.3118 - val_loss: 1.4795 - val_accuracy: 0.3226\n",
            "data batch 7 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 1.5541 - accuracy: 0.2760 - val_loss: 1.6391 - val_accuracy: 0.1935\n",
            "data batch 8 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 1.5402 - accuracy: 0.3082 - val_loss: 1.6181 - val_accuracy: 0.2258\n",
            "\n",
            "\n",
            "start epoch 5\n",
            "data batch 0 loaded\n",
            "9/9 [==============================] - 1s 74ms/step - loss: 1.5408 - accuracy: 0.3011 - val_loss: 1.5012 - val_accuracy: 0.3871\n",
            "data batch 1 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 1.5412 - accuracy: 0.3190 - val_loss: 1.5729 - val_accuracy: 0.2903\n",
            "data batch 2 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 1.5174 - accuracy: 0.3082 - val_loss: 1.5554 - val_accuracy: 0.1935\n",
            "data batch 3 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 1.5131 - accuracy: 0.3441 - val_loss: 1.5982 - val_accuracy: 0.2903\n",
            "data batch 4 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 1.5008 - accuracy: 0.3297 - val_loss: 1.5289 - val_accuracy: 0.2581\n",
            "data batch 5 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 1.4609 - accuracy: 0.3728 - val_loss: 1.6269 - val_accuracy: 0.2258\n",
            "data batch 6 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 1.5036 - accuracy: 0.3441 - val_loss: 1.5364 - val_accuracy: 0.3548\n",
            "data batch 7 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 1.4758 - accuracy: 0.4122 - val_loss: 1.6050 - val_accuracy: 0.2581\n",
            "data batch 8 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 1.4809 - accuracy: 0.3943 - val_loss: 1.6150 - val_accuracy: 0.2581\n",
            "\n",
            "\n",
            "start epoch 6\n",
            "data batch 0 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 1.4683 - accuracy: 0.3548 - val_loss: 1.4914 - val_accuracy: 0.3226\n",
            "data batch 1 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 1.4902 - accuracy: 0.3728 - val_loss: 1.5487 - val_accuracy: 0.2903\n",
            "data batch 2 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 1.5090 - accuracy: 0.3333 - val_loss: 1.6421 - val_accuracy: 0.2903\n",
            "data batch 3 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 1.5026 - accuracy: 0.3513 - val_loss: 1.6510 - val_accuracy: 0.2258\n",
            "data batch 4 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 1.4520 - accuracy: 0.4158 - val_loss: 1.5591 - val_accuracy: 0.3226\n",
            "data batch 5 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 1.3894 - accuracy: 0.4050 - val_loss: 1.5482 - val_accuracy: 0.3548\n",
            "data batch 6 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 1.4265 - accuracy: 0.3763 - val_loss: 1.5694 - val_accuracy: 0.1935\n",
            "data batch 7 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 1.4028 - accuracy: 0.3799 - val_loss: 1.7860 - val_accuracy: 0.1613\n",
            "data batch 8 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 1.3872 - accuracy: 0.4480 - val_loss: 1.6321 - val_accuracy: 0.2581\n",
            "\n",
            "\n",
            "start epoch 7\n",
            "data batch 0 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 1.4075 - accuracy: 0.4229 - val_loss: 1.5376 - val_accuracy: 0.2581\n",
            "data batch 1 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 1.3817 - accuracy: 0.4301 - val_loss: 1.5683 - val_accuracy: 0.2903\n",
            "data batch 2 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 1.4239 - accuracy: 0.3871 - val_loss: 1.4921 - val_accuracy: 0.2581\n",
            "data batch 3 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 1.4036 - accuracy: 0.4122 - val_loss: 1.6747 - val_accuracy: 0.2903\n",
            "data batch 4 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 1.3476 - accuracy: 0.4624 - val_loss: 1.6114 - val_accuracy: 0.1935\n",
            "data batch 5 loaded\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 1.3032 - accuracy: 0.4803 - val_loss: 1.4862 - val_accuracy: 0.4194\n",
            "data batch 6 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 1.3595 - accuracy: 0.4265 - val_loss: 1.7005 - val_accuracy: 0.2581\n",
            "data batch 7 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 1.3153 - accuracy: 0.4839 - val_loss: 2.0166 - val_accuracy: 0.0968\n",
            "data batch 8 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 1.3325 - accuracy: 0.4624 - val_loss: 1.6155 - val_accuracy: 0.3548\n",
            "\n",
            "\n",
            "start epoch 8\n",
            "data batch 0 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 1.2617 - accuracy: 0.5412 - val_loss: 1.6211 - val_accuracy: 0.3226\n",
            "data batch 1 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 1.2583 - accuracy: 0.4301 - val_loss: 1.5845 - val_accuracy: 0.3226\n",
            "data batch 2 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 1.3164 - accuracy: 0.4767 - val_loss: 1.5152 - val_accuracy: 0.2903\n",
            "data batch 3 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 1.3196 - accuracy: 0.4480 - val_loss: 1.8672 - val_accuracy: 0.2258\n",
            "data batch 4 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 1.2711 - accuracy: 0.4803 - val_loss: 1.6422 - val_accuracy: 0.1935\n",
            "data batch 5 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 1.1711 - accuracy: 0.5627 - val_loss: 1.5222 - val_accuracy: 0.2903\n",
            "data batch 6 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 1.1799 - accuracy: 0.5376 - val_loss: 1.8244 - val_accuracy: 0.2258\n",
            "data batch 7 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 1.1260 - accuracy: 0.5627 - val_loss: 1.9689 - val_accuracy: 0.2258\n",
            "data batch 8 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 1.1585 - accuracy: 0.5054 - val_loss: 1.6816 - val_accuracy: 0.2903\n",
            "\n",
            "\n",
            "start epoch 9\n",
            "data batch 0 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 1.1560 - accuracy: 0.5269 - val_loss: 1.7124 - val_accuracy: 0.3226\n",
            "data batch 1 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 1.0937 - accuracy: 0.5806 - val_loss: 1.6073 - val_accuracy: 0.3871\n",
            "data batch 2 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 1.1202 - accuracy: 0.5627 - val_loss: 1.5436 - val_accuracy: 0.3871\n",
            "data batch 3 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 1.1576 - accuracy: 0.5520 - val_loss: 1.9396 - val_accuracy: 0.2581\n",
            "data batch 4 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 1.1111 - accuracy: 0.5305 - val_loss: 1.9280 - val_accuracy: 0.0645\n",
            "data batch 5 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 1.0567 - accuracy: 0.5806 - val_loss: 1.6383 - val_accuracy: 0.1935\n",
            "data batch 6 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 1.0218 - accuracy: 0.6057 - val_loss: 1.8771 - val_accuracy: 0.1935\n",
            "data batch 7 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.9346 - accuracy: 0.6595 - val_loss: 2.0689 - val_accuracy: 0.2903\n",
            "data batch 8 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.9776 - accuracy: 0.6129 - val_loss: 1.7250 - val_accuracy: 0.3871\n",
            "\n",
            "\n",
            "start epoch 10\n",
            "data batch 0 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.9927 - accuracy: 0.6344 - val_loss: 1.9966 - val_accuracy: 0.2903\n",
            "data batch 1 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.9889 - accuracy: 0.5950 - val_loss: 1.7150 - val_accuracy: 0.2903\n",
            "data batch 2 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 1.0589 - accuracy: 0.6022 - val_loss: 1.5547 - val_accuracy: 0.4194\n",
            "data batch 3 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 1.0467 - accuracy: 0.5986 - val_loss: 1.9963 - val_accuracy: 0.3548\n",
            "data batch 4 loaded\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 1.0254 - accuracy: 0.5591 - val_loss: 2.0808 - val_accuracy: 0.1290\n",
            "data batch 5 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.9421 - accuracy: 0.6237 - val_loss: 1.6865 - val_accuracy: 0.2581\n",
            "data batch 6 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.9025 - accuracy: 0.6344 - val_loss: 1.9948 - val_accuracy: 0.1290\n",
            "data batch 7 loaded\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 0.8475 - accuracy: 0.6918 - val_loss: 2.4050 - val_accuracy: 0.1935\n",
            "data batch 8 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.8616 - accuracy: 0.6989 - val_loss: 1.7354 - val_accuracy: 0.4194\n",
            "\n",
            "\n",
            "start epoch 11\n",
            "data batch 0 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.8108 - accuracy: 0.7025 - val_loss: 2.0698 - val_accuracy: 0.2903\n",
            "data batch 1 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.8972 - accuracy: 0.6308 - val_loss: 1.8603 - val_accuracy: 0.4194\n",
            "data batch 2 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.8265 - accuracy: 0.6882 - val_loss: 1.8377 - val_accuracy: 0.2581\n",
            "data batch 3 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.9136 - accuracy: 0.6416 - val_loss: 2.2994 - val_accuracy: 0.3226\n",
            "data batch 4 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.8690 - accuracy: 0.6738 - val_loss: 2.1712 - val_accuracy: 0.2258\n",
            "data batch 5 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.8418 - accuracy: 0.6452 - val_loss: 2.0061 - val_accuracy: 0.2258\n",
            "data batch 6 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.8256 - accuracy: 0.6810 - val_loss: 2.1488 - val_accuracy: 0.1613\n",
            "data batch 7 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.8222 - accuracy: 0.7133 - val_loss: 2.3443 - val_accuracy: 0.2581\n",
            "data batch 8 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.6527 - accuracy: 0.7849 - val_loss: 1.9023 - val_accuracy: 0.3548\n",
            "\n",
            "\n",
            "start epoch 12\n",
            "data batch 0 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.6236 - accuracy: 0.7921 - val_loss: 2.3273 - val_accuracy: 0.2903\n",
            "data batch 1 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.6992 - accuracy: 0.7348 - val_loss: 2.2047 - val_accuracy: 0.3226\n",
            "data batch 2 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.6998 - accuracy: 0.7312 - val_loss: 1.9134 - val_accuracy: 0.3226\n",
            "data batch 3 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.7303 - accuracy: 0.7061 - val_loss: 2.3475 - val_accuracy: 0.2581\n",
            "data batch 4 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.8355 - accuracy: 0.6559 - val_loss: 2.5848 - val_accuracy: 0.1935\n",
            "data batch 5 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.7509 - accuracy: 0.6953 - val_loss: 2.1609 - val_accuracy: 0.3226\n",
            "data batch 6 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.6592 - accuracy: 0.7527 - val_loss: 2.6551 - val_accuracy: 0.0968\n",
            "data batch 7 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.6250 - accuracy: 0.7849 - val_loss: 2.8527 - val_accuracy: 0.1613\n",
            "data batch 8 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.5296 - accuracy: 0.8566 - val_loss: 2.1272 - val_accuracy: 0.4194\n",
            "\n",
            "\n",
            "start epoch 13\n",
            "data batch 0 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.5342 - accuracy: 0.8136 - val_loss: 2.4795 - val_accuracy: 0.3548\n",
            "data batch 1 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.6300 - accuracy: 0.7814 - val_loss: 2.5267 - val_accuracy: 0.3226\n",
            "data batch 2 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.5878 - accuracy: 0.8100 - val_loss: 2.2121 - val_accuracy: 0.3226\n",
            "data batch 3 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.5965 - accuracy: 0.7706 - val_loss: 2.6075 - val_accuracy: 0.2258\n",
            "data batch 4 loaded\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.6265 - accuracy: 0.7527 - val_loss: 3.0681 - val_accuracy: 0.1290\n",
            "data batch 5 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.5817 - accuracy: 0.7814 - val_loss: 2.0827 - val_accuracy: 0.3548\n",
            "data batch 6 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.5619 - accuracy: 0.7849 - val_loss: 2.7928 - val_accuracy: 0.1935\n",
            "data batch 7 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.5244 - accuracy: 0.8029 - val_loss: 3.2070 - val_accuracy: 0.1613\n",
            "data batch 8 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.4727 - accuracy: 0.8280 - val_loss: 2.5247 - val_accuracy: 0.3548\n",
            "\n",
            "\n",
            "start epoch 14\n",
            "data batch 0 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.3720 - accuracy: 0.9140 - val_loss: 2.7968 - val_accuracy: 0.3548\n",
            "data batch 1 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.4373 - accuracy: 0.8351 - val_loss: 2.8388 - val_accuracy: 0.3548\n",
            "data batch 2 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.5563 - accuracy: 0.7885 - val_loss: 2.6968 - val_accuracy: 0.2903\n",
            "data batch 3 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.4859 - accuracy: 0.8280 - val_loss: 3.1470 - val_accuracy: 0.1935\n",
            "data batch 4 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.5929 - accuracy: 0.7455 - val_loss: 2.9820 - val_accuracy: 0.1290\n",
            "data batch 5 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.4417 - accuracy: 0.8495 - val_loss: 2.2864 - val_accuracy: 0.3548\n",
            "data batch 6 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.3869 - accuracy: 0.8674 - val_loss: 3.1187 - val_accuracy: 0.1613\n",
            "data batch 7 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.5014 - accuracy: 0.8065 - val_loss: 3.6576 - val_accuracy: 0.1613\n",
            "data batch 8 loaded\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.3719 - accuracy: 0.8746 - val_loss: 3.1803 - val_accuracy: 0.2903\n",
            "\n",
            "\n",
            "start epoch 15\n",
            "data batch 0 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.3359 - accuracy: 0.8853 - val_loss: 3.2759 - val_accuracy: 0.3226\n",
            "data batch 1 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.3602 - accuracy: 0.8674 - val_loss: 3.3018 - val_accuracy: 0.2903\n",
            "data batch 2 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.3851 - accuracy: 0.8674 - val_loss: 2.8257 - val_accuracy: 0.3871\n",
            "data batch 3 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.4264 - accuracy: 0.8351 - val_loss: 3.1140 - val_accuracy: 0.2581\n",
            "data batch 4 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.4614 - accuracy: 0.8244 - val_loss: 3.3908 - val_accuracy: 0.2903\n",
            "data batch 5 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.3967 - accuracy: 0.8710 - val_loss: 2.5495 - val_accuracy: 0.2903\n",
            "data batch 6 loaded\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.3323 - accuracy: 0.8996 - val_loss: 3.6284 - val_accuracy: 0.1613\n",
            "data batch 7 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.3482 - accuracy: 0.8925 - val_loss: 4.3751 - val_accuracy: 0.2258\n",
            "data batch 8 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.3413 - accuracy: 0.8710 - val_loss: 2.9742 - val_accuracy: 0.3548\n",
            "\n",
            "\n",
            "start epoch 16\n",
            "data batch 0 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.2537 - accuracy: 0.9283 - val_loss: 3.4072 - val_accuracy: 0.3226\n",
            "data batch 1 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.2808 - accuracy: 0.9176 - val_loss: 3.8439 - val_accuracy: 0.2581\n",
            "data batch 2 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.3700 - accuracy: 0.8746 - val_loss: 3.1005 - val_accuracy: 0.3226\n",
            "data batch 3 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.3600 - accuracy: 0.8566 - val_loss: 3.3155 - val_accuracy: 0.2903\n",
            "data batch 4 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.4044 - accuracy: 0.8351 - val_loss: 4.1187 - val_accuracy: 0.0968\n",
            "data batch 5 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.3356 - accuracy: 0.8961 - val_loss: 2.8729 - val_accuracy: 0.2581\n",
            "data batch 6 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.2791 - accuracy: 0.9283 - val_loss: 3.8510 - val_accuracy: 0.0968\n",
            "data batch 7 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.2467 - accuracy: 0.9247 - val_loss: 4.7887 - val_accuracy: 0.2903\n",
            "data batch 8 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.2829 - accuracy: 0.9068 - val_loss: 3.5092 - val_accuracy: 0.3226\n",
            "\n",
            "\n",
            "start epoch 17\n",
            "data batch 0 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.1913 - accuracy: 0.9570 - val_loss: 4.0494 - val_accuracy: 0.2903\n",
            "data batch 1 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.2570 - accuracy: 0.9211 - val_loss: 4.0555 - val_accuracy: 0.2581\n",
            "data batch 2 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.2819 - accuracy: 0.8996 - val_loss: 2.9149 - val_accuracy: 0.4194\n",
            "data batch 3 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.2661 - accuracy: 0.9140 - val_loss: 4.1873 - val_accuracy: 0.2903\n",
            "data batch 4 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.3335 - accuracy: 0.8638 - val_loss: 4.0641 - val_accuracy: 0.1935\n",
            "data batch 5 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.2748 - accuracy: 0.9140 - val_loss: 3.1235 - val_accuracy: 0.3226\n",
            "data batch 6 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.2696 - accuracy: 0.9176 - val_loss: 4.1688 - val_accuracy: 0.0968\n",
            "data batch 7 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.2676 - accuracy: 0.9211 - val_loss: 4.4262 - val_accuracy: 0.2903\n",
            "data batch 8 loaded\n",
            "9/9 [==============================] - 1s 74ms/step - loss: 0.2743 - accuracy: 0.8996 - val_loss: 3.7310 - val_accuracy: 0.2903\n",
            "\n",
            "\n",
            "start epoch 18\n",
            "data batch 0 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.2330 - accuracy: 0.9355 - val_loss: 4.4918 - val_accuracy: 0.2258\n",
            "data batch 1 loaded\n",
            "9/9 [==============================] - 1s 74ms/step - loss: 0.1819 - accuracy: 0.9534 - val_loss: 4.4476 - val_accuracy: 0.2581\n",
            "data batch 2 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.2639 - accuracy: 0.9140 - val_loss: 3.0412 - val_accuracy: 0.4194\n",
            "data batch 3 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.2596 - accuracy: 0.9211 - val_loss: 4.3370 - val_accuracy: 0.1613\n",
            "data batch 4 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.1889 - accuracy: 0.9570 - val_loss: 4.4611 - val_accuracy: 0.1935\n",
            "data batch 5 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.2221 - accuracy: 0.9391 - val_loss: 3.1884 - val_accuracy: 0.2581\n",
            "data batch 6 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.2015 - accuracy: 0.9462 - val_loss: 4.8727 - val_accuracy: 0.1613\n",
            "data batch 7 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.2118 - accuracy: 0.9247 - val_loss: 4.6924 - val_accuracy: 0.2581\n",
            "data batch 8 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.1870 - accuracy: 0.9570 - val_loss: 4.5461 - val_accuracy: 0.2903\n",
            "\n",
            "\n",
            "start epoch 19\n",
            "data batch 0 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.2142 - accuracy: 0.9319 - val_loss: 4.3152 - val_accuracy: 0.1935\n",
            "data batch 1 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.1552 - accuracy: 0.9606 - val_loss: 4.7479 - val_accuracy: 0.2581\n",
            "data batch 2 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.1898 - accuracy: 0.9391 - val_loss: 3.1142 - val_accuracy: 0.4194\n",
            "data batch 3 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.2544 - accuracy: 0.9176 - val_loss: 4.7664 - val_accuracy: 0.2258\n",
            "data batch 4 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.2093 - accuracy: 0.9677 - val_loss: 4.4310 - val_accuracy: 0.2581\n",
            "data batch 5 loaded\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 0.1956 - accuracy: 0.9462 - val_loss: 3.5777 - val_accuracy: 0.3226\n",
            "data batch 6 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.2182 - accuracy: 0.9355 - val_loss: 4.8444 - val_accuracy: 0.2258\n",
            "data batch 7 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.3092 - accuracy: 0.8746 - val_loss: 4.7246 - val_accuracy: 0.2903\n",
            "data batch 8 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.2372 - accuracy: 0.9211 - val_loss: 4.5350 - val_accuracy: 0.1935\n",
            "\n",
            "\n",
            "start epoch 20\n",
            "data batch 0 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.1685 - accuracy: 0.9462 - val_loss: 4.3752 - val_accuracy: 0.2258\n",
            "data batch 1 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.1465 - accuracy: 0.9570 - val_loss: 5.1910 - val_accuracy: 0.2581\n",
            "data batch 2 loaded\n",
            "9/9 [==============================] - 1s 74ms/step - loss: 0.1676 - accuracy: 0.9427 - val_loss: 3.9303 - val_accuracy: 0.3548\n",
            "data batch 3 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.2022 - accuracy: 0.9427 - val_loss: 5.4714 - val_accuracy: 0.1935\n",
            "data batch 4 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.1918 - accuracy: 0.9498 - val_loss: 4.8899 - val_accuracy: 0.2258\n",
            "data batch 5 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.1723 - accuracy: 0.9534 - val_loss: 3.8455 - val_accuracy: 0.3548\n",
            "data batch 6 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.2604 - accuracy: 0.9032 - val_loss: 4.9340 - val_accuracy: 0.2903\n",
            "data batch 7 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.2384 - accuracy: 0.9068 - val_loss: 5.2994 - val_accuracy: 0.1613\n",
            "data batch 8 loaded\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 0.2001 - accuracy: 0.9211 - val_loss: 5.7759 - val_accuracy: 0.1613\n",
            "\n",
            "\n",
            "start epoch 21\n",
            "data batch 0 loaded\n",
            "9/9 [==============================] - 1s 74ms/step - loss: 0.3474 - accuracy: 0.8638 - val_loss: 3.9925 - val_accuracy: 0.3548\n",
            "data batch 1 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.2626 - accuracy: 0.9176 - val_loss: 5.0215 - val_accuracy: 0.1935\n",
            "data batch 2 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.1571 - accuracy: 0.9391 - val_loss: 3.7696 - val_accuracy: 0.3226\n",
            "data batch 3 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.1913 - accuracy: 0.9534 - val_loss: 5.3095 - val_accuracy: 0.1935\n",
            "data batch 4 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.1937 - accuracy: 0.9462 - val_loss: 4.7498 - val_accuracy: 0.1290\n",
            "data batch 5 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.1635 - accuracy: 0.9498 - val_loss: 3.5248 - val_accuracy: 0.3548\n",
            "data batch 6 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.1633 - accuracy: 0.9462 - val_loss: 5.1635 - val_accuracy: 0.3226\n",
            "data batch 7 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.1867 - accuracy: 0.9283 - val_loss: 6.3313 - val_accuracy: 0.2258\n",
            "data batch 8 loaded\n",
            "9/9 [==============================] - 1s 74ms/step - loss: 0.2776 - accuracy: 0.9104 - val_loss: 5.4170 - val_accuracy: 0.1613\n",
            "\n",
            "\n",
            "start epoch 22\n",
            "data batch 0 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.1559 - accuracy: 0.9534 - val_loss: 4.2310 - val_accuracy: 0.2903\n",
            "data batch 1 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.1662 - accuracy: 0.9427 - val_loss: 5.8221 - val_accuracy: 0.2581\n",
            "data batch 2 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.1310 - accuracy: 0.9606 - val_loss: 4.0210 - val_accuracy: 0.3226\n",
            "data batch 3 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.1818 - accuracy: 0.9462 - val_loss: 6.2332 - val_accuracy: 0.2258\n",
            "data batch 4 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.1651 - accuracy: 0.9642 - val_loss: 4.8466 - val_accuracy: 0.1935\n",
            "data batch 5 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.1259 - accuracy: 0.9749 - val_loss: 3.6585 - val_accuracy: 0.3226\n",
            "data batch 6 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.1061 - accuracy: 0.9749 - val_loss: 5.0443 - val_accuracy: 0.2581\n",
            "data batch 7 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.1037 - accuracy: 0.9642 - val_loss: 6.2692 - val_accuracy: 0.2903\n",
            "data batch 8 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.1858 - accuracy: 0.9355 - val_loss: 5.3535 - val_accuracy: 0.1613\n",
            "\n",
            "\n",
            "start epoch 23\n",
            "data batch 0 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.1614 - accuracy: 0.9534 - val_loss: 4.7973 - val_accuracy: 0.2258\n",
            "data batch 1 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.1015 - accuracy: 0.9749 - val_loss: 6.1416 - val_accuracy: 0.2581\n",
            "data batch 2 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.1398 - accuracy: 0.9570 - val_loss: 3.9309 - val_accuracy: 0.2903\n",
            "data batch 3 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.1388 - accuracy: 0.9534 - val_loss: 6.4812 - val_accuracy: 0.1935\n",
            "data batch 4 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.1395 - accuracy: 0.9642 - val_loss: 5.5153 - val_accuracy: 0.1935\n",
            "data batch 5 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.1273 - accuracy: 0.9749 - val_loss: 3.7739 - val_accuracy: 0.3548\n",
            "data batch 6 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.1061 - accuracy: 0.9749 - val_loss: 5.1973 - val_accuracy: 0.2258\n",
            "data batch 7 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.1098 - accuracy: 0.9677 - val_loss: 6.5477 - val_accuracy: 0.2581\n",
            "data batch 8 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.1340 - accuracy: 0.9498 - val_loss: 5.8431 - val_accuracy: 0.2258\n",
            "\n",
            "\n",
            "start epoch 24\n",
            "data batch 0 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.1089 - accuracy: 0.9606 - val_loss: 5.1513 - val_accuracy: 0.3226\n",
            "data batch 1 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.0945 - accuracy: 0.9749 - val_loss: 6.2266 - val_accuracy: 0.2581\n",
            "data batch 2 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.0562 - accuracy: 0.9964 - val_loss: 4.1402 - val_accuracy: 0.2903\n",
            "data batch 3 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.0974 - accuracy: 0.9677 - val_loss: 6.7619 - val_accuracy: 0.1290\n",
            "data batch 4 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.1238 - accuracy: 0.9606 - val_loss: 6.2687 - val_accuracy: 0.1613\n",
            "data batch 5 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.1261 - accuracy: 0.9606 - val_loss: 4.3996 - val_accuracy: 0.2903\n",
            "data batch 6 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.1265 - accuracy: 0.9642 - val_loss: 6.0642 - val_accuracy: 0.2258\n",
            "data batch 7 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.0665 - accuracy: 0.9821 - val_loss: 6.2327 - val_accuracy: 0.2258\n",
            "data batch 8 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.0773 - accuracy: 0.9749 - val_loss: 5.5003 - val_accuracy: 0.2581\n",
            "\n",
            "\n",
            "start epoch 25\n",
            "data batch 0 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.0536 - accuracy: 0.9892 - val_loss: 5.2831 - val_accuracy: 0.3548\n",
            "data batch 1 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.0590 - accuracy: 0.9928 - val_loss: 6.2525 - val_accuracy: 0.2581\n",
            "data batch 2 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.0733 - accuracy: 0.9713 - val_loss: 3.8645 - val_accuracy: 0.3548\n",
            "data batch 3 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.0910 - accuracy: 0.9749 - val_loss: 7.9494 - val_accuracy: 0.1935\n",
            "data batch 4 loaded\n",
            "9/9 [==============================] - 1s 74ms/step - loss: 0.1704 - accuracy: 0.9319 - val_loss: 6.4368 - val_accuracy: 0.2258\n",
            "data batch 5 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.1287 - accuracy: 0.9570 - val_loss: 4.0022 - val_accuracy: 0.3226\n",
            "data batch 6 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.0665 - accuracy: 0.9928 - val_loss: 5.2658 - val_accuracy: 0.2258\n",
            "data batch 7 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.0793 - accuracy: 0.9785 - val_loss: 6.5559 - val_accuracy: 0.1935\n",
            "data batch 8 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.0804 - accuracy: 0.9749 - val_loss: 5.4786 - val_accuracy: 0.2903\n",
            "\n",
            "\n",
            "start epoch 26\n",
            "data batch 0 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.0468 - accuracy: 1.0000 - val_loss: 5.4991 - val_accuracy: 0.2581\n",
            "data batch 1 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.0323 - accuracy: 0.9964 - val_loss: 6.6802 - val_accuracy: 0.1613\n",
            "data batch 2 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.0492 - accuracy: 0.9964 - val_loss: 4.2183 - val_accuracy: 0.3548\n",
            "data batch 3 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.0378 - accuracy: 0.9928 - val_loss: 7.7499 - val_accuracy: 0.1935\n",
            "data batch 4 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.0670 - accuracy: 0.9857 - val_loss: 6.7405 - val_accuracy: 0.1935\n",
            "data batch 5 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.1184 - accuracy: 0.9606 - val_loss: 4.8503 - val_accuracy: 0.2258\n",
            "data batch 6 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.0758 - accuracy: 0.9857 - val_loss: 5.5042 - val_accuracy: 0.2258\n",
            "data batch 7 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.0554 - accuracy: 0.9857 - val_loss: 7.1562 - val_accuracy: 0.1935\n",
            "data batch 8 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.0418 - accuracy: 0.9892 - val_loss: 6.1946 - val_accuracy: 0.1935\n",
            "\n",
            "\n",
            "start epoch 27\n",
            "data batch 0 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.0318 - accuracy: 0.9964 - val_loss: 5.6844 - val_accuracy: 0.2903\n",
            "data batch 1 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.0290 - accuracy: 0.9964 - val_loss: 7.1205 - val_accuracy: 0.2903\n",
            "data batch 2 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 4.4613 - val_accuracy: 0.3871\n",
            "data batch 3 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.0265 - accuracy: 0.9964 - val_loss: 7.3395 - val_accuracy: 0.1613\n",
            "data batch 4 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.0290 - accuracy: 0.9964 - val_loss: 7.5622 - val_accuracy: 0.1613\n",
            "data batch 5 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.0630 - accuracy: 0.9821 - val_loss: 4.5756 - val_accuracy: 0.3226\n",
            "data batch 6 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.0374 - accuracy: 0.9892 - val_loss: 5.9652 - val_accuracy: 0.2258\n",
            "data batch 7 loaded\n",
            "9/9 [==============================] - 1s 74ms/step - loss: 0.0420 - accuracy: 0.9857 - val_loss: 7.2104 - val_accuracy: 0.2258\n",
            "data batch 8 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.0265 - accuracy: 0.9964 - val_loss: 7.1531 - val_accuracy: 0.2258\n",
            "\n",
            "\n",
            "start epoch 28\n",
            "data batch 0 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.0414 - accuracy: 0.9928 - val_loss: 5.5842 - val_accuracy: 0.3871\n",
            "data batch 1 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.0373 - accuracy: 0.9928 - val_loss: 6.9083 - val_accuracy: 0.2258\n",
            "data batch 2 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 4.6682 - val_accuracy: 0.3548\n",
            "data batch 3 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 7.7350 - val_accuracy: 0.1935\n",
            "data batch 4 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 7.8167 - val_accuracy: 0.1613\n",
            "data batch 5 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.0231 - accuracy: 0.9964 - val_loss: 4.5163 - val_accuracy: 0.2581\n",
            "data batch 6 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 7.3196 - val_accuracy: 0.1935\n",
            "data batch 7 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 6.9213 - val_accuracy: 0.2258\n",
            "data batch 8 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 6.4493 - val_accuracy: 0.3226\n",
            "\n",
            "\n",
            "start epoch 29\n",
            "data batch 0 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 5.9710 - val_accuracy: 0.3871\n",
            "data batch 1 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 7.3124 - val_accuracy: 0.2581\n",
            "data batch 2 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.0188 - accuracy: 0.9964 - val_loss: 5.0164 - val_accuracy: 0.3548\n",
            "data batch 3 loaded\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 7.9940 - val_accuracy: 0.1935\n",
            "data batch 4 loaded\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 8.0751 - val_accuracy: 0.1613\n",
            "data batch 5 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 4.5819 - val_accuracy: 0.2903\n",
            "data batch 6 loaded\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 7.5439 - val_accuracy: 0.1935\n",
            "data batch 7 loaded\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 7.2578 - val_accuracy: 0.2258\n",
            "data batch 8 loaded\n",
            "9/9 [==============================] - 1s 74ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 6.6944 - val_accuracy: 0.2903\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0svWpVPkiUsK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "232caed4-b9ce-419e-aaf5-8315c98f2476"
      },
      "source": [
        "# testing process\n",
        "file_num = 2\n",
        "num_list = []\n",
        "acc_list = []\n",
        "m = tf.keras.metrics.CategoricalAccuracy()\n",
        "for i in range(file_num):\n",
        "  # myData = DR_resized(False, i, 32, 0.1, (224, 224))\n",
        "  myData = DR_resized(False, i, 32, 0.1)\n",
        "  num, acc = myModel.evaluate(myData.test_images, myData.test_labels)\n",
        "  print(num, acc)\n",
        "  # p = myModel.model.predict(myData.test_images)\n",
        "  # print(p)\n",
        "  # m.update_state(p, myData.test_labels)\n",
        "  # num_list.append(num)\n",
        "  # acc_list.append(acc)\n",
        "  myData.clear()\n",
        "  gc.collect()\n",
        "\n",
        "print(m.result().numpy())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1bf423dcbb72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnum_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0macc_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategoricalAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m# myData = DR_resized(False, i, 32, 0.1, (224, 224))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqL9za1Dkqjy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "211b35e0-ef16-4426-e7cb-1486450f1459"
      },
      "source": [
        "# compute overall accuracy\n",
        "num_list = np.array(num_list)\n",
        "acc_list = np.array(acc_list)\n",
        "acc_overall = (num_list * acc_list).sum() / num_list.sum()\n",
        "print(acc_overall)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBuQpdk7vC25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e77663df-0a46-428c-fcf2-b6433de16483"
      },
      "source": [
        "from datetime import datetime\n",
        "now = datetime.now()\n",
        "dt_string = now.strftime(\"%d-%m-%Y %H:%M:%S\")\n",
        "print(\"date and time =\", dt_string)\n",
        "myModel.save_model(os.path.join(project_root, \"Trained Models\", dt_string))\n",
        "np.save(os.path.join(project_root, \"Trained Models\", dt_string, \"history\"), history_array)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "date and time = 16-04-2021 00:41:45\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/CS 766 Project/Project Coding and Data Files/Trained Models/16-04-2021 00:41:45/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2QDEecGwGTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d46dfb8-9023-4d8e-c021-120b4234d6c8"
      },
      "source": [
        "# this part is for loading parameters and extracting features\n",
        "# load parameters\n",
        "parameter_version = \"16-04-2021 00:41:45\"\n",
        "if not os.path.exists(os.path.join(project_root, \"features\", parameter_version)):\n",
        "    os.mkdir(os.path.join(project_root, \"features\", parameter_version))\n",
        "\n",
        "my_model_pretrained = OriginCNN()\n",
        "# my_model_pretrained = Res50()\n",
        "my_model_pretrained.build()\n",
        "my_model_pretrained.load_model(os.path.join(project_root, \"Trained Models\", parameter_version))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 333, 333, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 166, 166, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 55, 55, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 27, 27, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 9, 9, 32)          9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                16416     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 165       \n",
            "=================================================================\n",
            "Total params: 35,973\n",
            "Trainable params: 35,973\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dC4KT0HjTqe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b3e8f64-cc88-400f-f998-7548475a1a2a"
      },
      "source": [
        "# load training data, extract features and save to npy files\n",
        "file_num = 9\n",
        "for i in range(file_num):\n",
        "  # myData = DR_resized(True, i, 32, 0.1, (224, 224))\n",
        "  myData = DR_resized(True, i, 32, 0.1)\n",
        "  feature = my_model_pretrained.extract_feature(myData.train_images)\n",
        "  # feature = myModel.extract_feature(myData.train_images)\n",
        "  np.save(os.path.join(project_root, \"features\", parameter_version, \"Xtrain_feature%d.npy\" % i), feature)\n",
        "  print(\"Xtrain_feature%d.npy\" % i)\n",
        "  print(feature.shape)\n",
        "  myData.clear()\n",
        "  gc.collect()\n",
        "\n",
        "# load testing data, extract features and save to npy files\n",
        "file_num = 2\n",
        "for i in range(file_num):\n",
        "  # myData = DR_resized(False, i, 32, 0.1, (224, 224))\n",
        "  myData = DR_resized(False, i, 32, 0.1)\n",
        "  feature = my_model_pretrained.extract_feature(myData.test_images)\n",
        "  np.save(os.path.join(project_root, \"features\", parameter_version, \"Xtest_feature%d.npy\" % i), feature)\n",
        "  print(\"Xtest_feature%d.npy\" % i)\n",
        "  myData.clear()\n",
        "  gc.collect()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Xtrain_feature0.npy\n",
            "(310, 512)\n",
            "Xtrain_feature1.npy\n",
            "(310, 512)\n",
            "Xtrain_feature2.npy\n",
            "(310, 512)\n",
            "Xtrain_feature3.npy\n",
            "(310, 512)\n",
            "Xtrain_feature4.npy\n",
            "(310, 512)\n",
            "Xtrain_feature5.npy\n",
            "(310, 512)\n",
            "Xtrain_feature6.npy\n",
            "(310, 512)\n",
            "Xtrain_feature7.npy\n",
            "(310, 512)\n",
            "Xtrain_feature8.npy\n",
            "(310, 512)\n",
            "Xtest_feature0.npy\n",
            "Xtest_feature1.npy\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}