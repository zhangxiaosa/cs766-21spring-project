{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "run.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGoAP5Dn3DwQ"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os, re, sys\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import gc\n",
        "import skimage.transform\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYucCZeH_dHH",
        "outputId": "c5ceff1c-f764-4cbe-bf3a-0518c9da6815"
      },
      "source": [
        "# test if GPUs are available\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUiMh4isCHnS",
        "outputId": "2dbef2a8-cab5-4bc1-dfb7-ff3a98feeb0d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJQvxwJFDmYk"
      },
      "source": [
        "# set project root, maybe you need to firstly \n",
        "# add shortcut of CS 766 Project to drive.\n",
        "project_root = './drive/MyDrive/CS 766 Project/Project Coding and Data Files/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGJsefpJ-XjF"
      },
      "source": [
        "# class to initialize CNNs\n",
        "class OriginCNN(object):\n",
        "  \"\"\"docstring for OriginCNN\"\"\"\n",
        "  def __init__(self):\n",
        "    self.optimizer = 'adam'\n",
        "    # self.optimizer = tf.keras.optimizers.SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "    # self.loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    # will add more properties\n",
        "\n",
        "\n",
        "  def build(self):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), strides=(3,3), activation='relu', input_shape=(1000, 1000, 3)))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(32, (3, 3), strides=(3,3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(32, (3, 3), strides=(3,3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(32, activation='relu'))\n",
        "    model.add(layers.Dense(2))\n",
        "\n",
        "    model.summary()\n",
        "    model.compile(optimizer=self.optimizer,\n",
        "                loss=self.loss,\n",
        "                metrics=['accuracy'])\n",
        "    self.model = model\n",
        "\n",
        "\n",
        "  def train(self, train_images, train_labels, epochs, datagen=None):\n",
        "    if(datagen):\n",
        "      train_generator = datagen.flow(train_images, train_labels, batch_size=32, subset='training')\n",
        "      validation_generator = datagen.flow(train_images, train_labels, batch_size=32, subset='validation')\n",
        "      self.history = self.model.fit_generator(train_generator,\n",
        "                                              # steps_per_epoch=len(train_generator) / 32,\n",
        "                                              validation_data=validation_generator, \n",
        "                                              # validation_steps=len(validation_generator) / 32,\n",
        "                                              epochs=epochs, \n",
        "                                              shuffle=False)\n",
        "    else:\n",
        "      self.history = self.model.fit(train_images, train_labels, epochs=epochs, validation_split=0.1)\n",
        "    return self.history\n",
        "\n",
        "  def train_on_batch(self, train_images, train_labels):\n",
        "    return self.model.train_on_batch(train_images, train_labels)\n",
        "\n",
        "  def predict(self, test_images):\n",
        "    return self.model.predict(test_images)\n",
        "\n",
        "\n",
        "  def evaluate(self, test_images, test_labels):\n",
        "    _, test_acc = self.model.evaluate(test_images, test_labels, verbose=2)\n",
        "    return test_images.shape[0], test_acc\n",
        "\n",
        "  def save_model(self, filepath):\n",
        "    self.model.save(filepath)\n",
        "\n",
        "  def load_model(self, filepath):\n",
        "    self.model = tf.keras.models.load_model(filepath)\n",
        "\n",
        "  def extract_feature(self, images):\n",
        "    extract = models.Model(self.model.inputs, self.model.layers[-3].output)\n",
        "    return extract.predict(images)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSiCn4VzdaV8"
      },
      "source": [
        "from tensorflow.keras.applications import ResNet50, InceptionV3, VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "class Res50(object):\n",
        "  \"\"\"docstring for OriginCNN\"\"\"\n",
        "  def __init__(self):\n",
        "    self.optimizer = 'adam'\n",
        "    # self.optimizer = tf.keras.optimizers.SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "    # self.loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    # will add more properties\n",
        "\n",
        "\n",
        "  def build(self):\n",
        "    base_model = InceptionV3(\n",
        "      include_top=False,\n",
        "      weights=\"imagenet\",\n",
        "      input_shape=(224, 224, 3)\n",
        "    )\n",
        "\n",
        "    # add a global spatial average pooling layer\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    # let's add a fully-connected layer\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    # and a logistic layer -- let's say we have n classes\n",
        "    predictions = Dense(2)(x)\n",
        "\n",
        "    # this is the model we will train\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "\n",
        "    model.summary()\n",
        "    model.compile(optimizer=self.optimizer,\n",
        "                loss=self.loss,\n",
        "                metrics=['accuracy'])\n",
        "    self.model = model\n",
        "\n",
        "\n",
        "  def train(self, train_images, train_labels, epochs, datagen=None):\n",
        "    if(datagen):\n",
        "      train_images = train_images / 255.0\n",
        "      train_generator = datagen.flow(train_images, train_labels, batch_size=32, subset='training')\n",
        "      validation_generator = datagen.flow(train_images, train_labels, batch_size=32, subset='validation')\n",
        "      self.history = self.model.fit_generator(train_generator,\n",
        "                                              # steps_per_epoch=len(train_generator) / 32,\n",
        "                                              validation_data=validation_generator, \n",
        "                                              # validation_steps=len(validation_generator) / 32,\n",
        "                                              epochs=epochs, \n",
        "                                              shuffle=False)\n",
        "    else:\n",
        "      self.history = self.model.fit(train_images, train_labels, epochs=epochs, validation_split=0.1)\n",
        "    return self.history\n",
        "\n",
        "  def train_on_batch(self, train_images, train_labels):\n",
        "    return self.model.train_on_batch(train_images, train_labels)\n",
        "\n",
        "  def predict(self, test_images):\n",
        "    return self.model.predict(test_images)\n",
        "\n",
        "\n",
        "  def evaluate(self, test_images, test_labels):\n",
        "    _, test_acc = self.model.evaluate(test_images, test_labels, verbose=2)\n",
        "    return test_images.shape[0], test_acc\n",
        "\n",
        "  def save_model(self, filepath):\n",
        "    self.model.save(filepath)\n",
        "\n",
        "  def load_model(self, filepath):\n",
        "    self.model = tf.keras.models.load_model(filepath)\n",
        "\n",
        "  def extract_feature(self, images):\n",
        "    extract = models.Model(self.model.inputs, self.model.layers[-2].output)\n",
        "    return extract.predict(images)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3suc98v-bRj"
      },
      "source": [
        "class DR_resized(object):\n",
        "  \"\"\"docstring for DR_resized\"\"\"\n",
        "  def __init__(self, is_training, batch_id, batch_size, train_val_split_rate, size=None):\n",
        "    self.batch_size = batch_size\n",
        "    self.train_val_split_rate = train_val_split_rate\n",
        "    if(is_training):\n",
        "      # load images\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Stratified_Random_Sampling_Datasets\", \"Processed_Xtrain_Batch%d.npy\" % batch_id))\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Even_Class_Distribution_Datasets\", \"Processed_Xtrain_Batch%d_even.npy\" % batch_id))\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Color_Even_Class_Distribution_Datasets\", \"Color_Processed_Xtrain_Batch%d_even.npy\" % batch_id))\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"04_Only_Preprocessed_Even_Class_Distribution_Datasets\", \"04_Only_Processed_Xtrain_Batch%d_even.npy\" % batch_id))\n",
        "      all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"04_Only_Color_Even_Class_Distribution_Datasets\", \"Xtrain\", \"04_Only_Color_Processed_Xtrain_Batch%d_even.npy\" % batch_id))\n",
        "      \n",
        "      # add a dimension for channels if gray scale images\n",
        "      if (len(all_images[0].shape) == 2):\n",
        "        all_images = np.expand_dims(all_images, axis=-1)\n",
        "\n",
        "      # resize\n",
        "      # gray scale\n",
        "      if(size):\n",
        "        if (len(all_images[0].shape) == 2):\n",
        "          all_images_resize = np.zeros((all_images.shape[0], size[0], size[1], 3));\n",
        "          for i in range(all_images.shape[0]):\n",
        "            img = skimage.transform.resize(all_images[i].astype('float64'), (size[0], size[1]))\n",
        "            img3 = np.repeat(img, 3, axis=2)\n",
        "            all_images_resize[i] = img3\n",
        "        # color image\n",
        "        else:\n",
        "          all_images_resize = np.zeros((all_images.shape[0], size[0], size[1], 3));\n",
        "          for i in range(all_images.shape[0]):\n",
        "            all_images_resize[i] = skimage.transform.resize(all_images[i].astype('float64'), (size[0], size[1]))\n",
        "        all_images = all_images_resize\n",
        "\n",
        "\n",
        "      # load labels\n",
        "      # all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Stratified Random Sampling Datasets\", \"Ytrain\", \"Ytrain_Batch%d.npy\" % batch_id), allow_pickle=True)\n",
        "      # all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Even Class Distribution Datasets\", \"Ytrain\", \"Ytrain_Batch%d_even.npy\" % batch_id), allow_pickle=True)\n",
        "      # all_labels = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"04_Only_Preprocessed_Even_Class_Distribution_Datasets\", \"04_Only_Ytrain_Batch%d_even.npy\" % batch_id), allow_pickle=True)\n",
        "      all_labels = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"04_Only_Color_Even_Class_Distribution_Datasets\", \"Ytrain\", \"04_Only_Ytrain_Batch%d_even.npy\" % batch_id), allow_pickle=True)\n",
        "      all_labels = np.array([item[1] for item in all_labels])\n",
        "      \n",
        "      # one hot\n",
        "      # all_labels_one_hot = np.zeros((all_labels.size, 5))\n",
        "      # all_labels_one_hot[np.arange(all_labels.size),all_labels] = 1\n",
        "\n",
        "      # without one hot\n",
        "      all_labels_one_hot = np.expand_dims(all_labels, axis=-1)\n",
        "\n",
        "      # shuffle\n",
        "      np.random.seed(0);\n",
        "      indices = np.arange(all_images.shape[0])\n",
        "      np.random.shuffle(indices)\n",
        "      all_images = all_images[indices]\n",
        "      all_labels_one_hot = all_labels_one_hot[indices]\n",
        "\n",
        "      self.train_images = all_images\n",
        "      self.train_labels = all_labels_one_hot\n",
        "    \n",
        "    else:\n",
        "      # load images\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Stratified_Random_Sampling_Datasets\", \"Processed_Xtest_Batch%d.npy\") % batch_id)\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Even_Class_Distribution_Datasets\", \"Processed_Xest_Batch%d_even.npy\") % batch_id)\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Color_Even_Class_Distribution_Datasets\", \"Color_Processed_Xest_Batch%d_even.npy\") % batch_id)\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"04_Only_Preprocessed_Even_Class_Distribution_Datasets\", \"04_Only_Processed_Xest_Batch%d_even.npy\" % batch_id))\n",
        "      all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"04_Only_Color_Even_Class_Distribution_Datasets\", \"Xtest\", \"04_Only_Color_Processed_Xest_Batch%d_even.npy\" % batch_id))\n",
        "      \n",
        "      # add a dimension for channels if gray scale images\n",
        "      if (len(all_images[0].shape) == 2):\n",
        "        all_images = np.expand_dims(all_images, axis=-1)\n",
        "\n",
        "      # resize\n",
        "      if(size):\n",
        "        # gray scale\n",
        "        if (len(all_images[0].shape) == 2):\n",
        "          all_images_resize = np.zeros((all_images.shape[0], size[0], size[1], 1));\n",
        "          for i in range(all_images.shape[0]):\n",
        "            all_images_resize[i] = skimage.transform.resize(all_images[i].astype('float64'), (size[0], size[1]));\n",
        "        # color image\n",
        "        else:\n",
        "          all_images_resize = np.zeros((all_images.shape[0], size[0], size[1], 3));\n",
        "          for i in range(all_images.shape[0]):\n",
        "            all_images_resize[i] = skimage.transform.resize(all_images[i].astype('float64'), (size[0], size[1]));\n",
        "        all_images = all_images_resize\n",
        "\n",
        "\n",
        "      # load labels\n",
        "      # all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Stratified Random Sampling Datasets\", \"Ytest\", \"Ytest_Batch%d.npy\" % batch_id), allow_pickle=True)\n",
        "      # all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Even Class Distribution Datasets\", \"Ytest\", \"Yest_Batch%d_even.npy\" % batch_id), allow_pickle=True)\n",
        "      # all_labels = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"04_Only_Preprocessed_Even_Class_Distribution_Datasets\", \"04_Only_Yest_Batch%d_even.npy\" % batch_id), allow_pickle=True)\n",
        "      all_labels = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"04_Only_Color_Even_Class_Distribution_Datasets\", \"Ytest\", \"04_Only_Yest_Batch%d_even.npy\" % batch_id), allow_pickle=True)\n",
        "      all_labels = np.array([item[1] for item in all_labels])\n",
        "\n",
        "      # one hot\n",
        "      # all_labels_one_hot = np.zeros((all_labels.size, 5))\n",
        "      # all_labels_one_hot[np.arange(all_labels.size),all_labels] = 1\n",
        "\n",
        "      # without one hot\n",
        "      all_labels_one_hot = np.expand_dims(all_labels, axis=-1)\n",
        "      \n",
        "      self.test_images = all_images\n",
        "      self.test_labels = all_labels_one_hot\n",
        "  \n",
        "  def clear(self):\n",
        "    self.train_images = None\n",
        "    self.validate_images = None\n",
        "    self.test_images = None\n",
        "    self.train_labels = None\n",
        "    self.validate_labels = None\n",
        "    self.test_labels = None\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L57sy6Z02c-"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class Cifar(object):\n",
        "  \"\"\"docstring for DR_resized\"\"\"\n",
        "  def __init__(self, is_training, batch_id, batch_size, train_val_split_rate):\n",
        "    self.batch_size = batch_size\n",
        "    self.train_val_split_rate = train_val_split_rate\n",
        "\n",
        "    if(is_training):\n",
        "      # load images\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Stratified_Random_Sampling_Datasets\", \"Processed_Xtrain_Batch%d.npy\" % batch_id))\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Even_Class_Distribution_Datasets\", \"Processed_Xtrain_Batch%d_even.npy\" % batch_id))\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Color_Even_Class_Distribution_Datasets\", \"Color_Processed_Xtrain_Batch%d_even.npy\" % batch_id))\n",
        "      \n",
        "      # add a dimension for channels if gray scale images\n",
        "      # if (len(all_images[0].shape) == 2):\n",
        "        # all_images = np.expand_dims(all_images, axis=-1)\n",
        "\n",
        "      # load labels\n",
        "      # all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Stratified Random Sampling Datasets\", \"Ytrain\", \"Ytrain_Batch%d.npy\" % batch_id), allow_pickle=True)\n",
        "      # all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Even Class Distribution Datasets\", \"Ytrain\", \"Ytrain_Batch%d_even.npy\" % batch_id), allow_pickle=True)\n",
        "      # all_labels = np.array([item[1] for item in all_labels])\n",
        "\n",
        "      (train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "      train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "      all_images = train_images\n",
        "      all_labels = train_labels\n",
        "      \n",
        "      # one hot\n",
        "      # all_labels_one_hot = np.zeros((all_labels.size, 10))\n",
        "      # all_labels_one_hot[np.arange(all_labels.size),all_labels] = 1\n",
        "\n",
        "      # without one hot\n",
        "      all_labels_one_hot = np.expand_dims(all_labels, axis=-1)\n",
        "\n",
        "      # shuffle\n",
        "      indices = np.arange(all_images.shape[0])\n",
        "      np.random.shuffle(indices)\n",
        "      all_images = all_images[indices]\n",
        "      all_labels_one_hot = all_labels_one_hot[indices]\n",
        "\n",
        "      self.train_images = all_images\n",
        "      self.train_labels = all_labels_one_hot\n",
        "    \n",
        "    else:\n",
        "      # load images\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Stratified_Random_Sampling_Datasets\", \"Processed_Xtest_Batch%d.npy\") % batch_id)\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Even_Class_Distribution_Datasets\", \"Processed_Xest_Batch%d_even.npy\") % batch_id)\n",
        "      # all_images = np.load(os.path.join(project_root, \"Processed_Data_Batches\", \"Color_Even_Class_Distribution_Datasets\", \"Color_Processed_Xest_Batch%d_even.npy\") % batch_id)\n",
        "      \n",
        "      # add a dimension for channels if gray scale images\n",
        "      # if (len(all_images[0].shape) == 2):\n",
        "      #   all_images = np.expand_dims(all_images, axis=-1)\n",
        "\n",
        "      # load labels\n",
        "      # all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Stratified Random Sampling Datasets\", \"Ytest\", \"Ytest_Batch%d.npy\" % batch_id), allow_pickle=True)\n",
        "      # all_labels = np.load(os.path.join(project_root, \"Data Batches\", \"Even Class Distribution Datasets\", \"Ytest\", \"Yest_Batch%d_even.npy\" % batch_id), allow_pickle=True)\n",
        "      # all_labels = np.array([item[1] for item in all_labels])\n",
        "\n",
        "      (train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "      train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "      all_images = test_images\n",
        "      all_labels = test_labels\n",
        "\n",
        "      # one hot\n",
        "      all_labels_one_hot = np.zeros((all_labels.size, 10))\n",
        "      all_labels_one_hot[np.arange(all_labels.size),all_labels] = 1\n",
        "\n",
        "      # without one hot\n",
        "      # all_labels = np.expand_dims(all_labels, axis=-1)\n",
        "      \n",
        "      self.test_images = all_images\n",
        "      self.test_labels = all_labels_one_hot\n",
        "  \n",
        "  def clear(self):\n",
        "    self.train_images = None\n",
        "    self.validate_images = None\n",
        "    self.test_images = None\n",
        "    self.train_labels = None\n",
        "    self.validate_labels = None\n",
        "    self.test_labels = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOADsxqM3DwR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55934117-4c77-40eb-eb4b-a7ddd92212a3"
      },
      "source": [
        "# initialize CNN\n",
        "# myModel = OriginCNN()\n",
        "myModel = Res50()\n",
        "myModel.build()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_191 (Conv2D)             (None, 111, 111, 32) 864         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_188 (BatchN (None, 111, 111, 32) 96          conv2d_191[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 111, 111, 32) 0           batch_normalization_188[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_192 (Conv2D)             (None, 109, 109, 32) 9216        activation_188[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_189 (BatchN (None, 109, 109, 32) 96          conv2d_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_189 (Activation)     (None, 109, 109, 32) 0           batch_normalization_189[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_193 (Conv2D)             (None, 109, 109, 64) 18432       activation_189[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_190 (BatchN (None, 109, 109, 64) 192         conv2d_193[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_190 (Activation)     (None, 109, 109, 64) 0           batch_normalization_190[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling2D) (None, 54, 54, 64)   0           activation_190[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_194 (Conv2D)             (None, 54, 54, 80)   5120        max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_191 (BatchN (None, 54, 54, 80)   240         conv2d_194[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_191 (Activation)     (None, 54, 54, 80)   0           batch_normalization_191[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_195 (Conv2D)             (None, 52, 52, 192)  138240      activation_191[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_192 (BatchN (None, 52, 52, 192)  576         conv2d_195[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_192 (Activation)     (None, 52, 52, 192)  0           batch_normalization_192[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling2D) (None, 25, 25, 192)  0           activation_192[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_199 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_196 (BatchN (None, 25, 25, 64)   192         conv2d_199[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_196 (Activation)     (None, 25, 25, 64)   0           batch_normalization_196[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_197 (Conv2D)             (None, 25, 25, 48)   9216        max_pooling2d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_200 (Conv2D)             (None, 25, 25, 96)   55296       activation_196[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_194 (BatchN (None, 25, 25, 48)   144         conv2d_197[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_197 (BatchN (None, 25, 25, 96)   288         conv2d_200[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_194 (Activation)     (None, 25, 25, 48)   0           batch_normalization_194[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_197 (Activation)     (None, 25, 25, 96)   0           batch_normalization_197[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_18 (AveragePo (None, 25, 25, 192)  0           max_pooling2d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_196 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_198 (Conv2D)             (None, 25, 25, 64)   76800       activation_194[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_201 (Conv2D)             (None, 25, 25, 96)   82944       activation_197[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_202 (Conv2D)             (None, 25, 25, 32)   6144        average_pooling2d_18[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_193 (BatchN (None, 25, 25, 64)   192         conv2d_196[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_195 (BatchN (None, 25, 25, 64)   192         conv2d_198[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_198 (BatchN (None, 25, 25, 96)   288         conv2d_201[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_199 (BatchN (None, 25, 25, 32)   96          conv2d_202[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_193 (Activation)     (None, 25, 25, 64)   0           batch_normalization_193[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_195 (Activation)     (None, 25, 25, 64)   0           batch_normalization_195[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_198 (Activation)     (None, 25, 25, 96)   0           batch_normalization_198[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_199 (Activation)     (None, 25, 25, 32)   0           batch_normalization_199[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_193[0][0]             \n",
            "                                                                 activation_195[0][0]             \n",
            "                                                                 activation_198[0][0]             \n",
            "                                                                 activation_199[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_206 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_203 (BatchN (None, 25, 25, 64)   192         conv2d_206[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_203 (Activation)     (None, 25, 25, 64)   0           batch_normalization_203[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_204 (Conv2D)             (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_207 (Conv2D)             (None, 25, 25, 96)   55296       activation_203[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_201 (BatchN (None, 25, 25, 48)   144         conv2d_204[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_204 (BatchN (None, 25, 25, 96)   288         conv2d_207[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_201 (Activation)     (None, 25, 25, 48)   0           batch_normalization_201[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_204 (Activation)     (None, 25, 25, 96)   0           batch_normalization_204[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_19 (AveragePo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_203 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_205 (Conv2D)             (None, 25, 25, 64)   76800       activation_201[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_208 (Conv2D)             (None, 25, 25, 96)   82944       activation_204[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_209 (Conv2D)             (None, 25, 25, 64)   16384       average_pooling2d_19[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_200 (BatchN (None, 25, 25, 64)   192         conv2d_203[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_202 (BatchN (None, 25, 25, 64)   192         conv2d_205[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_205 (BatchN (None, 25, 25, 96)   288         conv2d_208[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_206 (BatchN (None, 25, 25, 64)   192         conv2d_209[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_200 (Activation)     (None, 25, 25, 64)   0           batch_normalization_200[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_202 (Activation)     (None, 25, 25, 64)   0           batch_normalization_202[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_205 (Activation)     (None, 25, 25, 96)   0           batch_normalization_205[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_206 (Activation)     (None, 25, 25, 64)   0           batch_normalization_206[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_200[0][0]             \n",
            "                                                                 activation_202[0][0]             \n",
            "                                                                 activation_205[0][0]             \n",
            "                                                                 activation_206[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_213 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_210 (BatchN (None, 25, 25, 64)   192         conv2d_213[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_210 (Activation)     (None, 25, 25, 64)   0           batch_normalization_210[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_211 (Conv2D)             (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_214 (Conv2D)             (None, 25, 25, 96)   55296       activation_210[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_208 (BatchN (None, 25, 25, 48)   144         conv2d_211[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_211 (BatchN (None, 25, 25, 96)   288         conv2d_214[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_208 (Activation)     (None, 25, 25, 48)   0           batch_normalization_208[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_211 (Activation)     (None, 25, 25, 96)   0           batch_normalization_211[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_20 (AveragePo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_210 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_212 (Conv2D)             (None, 25, 25, 64)   76800       activation_208[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_215 (Conv2D)             (None, 25, 25, 96)   82944       activation_211[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_216 (Conv2D)             (None, 25, 25, 64)   18432       average_pooling2d_20[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_207 (BatchN (None, 25, 25, 64)   192         conv2d_210[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_209 (BatchN (None, 25, 25, 64)   192         conv2d_212[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_212 (BatchN (None, 25, 25, 96)   288         conv2d_215[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_213 (BatchN (None, 25, 25, 64)   192         conv2d_216[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_207 (Activation)     (None, 25, 25, 64)   0           batch_normalization_207[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_209 (Activation)     (None, 25, 25, 64)   0           batch_normalization_209[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_212 (Activation)     (None, 25, 25, 96)   0           batch_normalization_212[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_213 (Activation)     (None, 25, 25, 64)   0           batch_normalization_213[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_207[0][0]             \n",
            "                                                                 activation_209[0][0]             \n",
            "                                                                 activation_212[0][0]             \n",
            "                                                                 activation_213[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_218 (Conv2D)             (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_215 (BatchN (None, 25, 25, 64)   192         conv2d_218[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_215 (Activation)     (None, 25, 25, 64)   0           batch_normalization_215[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_219 (Conv2D)             (None, 25, 25, 96)   55296       activation_215[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_216 (BatchN (None, 25, 25, 96)   288         conv2d_219[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_216 (Activation)     (None, 25, 25, 96)   0           batch_normalization_216[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_217 (Conv2D)             (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_220 (Conv2D)             (None, 12, 12, 96)   82944       activation_216[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_214 (BatchN (None, 12, 12, 384)  1152        conv2d_217[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_217 (BatchN (None, 12, 12, 96)   288         conv2d_220[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_214 (Activation)     (None, 12, 12, 384)  0           batch_normalization_214[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_217 (Activation)     (None, 12, 12, 96)   0           batch_normalization_217[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling2D) (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_214[0][0]             \n",
            "                                                                 activation_217[0][0]             \n",
            "                                                                 max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_225 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_222 (BatchN (None, 12, 12, 128)  384         conv2d_225[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_222 (Activation)     (None, 12, 12, 128)  0           batch_normalization_222[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_226 (Conv2D)             (None, 12, 12, 128)  114688      activation_222[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_223 (BatchN (None, 12, 12, 128)  384         conv2d_226[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_223 (Activation)     (None, 12, 12, 128)  0           batch_normalization_223[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_222 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_227 (Conv2D)             (None, 12, 12, 128)  114688      activation_223[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_219 (BatchN (None, 12, 12, 128)  384         conv2d_222[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_224 (BatchN (None, 12, 12, 128)  384         conv2d_227[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_219 (Activation)     (None, 12, 12, 128)  0           batch_normalization_219[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_224 (Activation)     (None, 12, 12, 128)  0           batch_normalization_224[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_223 (Conv2D)             (None, 12, 12, 128)  114688      activation_219[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_228 (Conv2D)             (None, 12, 12, 128)  114688      activation_224[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_220 (BatchN (None, 12, 12, 128)  384         conv2d_223[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_225 (BatchN (None, 12, 12, 128)  384         conv2d_228[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_220 (Activation)     (None, 12, 12, 128)  0           batch_normalization_220[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_225 (Activation)     (None, 12, 12, 128)  0           batch_normalization_225[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_21 (AveragePo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_221 (Conv2D)             (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_224 (Conv2D)             (None, 12, 12, 192)  172032      activation_220[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_229 (Conv2D)             (None, 12, 12, 192)  172032      activation_225[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_230 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_21[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_218 (BatchN (None, 12, 12, 192)  576         conv2d_221[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_221 (BatchN (None, 12, 12, 192)  576         conv2d_224[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_226 (BatchN (None, 12, 12, 192)  576         conv2d_229[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_227 (BatchN (None, 12, 12, 192)  576         conv2d_230[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_218 (Activation)     (None, 12, 12, 192)  0           batch_normalization_218[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_221 (Activation)     (None, 12, 12, 192)  0           batch_normalization_221[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_226 (Activation)     (None, 12, 12, 192)  0           batch_normalization_226[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_227 (Activation)     (None, 12, 12, 192)  0           batch_normalization_227[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_218[0][0]             \n",
            "                                                                 activation_221[0][0]             \n",
            "                                                                 activation_226[0][0]             \n",
            "                                                                 activation_227[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_235 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_232 (BatchN (None, 12, 12, 160)  480         conv2d_235[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_232 (Activation)     (None, 12, 12, 160)  0           batch_normalization_232[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_236 (Conv2D)             (None, 12, 12, 160)  179200      activation_232[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_233 (BatchN (None, 12, 12, 160)  480         conv2d_236[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_233 (Activation)     (None, 12, 12, 160)  0           batch_normalization_233[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_232 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_237 (Conv2D)             (None, 12, 12, 160)  179200      activation_233[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_229 (BatchN (None, 12, 12, 160)  480         conv2d_232[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_234 (BatchN (None, 12, 12, 160)  480         conv2d_237[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_229 (Activation)     (None, 12, 12, 160)  0           batch_normalization_229[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_234 (Activation)     (None, 12, 12, 160)  0           batch_normalization_234[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_233 (Conv2D)             (None, 12, 12, 160)  179200      activation_229[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_238 (Conv2D)             (None, 12, 12, 160)  179200      activation_234[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_230 (BatchN (None, 12, 12, 160)  480         conv2d_233[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_235 (BatchN (None, 12, 12, 160)  480         conv2d_238[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_230 (Activation)     (None, 12, 12, 160)  0           batch_normalization_230[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_235 (Activation)     (None, 12, 12, 160)  0           batch_normalization_235[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_22 (AveragePo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_231 (Conv2D)             (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_234 (Conv2D)             (None, 12, 12, 192)  215040      activation_230[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_239 (Conv2D)             (None, 12, 12, 192)  215040      activation_235[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_240 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_22[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_228 (BatchN (None, 12, 12, 192)  576         conv2d_231[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_231 (BatchN (None, 12, 12, 192)  576         conv2d_234[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_236 (BatchN (None, 12, 12, 192)  576         conv2d_239[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_237 (BatchN (None, 12, 12, 192)  576         conv2d_240[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_228 (Activation)     (None, 12, 12, 192)  0           batch_normalization_228[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_231 (Activation)     (None, 12, 12, 192)  0           batch_normalization_231[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_236 (Activation)     (None, 12, 12, 192)  0           batch_normalization_236[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_237 (Activation)     (None, 12, 12, 192)  0           batch_normalization_237[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_228[0][0]             \n",
            "                                                                 activation_231[0][0]             \n",
            "                                                                 activation_236[0][0]             \n",
            "                                                                 activation_237[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_245 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_242 (BatchN (None, 12, 12, 160)  480         conv2d_245[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_242 (Activation)     (None, 12, 12, 160)  0           batch_normalization_242[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_246 (Conv2D)             (None, 12, 12, 160)  179200      activation_242[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_243 (BatchN (None, 12, 12, 160)  480         conv2d_246[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_243 (Activation)     (None, 12, 12, 160)  0           batch_normalization_243[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_242 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_247 (Conv2D)             (None, 12, 12, 160)  179200      activation_243[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_239 (BatchN (None, 12, 12, 160)  480         conv2d_242[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_244 (BatchN (None, 12, 12, 160)  480         conv2d_247[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_239 (Activation)     (None, 12, 12, 160)  0           batch_normalization_239[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_244 (Activation)     (None, 12, 12, 160)  0           batch_normalization_244[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_243 (Conv2D)             (None, 12, 12, 160)  179200      activation_239[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_248 (Conv2D)             (None, 12, 12, 160)  179200      activation_244[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_240 (BatchN (None, 12, 12, 160)  480         conv2d_243[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_245 (BatchN (None, 12, 12, 160)  480         conv2d_248[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_240 (Activation)     (None, 12, 12, 160)  0           batch_normalization_240[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_245 (Activation)     (None, 12, 12, 160)  0           batch_normalization_245[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_23 (AveragePo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_241 (Conv2D)             (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_244 (Conv2D)             (None, 12, 12, 192)  215040      activation_240[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_249 (Conv2D)             (None, 12, 12, 192)  215040      activation_245[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_250 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_23[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_238 (BatchN (None, 12, 12, 192)  576         conv2d_241[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_241 (BatchN (None, 12, 12, 192)  576         conv2d_244[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_246 (BatchN (None, 12, 12, 192)  576         conv2d_249[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_247 (BatchN (None, 12, 12, 192)  576         conv2d_250[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_238 (Activation)     (None, 12, 12, 192)  0           batch_normalization_238[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_241 (Activation)     (None, 12, 12, 192)  0           batch_normalization_241[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_246 (Activation)     (None, 12, 12, 192)  0           batch_normalization_246[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_247 (Activation)     (None, 12, 12, 192)  0           batch_normalization_247[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_238[0][0]             \n",
            "                                                                 activation_241[0][0]             \n",
            "                                                                 activation_246[0][0]             \n",
            "                                                                 activation_247[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_255 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_252 (BatchN (None, 12, 12, 192)  576         conv2d_255[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_252 (Activation)     (None, 12, 12, 192)  0           batch_normalization_252[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_256 (Conv2D)             (None, 12, 12, 192)  258048      activation_252[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_253 (BatchN (None, 12, 12, 192)  576         conv2d_256[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_253 (Activation)     (None, 12, 12, 192)  0           batch_normalization_253[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_252 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_257 (Conv2D)             (None, 12, 12, 192)  258048      activation_253[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_249 (BatchN (None, 12, 12, 192)  576         conv2d_252[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_254 (BatchN (None, 12, 12, 192)  576         conv2d_257[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_249 (Activation)     (None, 12, 12, 192)  0           batch_normalization_249[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_254 (Activation)     (None, 12, 12, 192)  0           batch_normalization_254[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_253 (Conv2D)             (None, 12, 12, 192)  258048      activation_249[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_258 (Conv2D)             (None, 12, 12, 192)  258048      activation_254[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_250 (BatchN (None, 12, 12, 192)  576         conv2d_253[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_255 (BatchN (None, 12, 12, 192)  576         conv2d_258[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_250 (Activation)     (None, 12, 12, 192)  0           batch_normalization_250[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_255 (Activation)     (None, 12, 12, 192)  0           batch_normalization_255[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_24 (AveragePo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_251 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_254 (Conv2D)             (None, 12, 12, 192)  258048      activation_250[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_259 (Conv2D)             (None, 12, 12, 192)  258048      activation_255[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_260 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_24[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_248 (BatchN (None, 12, 12, 192)  576         conv2d_251[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_251 (BatchN (None, 12, 12, 192)  576         conv2d_254[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_256 (BatchN (None, 12, 12, 192)  576         conv2d_259[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_257 (BatchN (None, 12, 12, 192)  576         conv2d_260[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_248 (Activation)     (None, 12, 12, 192)  0           batch_normalization_248[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_251 (Activation)     (None, 12, 12, 192)  0           batch_normalization_251[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_256 (Activation)     (None, 12, 12, 192)  0           batch_normalization_256[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_257 (Activation)     (None, 12, 12, 192)  0           batch_normalization_257[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_248[0][0]             \n",
            "                                                                 activation_251[0][0]             \n",
            "                                                                 activation_256[0][0]             \n",
            "                                                                 activation_257[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_263 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_260 (BatchN (None, 12, 12, 192)  576         conv2d_263[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_260 (Activation)     (None, 12, 12, 192)  0           batch_normalization_260[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_264 (Conv2D)             (None, 12, 12, 192)  258048      activation_260[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_261 (BatchN (None, 12, 12, 192)  576         conv2d_264[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_261 (Activation)     (None, 12, 12, 192)  0           batch_normalization_261[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_261 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_265 (Conv2D)             (None, 12, 12, 192)  258048      activation_261[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_258 (BatchN (None, 12, 12, 192)  576         conv2d_261[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_262 (BatchN (None, 12, 12, 192)  576         conv2d_265[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_258 (Activation)     (None, 12, 12, 192)  0           batch_normalization_258[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_262 (Activation)     (None, 12, 12, 192)  0           batch_normalization_262[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_262 (Conv2D)             (None, 5, 5, 320)    552960      activation_258[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_266 (Conv2D)             (None, 5, 5, 192)    331776      activation_262[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_259 (BatchN (None, 5, 5, 320)    960         conv2d_262[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_263 (BatchN (None, 5, 5, 192)    576         conv2d_266[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_259 (Activation)     (None, 5, 5, 320)    0           batch_normalization_259[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_263 (Activation)     (None, 5, 5, 192)    0           batch_normalization_263[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling2D) (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_259[0][0]             \n",
            "                                                                 activation_263[0][0]             \n",
            "                                                                 max_pooling2d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_271 (Conv2D)             (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_268 (BatchN (None, 5, 5, 448)    1344        conv2d_271[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_268 (Activation)     (None, 5, 5, 448)    0           batch_normalization_268[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_268 (Conv2D)             (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_272 (Conv2D)             (None, 5, 5, 384)    1548288     activation_268[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_265 (BatchN (None, 5, 5, 384)    1152        conv2d_268[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_269 (BatchN (None, 5, 5, 384)    1152        conv2d_272[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_265 (Activation)     (None, 5, 5, 384)    0           batch_normalization_265[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_269 (Activation)     (None, 5, 5, 384)    0           batch_normalization_269[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_269 (Conv2D)             (None, 5, 5, 384)    442368      activation_265[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_270 (Conv2D)             (None, 5, 5, 384)    442368      activation_265[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_273 (Conv2D)             (None, 5, 5, 384)    442368      activation_269[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_274 (Conv2D)             (None, 5, 5, 384)    442368      activation_269[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_25 (AveragePo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_267 (Conv2D)             (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_266 (BatchN (None, 5, 5, 384)    1152        conv2d_269[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_267 (BatchN (None, 5, 5, 384)    1152        conv2d_270[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_270 (BatchN (None, 5, 5, 384)    1152        conv2d_273[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_271 (BatchN (None, 5, 5, 384)    1152        conv2d_274[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_275 (Conv2D)             (None, 5, 5, 192)    245760      average_pooling2d_25[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_264 (BatchN (None, 5, 5, 320)    960         conv2d_267[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_266 (Activation)     (None, 5, 5, 384)    0           batch_normalization_266[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_267 (Activation)     (None, 5, 5, 384)    0           batch_normalization_267[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_270 (Activation)     (None, 5, 5, 384)    0           batch_normalization_270[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_271 (Activation)     (None, 5, 5, 384)    0           batch_normalization_271[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_272 (BatchN (None, 5, 5, 192)    576         conv2d_275[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_264 (Activation)     (None, 5, 5, 320)    0           batch_normalization_264[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_266[0][0]             \n",
            "                                                                 activation_267[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 5, 5, 768)    0           activation_270[0][0]             \n",
            "                                                                 activation_271[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_272 (Activation)     (None, 5, 5, 192)    0           batch_normalization_272[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_264[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_4[0][0]              \n",
            "                                                                 activation_272[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_280 (Conv2D)             (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_277 (BatchN (None, 5, 5, 448)    1344        conv2d_280[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_277 (Activation)     (None, 5, 5, 448)    0           batch_normalization_277[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_277 (Conv2D)             (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_281 (Conv2D)             (None, 5, 5, 384)    1548288     activation_277[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_274 (BatchN (None, 5, 5, 384)    1152        conv2d_277[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_278 (BatchN (None, 5, 5, 384)    1152        conv2d_281[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_274 (Activation)     (None, 5, 5, 384)    0           batch_normalization_274[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_278 (Activation)     (None, 5, 5, 384)    0           batch_normalization_278[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_278 (Conv2D)             (None, 5, 5, 384)    442368      activation_274[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_279 (Conv2D)             (None, 5, 5, 384)    442368      activation_274[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_282 (Conv2D)             (None, 5, 5, 384)    442368      activation_278[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_283 (Conv2D)             (None, 5, 5, 384)    442368      activation_278[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_26 (AveragePo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_276 (Conv2D)             (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_275 (BatchN (None, 5, 5, 384)    1152        conv2d_278[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_276 (BatchN (None, 5, 5, 384)    1152        conv2d_279[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_279 (BatchN (None, 5, 5, 384)    1152        conv2d_282[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_280 (BatchN (None, 5, 5, 384)    1152        conv2d_283[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_284 (Conv2D)             (None, 5, 5, 192)    393216      average_pooling2d_26[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_273 (BatchN (None, 5, 5, 320)    960         conv2d_276[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_275 (Activation)     (None, 5, 5, 384)    0           batch_normalization_275[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_276 (Activation)     (None, 5, 5, 384)    0           batch_normalization_276[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_279 (Activation)     (None, 5, 5, 384)    0           batch_normalization_279[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_280 (Activation)     (None, 5, 5, 384)    0           batch_normalization_280[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_281 (BatchN (None, 5, 5, 192)    576         conv2d_284[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_273 (Activation)     (None, 5, 5, 320)    0           batch_normalization_273[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_275[0][0]             \n",
            "                                                                 activation_276[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 5, 5, 768)    0           activation_279[0][0]             \n",
            "                                                                 activation_280[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_281 (Activation)     (None, 5, 5, 192)    0           batch_normalization_281[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_273[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_5[0][0]              \n",
            "                                                                 activation_281[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_2 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 512)          1049088     global_average_pooling2d_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 2)            1026        dense_6[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 22,852,898\n",
            "Trainable params: 22,818,466\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrJnfPqP3DwS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbb0a8bb-6cee-44e2-d477-22730e82c5cd"
      },
      "source": [
        "# training process\n",
        "datagen = ImageDataGenerator(        \n",
        "            rotation_range=20,\n",
        "            width_shift_range=0.1,  \n",
        "            height_shift_range=0.1,    \n",
        "            shear_range=0.1,        \n",
        "            zoom_range=0.1,        \n",
        "            horizontal_flip=True,         \n",
        "            fill_mode='constant', cval=0,\n",
        "            channel_shift_range=20,\n",
        "            brightness_range=[0.5,1.5],\n",
        "            validation_split=0.1,\n",
        "            rescale=1.0/255\n",
        "            )\n",
        "file_num = 9\n",
        "epoch_num = 30\n",
        "history_array = np.zeros((file_num, epoch_num, 4))\n",
        "for epoch in range(epoch_num):\n",
        "  print(\"\\n\\nstart epoch %d\" % epoch)\n",
        "  for i in range(file_num):\n",
        "    # load data\n",
        "    myData = DR_resized(True, i, 32, 0.1, (224, 224))\n",
        "    # myData = DR_resized(True, i, 32, 0.1)\n",
        "    print(\"data batch %d loaded\" % i)\n",
        "\n",
        "    history = myModel.train(myData.train_images, myData.train_labels, epochs=1)\n",
        "    # history = myModel.train(myData.train_images, myData.train_labels, epochs=1, datagen=datagen)\n",
        "    history_array[i, epoch, 0] = history.history['loss'][0]\n",
        "    history_array[i, epoch, 1] = history.history['accuracy'][0]\n",
        "    history_array[i, epoch, 2] = history.history['val_loss'][0]\n",
        "    history_array[i, epoch, 3] = history.history['val_accuracy'][0]\n",
        "    myData.clear()\n",
        "    gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "start epoch 0\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 11s 1s/step - loss: 0.9627 - accuracy: 0.4551 - val_loss: 34.9457 - val_accuracy: 0.3846\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 1.9826 - accuracy: 0.4775 - val_loss: 36261.0234 - val_accuracy: 0.3846\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 2s 520ms/step - loss: 1.0905 - accuracy: 0.5045 - val_loss: 26442.1211 - val_accuracy: 0.3846\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 2s 527ms/step - loss: 2.1377 - accuracy: 0.4775 - val_loss: 92953.7578 - val_accuracy: 0.3846\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 2s 523ms/step - loss: 0.8382 - accuracy: 0.5495 - val_loss: 960115.6875 - val_accuracy: 0.3846\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 1.0982 - accuracy: 0.5135 - val_loss: 596613.2500 - val_accuracy: 0.3846\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 2s 526ms/step - loss: 0.7675 - accuracy: 0.5045 - val_loss: 75901.1094 - val_accuracy: 0.6154\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 2s 527ms/step - loss: 1.0849 - accuracy: 0.5225 - val_loss: 35467.4492 - val_accuracy: 0.6154\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 0.7462 - accuracy: 0.5135 - val_loss: 110878.1328 - val_accuracy: 0.3846\n",
            "\n",
            "\n",
            "start epoch 1\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 0.7448 - accuracy: 0.5135 - val_loss: 63649.6836 - val_accuracy: 0.3846\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 0.7365 - accuracy: 0.5405 - val_loss: 16637.0039 - val_accuracy: 0.3846\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 2s 521ms/step - loss: 0.7671 - accuracy: 0.4414 - val_loss: 5052.8872 - val_accuracy: 0.6154\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 2s 526ms/step - loss: 0.7403 - accuracy: 0.4775 - val_loss: 2749.2249 - val_accuracy: 0.6154\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 0.7159 - accuracy: 0.5135 - val_loss: 705.1897 - val_accuracy: 0.6154\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 0.7109 - accuracy: 0.5135 - val_loss: 39.8723 - val_accuracy: 0.3846\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 0.6991 - accuracy: 0.5225 - val_loss: 244.6027 - val_accuracy: 0.3846\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 0.6945 - accuracy: 0.5315 - val_loss: 530.1335 - val_accuracy: 0.3846\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 0.7300 - accuracy: 0.4775 - val_loss: 98.1594 - val_accuracy: 0.3846\n",
            "\n",
            "\n",
            "start epoch 2\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 2s 527ms/step - loss: 0.6749 - accuracy: 0.5135 - val_loss: 0.7804 - val_accuracy: 0.3846\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 0.7318 - accuracy: 0.5135 - val_loss: 0.7378 - val_accuracy: 0.3846\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 2s 526ms/step - loss: 0.6959 - accuracy: 0.4775 - val_loss: 0.7106 - val_accuracy: 0.3846\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 0.7000 - accuracy: 0.4505 - val_loss: 0.7146 - val_accuracy: 0.3846\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 2s 526ms/step - loss: 0.6888 - accuracy: 0.5045 - val_loss: 0.7397 - val_accuracy: 0.3846\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 0.7497 - accuracy: 0.5135 - val_loss: 0.7351 - val_accuracy: 0.3846\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 2s 524ms/step - loss: 0.7573 - accuracy: 0.5856 - val_loss: 0.7144 - val_accuracy: 0.3846\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 2s 524ms/step - loss: 0.6790 - accuracy: 0.4865 - val_loss: 0.7041 - val_accuracy: 0.3846\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 2s 525ms/step - loss: 0.6884 - accuracy: 0.5045 - val_loss: 0.6953 - val_accuracy: 0.3846\n",
            "\n",
            "\n",
            "start epoch 3\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 2s 525ms/step - loss: 0.6906 - accuracy: 0.5045 - val_loss: 0.7018 - val_accuracy: 0.3846\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 0.7210 - accuracy: 0.5045 - val_loss: 0.7018 - val_accuracy: 0.3846\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 2s 526ms/step - loss: 0.6933 - accuracy: 0.5766 - val_loss: 0.7045 - val_accuracy: 0.3846\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 2s 526ms/step - loss: 0.7118 - accuracy: 0.4595 - val_loss: 0.6970 - val_accuracy: 0.3846\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 0.7056 - accuracy: 0.5045 - val_loss: 0.6967 - val_accuracy: 0.3846\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 2s 526ms/step - loss: 0.6999 - accuracy: 0.4414 - val_loss: 0.7019 - val_accuracy: 0.3846\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 2s 524ms/step - loss: 0.7140 - accuracy: 0.4685 - val_loss: 0.6966 - val_accuracy: 0.3846\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 2s 524ms/step - loss: 0.6914 - accuracy: 0.4955 - val_loss: 0.6941 - val_accuracy: 0.3846\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 2s 525ms/step - loss: 0.6859 - accuracy: 0.5135 - val_loss: 0.6958 - val_accuracy: 0.3846\n",
            "\n",
            "\n",
            "start epoch 4\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 2s 522ms/step - loss: 0.6735 - accuracy: 0.5405 - val_loss: 0.7013 - val_accuracy: 0.3846\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 2s 527ms/step - loss: 0.7394 - accuracy: 0.4685 - val_loss: 0.6972 - val_accuracy: 0.3846\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 2s 522ms/step - loss: 0.7270 - accuracy: 0.5225 - val_loss: 0.6906 - val_accuracy: 0.6154\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 2s 525ms/step - loss: 0.7072 - accuracy: 0.4865 - val_loss: 0.6897 - val_accuracy: 0.6154\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 0.7418 - accuracy: 0.4865 - val_loss: 0.6966 - val_accuracy: 0.3846\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 0.7141 - accuracy: 0.4505 - val_loss: 0.6969 - val_accuracy: 0.3846\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 0.7006 - accuracy: 0.5045 - val_loss: 0.6973 - val_accuracy: 0.3846\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 0.6833 - accuracy: 0.5405 - val_loss: 0.6959 - val_accuracy: 0.3846\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 2s 526ms/step - loss: 0.6865 - accuracy: 0.4955 - val_loss: 0.6932 - val_accuracy: 0.3846\n",
            "\n",
            "\n",
            "start epoch 5\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 2s 525ms/step - loss: 0.6917 - accuracy: 0.5135 - val_loss: 0.6942 - val_accuracy: 0.3846\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 0.6944 - accuracy: 0.4955 - val_loss: 0.6959 - val_accuracy: 0.3846\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 0.6808 - accuracy: 0.4685 - val_loss: 0.6924 - val_accuracy: 0.6154\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 2s 525ms/step - loss: 0.6967 - accuracy: 0.4775 - val_loss: 0.6891 - val_accuracy: 0.6154\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 0.7046 - accuracy: 0.4865 - val_loss: 0.6917 - val_accuracy: 0.6154\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 0.7316 - accuracy: 0.5586 - val_loss: 0.7034 - val_accuracy: 0.3846\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 2s 525ms/step - loss: 0.7644 - accuracy: 0.5045 - val_loss: 0.7155 - val_accuracy: 0.3846\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 2s 527ms/step - loss: 0.6940 - accuracy: 0.5135 - val_loss: 0.7106 - val_accuracy: 0.3846\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 2s 523ms/step - loss: 0.6914 - accuracy: 0.5045 - val_loss: 0.7044 - val_accuracy: 0.3846\n",
            "\n",
            "\n",
            "start epoch 6\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 2s 524ms/step - loss: 0.6946 - accuracy: 0.4685 - val_loss: 0.7021 - val_accuracy: 0.3846\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 2s 527ms/step - loss: 0.7186 - accuracy: 0.5676 - val_loss: 0.7074 - val_accuracy: 0.3846\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 2s 522ms/step - loss: 0.6695 - accuracy: 0.5135 - val_loss: 0.7132 - val_accuracy: 0.3846\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 0.8057 - accuracy: 0.5135 - val_loss: 0.7115 - val_accuracy: 0.3846\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 2s 524ms/step - loss: 0.6776 - accuracy: 0.5135 - val_loss: 0.7056 - val_accuracy: 0.3846\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 2s 527ms/step - loss: 0.7019 - accuracy: 0.5315 - val_loss: 0.7037 - val_accuracy: 0.3846\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 2s 523ms/step - loss: 0.6937 - accuracy: 0.5135 - val_loss: 0.7058 - val_accuracy: 0.3846\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 0.6835 - accuracy: 0.5135 - val_loss: 0.7062 - val_accuracy: 0.3846\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 2s 527ms/step - loss: 0.6867 - accuracy: 0.5135 - val_loss: 0.7064 - val_accuracy: 0.3846\n",
            "\n",
            "\n",
            "start epoch 7\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 2s 524ms/step - loss: 0.6732 - accuracy: 0.5135 - val_loss: 0.7031 - val_accuracy: 0.3846\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 0.6999 - accuracy: 0.5135 - val_loss: 0.7023 - val_accuracy: 0.3846\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 2s 526ms/step - loss: 0.6768 - accuracy: 0.5045 - val_loss: 0.6987 - val_accuracy: 0.3846\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 2s 525ms/step - loss: 0.7116 - accuracy: 0.5225 - val_loss: 0.6984 - val_accuracy: 0.3846\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 0.6968 - accuracy: 0.4955 - val_loss: 0.7028 - val_accuracy: 0.3846\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 2s 524ms/step - loss: 0.7190 - accuracy: 0.3964 - val_loss: 0.7044 - val_accuracy: 0.3846\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 0.7154 - accuracy: 0.5045 - val_loss: 0.7071 - val_accuracy: 0.3846\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 2s 522ms/step - loss: 0.7090 - accuracy: 0.4955 - val_loss: 0.7066 - val_accuracy: 0.3846\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 2s 523ms/step - loss: 0.6826 - accuracy: 0.5135 - val_loss: 0.7013 - val_accuracy: 0.3846\n",
            "\n",
            "\n",
            "start epoch 8\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 2s 526ms/step - loss: 0.6838 - accuracy: 0.4775 - val_loss: 0.6985 - val_accuracy: 0.3846\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 0.7295 - accuracy: 0.4865 - val_loss: 0.6993 - val_accuracy: 0.3846\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 2s 523ms/step - loss: 0.7332 - accuracy: 0.4685 - val_loss: 0.7056 - val_accuracy: 0.3846\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 0.7077 - accuracy: 0.4865 - val_loss: 0.7106 - val_accuracy: 0.3846\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 0.6919 - accuracy: 0.5045 - val_loss: 0.7156 - val_accuracy: 0.3846\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 2s 522ms/step - loss: 0.7055 - accuracy: 0.5135 - val_loss: 0.7151 - val_accuracy: 0.3846\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 0.7005 - accuracy: 0.5045 - val_loss: 0.7079 - val_accuracy: 0.3846\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 0.6962 - accuracy: 0.5405 - val_loss: 0.7052 - val_accuracy: 0.3846\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 0.6907 - accuracy: 0.4865 - val_loss: 0.7078 - val_accuracy: 0.3846\n",
            "\n",
            "\n",
            "start epoch 9\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 2s 523ms/step - loss: 0.6880 - accuracy: 0.5135 - val_loss: 0.7106 - val_accuracy: 0.3846\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 0.6816 - accuracy: 0.5135 - val_loss: 0.7058 - val_accuracy: 0.3846\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 2s 526ms/step - loss: 0.6764 - accuracy: 0.5225 - val_loss: 0.6427 - val_accuracy: 0.3846\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 2s 524ms/step - loss: 0.7329 - accuracy: 0.4775 - val_loss: 0.6897 - val_accuracy: 0.6154\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 2s 523ms/step - loss: 0.6897 - accuracy: 0.5135 - val_loss: 0.6903 - val_accuracy: 0.6154\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 0.7198 - accuracy: 0.4865 - val_loss: 0.7133 - val_accuracy: 0.3846\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 2s 525ms/step - loss: 0.7064 - accuracy: 0.4775 - val_loss: 0.7100 - val_accuracy: 0.3846\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 0.7181 - accuracy: 0.5135 - val_loss: 0.7057 - val_accuracy: 0.3846\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 2s 522ms/step - loss: 0.6843 - accuracy: 0.4685 - val_loss: 0.7018 - val_accuracy: 0.3846\n",
            "\n",
            "\n",
            "start epoch 10\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 2s 524ms/step - loss: 0.6926 - accuracy: 0.5045 - val_loss: 0.7006 - val_accuracy: 0.3846\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 2s 522ms/step - loss: 0.6918 - accuracy: 0.4324 - val_loss: 0.6930 - val_accuracy: 0.6154\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 2s 522ms/step - loss: 0.7050 - accuracy: 0.4955 - val_loss: 0.6898 - val_accuracy: 0.6154\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 2s 524ms/step - loss: 0.7318 - accuracy: 0.4775 - val_loss: 0.6985 - val_accuracy: 0.3846\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 2s 524ms/step - loss: 0.6972 - accuracy: 0.4234 - val_loss: 0.7094 - val_accuracy: 0.3846\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 0.6972 - accuracy: 0.5135 - val_loss: 0.7108 - val_accuracy: 0.3846\n",
            "data batch 6 loaded\n",
            "4/4 [==============================] - 2s 525ms/step - loss: 0.6817 - accuracy: 0.5135 - val_loss: 0.7107 - val_accuracy: 0.3846\n",
            "data batch 7 loaded\n",
            "4/4 [==============================] - 2s 522ms/step - loss: 0.6856 - accuracy: 0.5135 - val_loss: 0.7107 - val_accuracy: 0.3846\n",
            "data batch 8 loaded\n",
            "4/4 [==============================] - 2s 526ms/step - loss: 0.6814 - accuracy: 0.5135 - val_loss: 0.7069 - val_accuracy: 0.3846\n",
            "\n",
            "\n",
            "start epoch 11\n",
            "data batch 0 loaded\n",
            "4/4 [==============================] - 2s 527ms/step - loss: 0.6700 - accuracy: 0.5135 - val_loss: 0.7016 - val_accuracy: 0.3846\n",
            "data batch 1 loaded\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 0.7111 - accuracy: 0.4505 - val_loss: 0.6925 - val_accuracy: 0.6154\n",
            "data batch 2 loaded\n",
            "4/4 [==============================] - 2s 523ms/step - loss: 0.6756 - accuracy: 0.5135 - val_loss: 0.6877 - val_accuracy: 0.6154\n",
            "data batch 3 loaded\n",
            "4/4 [==============================] - 2s 519ms/step - loss: 0.7211 - accuracy: 0.4775 - val_loss: 0.6866 - val_accuracy: 0.6154\n",
            "data batch 4 loaded\n",
            "4/4 [==============================] - 2s 516ms/step - loss: 0.6882 - accuracy: 0.5135 - val_loss: 0.6863 - val_accuracy: 0.6154\n",
            "data batch 5 loaded\n",
            "4/4 [==============================] - 2s 523ms/step - loss: 0.7054 - accuracy: 0.4865 - val_loss: 0.7861 - val_accuracy: 0.5385\n",
            "data batch 6 loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0svWpVPkiUsK"
      },
      "source": [
        "# testing process\n",
        "file_num = 2\n",
        "num_list = []\n",
        "acc_list = []\n",
        "m = tf.keras.metrics.CategoricalAccuracy()\n",
        "for i in range(file_num):\n",
        "  # myData = DR_resized(False, i, 32, 0.1, (224, 224))\n",
        "  myData = DR_resized(False, i, 32, 0.1)\n",
        "  num, acc = myModel.evaluate(myData.test_images, myData.test_labels)\n",
        "  print(num, acc)\n",
        "  # p = myModel.model.predict(myData.test_images)\n",
        "  # print(p)\n",
        "  # m.update_state(p, myData.test_labels)\n",
        "  # num_list.append(num)\n",
        "  # acc_list.append(acc)\n",
        "  myData.clear()\n",
        "  gc.collect()\n",
        "\n",
        "print(m.result().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqL9za1Dkqjy"
      },
      "source": [
        "# compute overall accuracy\n",
        "num_list = np.array(num_list)\n",
        "acc_list = np.array(acc_list)\n",
        "acc_overall = (num_list * acc_list).sum() / num_list.sum()\n",
        "print(acc_overall)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBuQpdk7vC25"
      },
      "source": [
        "from datetime import datetime\n",
        "now = datetime.now()\n",
        "dt_string = now.strftime(\"%d-%m-%Y %H:%M:%S\")\n",
        "print(\"date and time =\", dt_string)\n",
        "myModel.save_model(os.path.join(project_root, \"Trained Models\", dt_string))\n",
        "np.save(os.path.join(project_root, \"Trained Models\", dt_string, \"history\"), history_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2QDEecGwGTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5921edd5-b600-49f1-ad92-89ffc1f338e6"
      },
      "source": [
        "# this part is for loading parameters and extracting features\n",
        "# load parameters\n",
        "parameter_version = \"20-04-2021 17:43:17\"\n",
        "if not os.path.exists(os.path.join(project_root, \"features\", parameter_version)):\n",
        "    os.mkdir(os.path.join(project_root, \"features\", parameter_version))\n",
        "\n",
        "# my_model_pretrained = OriginCNN()\n",
        "my_model_pretrained = Res50()\n",
        "my_model_pretrained.build()\n",
        "my_model_pretrained.load_model(os.path.join(project_root, \"Trained Models\", parameter_version))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_285 (Conv2D)             (None, 111, 111, 32) 864         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_282 (BatchN (None, 111, 111, 32) 96          conv2d_285[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_282 (Activation)     (None, 111, 111, 32) 0           batch_normalization_282[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_286 (Conv2D)             (None, 109, 109, 32) 9216        activation_282[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_283 (BatchN (None, 109, 109, 32) 96          conv2d_286[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_283 (Activation)     (None, 109, 109, 32) 0           batch_normalization_283[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_287 (Conv2D)             (None, 109, 109, 64) 18432       activation_283[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_284 (BatchN (None, 109, 109, 64) 192         conv2d_287[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_284 (Activation)     (None, 109, 109, 64) 0           batch_normalization_284[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling2D) (None, 54, 54, 64)   0           activation_284[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_288 (Conv2D)             (None, 54, 54, 80)   5120        max_pooling2d_15[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_285 (BatchN (None, 54, 54, 80)   240         conv2d_288[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_285 (Activation)     (None, 54, 54, 80)   0           batch_normalization_285[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_289 (Conv2D)             (None, 52, 52, 192)  138240      activation_285[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_286 (BatchN (None, 52, 52, 192)  576         conv2d_289[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_286 (Activation)     (None, 52, 52, 192)  0           batch_normalization_286[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling2D) (None, 25, 25, 192)  0           activation_286[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_293 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_290 (BatchN (None, 25, 25, 64)   192         conv2d_293[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_290 (Activation)     (None, 25, 25, 64)   0           batch_normalization_290[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_291 (Conv2D)             (None, 25, 25, 48)   9216        max_pooling2d_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_294 (Conv2D)             (None, 25, 25, 96)   55296       activation_290[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_288 (BatchN (None, 25, 25, 48)   144         conv2d_291[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_291 (BatchN (None, 25, 25, 96)   288         conv2d_294[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_288 (Activation)     (None, 25, 25, 48)   0           batch_normalization_288[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_291 (Activation)     (None, 25, 25, 96)   0           batch_normalization_291[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_27 (AveragePo (None, 25, 25, 192)  0           max_pooling2d_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_290 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_292 (Conv2D)             (None, 25, 25, 64)   76800       activation_288[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_295 (Conv2D)             (None, 25, 25, 96)   82944       activation_291[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_296 (Conv2D)             (None, 25, 25, 32)   6144        average_pooling2d_27[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_287 (BatchN (None, 25, 25, 64)   192         conv2d_290[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_289 (BatchN (None, 25, 25, 64)   192         conv2d_292[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_292 (BatchN (None, 25, 25, 96)   288         conv2d_295[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_293 (BatchN (None, 25, 25, 32)   96          conv2d_296[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_287 (Activation)     (None, 25, 25, 64)   0           batch_normalization_287[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_289 (Activation)     (None, 25, 25, 64)   0           batch_normalization_289[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_292 (Activation)     (None, 25, 25, 96)   0           batch_normalization_292[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_293 (Activation)     (None, 25, 25, 32)   0           batch_normalization_293[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_287[0][0]             \n",
            "                                                                 activation_289[0][0]             \n",
            "                                                                 activation_292[0][0]             \n",
            "                                                                 activation_293[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_300 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_297 (BatchN (None, 25, 25, 64)   192         conv2d_300[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_297 (Activation)     (None, 25, 25, 64)   0           batch_normalization_297[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_298 (Conv2D)             (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_301 (Conv2D)             (None, 25, 25, 96)   55296       activation_297[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_295 (BatchN (None, 25, 25, 48)   144         conv2d_298[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_298 (BatchN (None, 25, 25, 96)   288         conv2d_301[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_295 (Activation)     (None, 25, 25, 48)   0           batch_normalization_295[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_298 (Activation)     (None, 25, 25, 96)   0           batch_normalization_298[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_28 (AveragePo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_297 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_299 (Conv2D)             (None, 25, 25, 64)   76800       activation_295[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_302 (Conv2D)             (None, 25, 25, 96)   82944       activation_298[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_303 (Conv2D)             (None, 25, 25, 64)   16384       average_pooling2d_28[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_294 (BatchN (None, 25, 25, 64)   192         conv2d_297[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_296 (BatchN (None, 25, 25, 64)   192         conv2d_299[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_299 (BatchN (None, 25, 25, 96)   288         conv2d_302[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_300 (BatchN (None, 25, 25, 64)   192         conv2d_303[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_294 (Activation)     (None, 25, 25, 64)   0           batch_normalization_294[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_296 (Activation)     (None, 25, 25, 64)   0           batch_normalization_296[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_299 (Activation)     (None, 25, 25, 96)   0           batch_normalization_299[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_300 (Activation)     (None, 25, 25, 64)   0           batch_normalization_300[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_294[0][0]             \n",
            "                                                                 activation_296[0][0]             \n",
            "                                                                 activation_299[0][0]             \n",
            "                                                                 activation_300[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_307 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_304 (BatchN (None, 25, 25, 64)   192         conv2d_307[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_304 (Activation)     (None, 25, 25, 64)   0           batch_normalization_304[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_305 (Conv2D)             (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_308 (Conv2D)             (None, 25, 25, 96)   55296       activation_304[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_302 (BatchN (None, 25, 25, 48)   144         conv2d_305[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_305 (BatchN (None, 25, 25, 96)   288         conv2d_308[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_302 (Activation)     (None, 25, 25, 48)   0           batch_normalization_302[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_305 (Activation)     (None, 25, 25, 96)   0           batch_normalization_305[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_29 (AveragePo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_304 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_306 (Conv2D)             (None, 25, 25, 64)   76800       activation_302[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_309 (Conv2D)             (None, 25, 25, 96)   82944       activation_305[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_310 (Conv2D)             (None, 25, 25, 64)   18432       average_pooling2d_29[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_301 (BatchN (None, 25, 25, 64)   192         conv2d_304[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_303 (BatchN (None, 25, 25, 64)   192         conv2d_306[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_306 (BatchN (None, 25, 25, 96)   288         conv2d_309[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_307 (BatchN (None, 25, 25, 64)   192         conv2d_310[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_301 (Activation)     (None, 25, 25, 64)   0           batch_normalization_301[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_303 (Activation)     (None, 25, 25, 64)   0           batch_normalization_303[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_306 (Activation)     (None, 25, 25, 96)   0           batch_normalization_306[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_307 (Activation)     (None, 25, 25, 64)   0           batch_normalization_307[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_301[0][0]             \n",
            "                                                                 activation_303[0][0]             \n",
            "                                                                 activation_306[0][0]             \n",
            "                                                                 activation_307[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_312 (Conv2D)             (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_309 (BatchN (None, 25, 25, 64)   192         conv2d_312[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_309 (Activation)     (None, 25, 25, 64)   0           batch_normalization_309[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_313 (Conv2D)             (None, 25, 25, 96)   55296       activation_309[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_310 (BatchN (None, 25, 25, 96)   288         conv2d_313[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_310 (Activation)     (None, 25, 25, 96)   0           batch_normalization_310[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_311 (Conv2D)             (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_314 (Conv2D)             (None, 12, 12, 96)   82944       activation_310[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_308 (BatchN (None, 12, 12, 384)  1152        conv2d_311[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_311 (BatchN (None, 12, 12, 96)   288         conv2d_314[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_308 (Activation)     (None, 12, 12, 384)  0           batch_normalization_308[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_311 (Activation)     (None, 12, 12, 96)   0           batch_normalization_311[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling2D) (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_308[0][0]             \n",
            "                                                                 activation_311[0][0]             \n",
            "                                                                 max_pooling2d_17[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_319 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_316 (BatchN (None, 12, 12, 128)  384         conv2d_319[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_316 (Activation)     (None, 12, 12, 128)  0           batch_normalization_316[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_320 (Conv2D)             (None, 12, 12, 128)  114688      activation_316[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_317 (BatchN (None, 12, 12, 128)  384         conv2d_320[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_317 (Activation)     (None, 12, 12, 128)  0           batch_normalization_317[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_316 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_321 (Conv2D)             (None, 12, 12, 128)  114688      activation_317[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_313 (BatchN (None, 12, 12, 128)  384         conv2d_316[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_318 (BatchN (None, 12, 12, 128)  384         conv2d_321[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_313 (Activation)     (None, 12, 12, 128)  0           batch_normalization_313[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_318 (Activation)     (None, 12, 12, 128)  0           batch_normalization_318[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_317 (Conv2D)             (None, 12, 12, 128)  114688      activation_313[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_322 (Conv2D)             (None, 12, 12, 128)  114688      activation_318[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_314 (BatchN (None, 12, 12, 128)  384         conv2d_317[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_319 (BatchN (None, 12, 12, 128)  384         conv2d_322[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_314 (Activation)     (None, 12, 12, 128)  0           batch_normalization_314[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_319 (Activation)     (None, 12, 12, 128)  0           batch_normalization_319[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_30 (AveragePo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_315 (Conv2D)             (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_318 (Conv2D)             (None, 12, 12, 192)  172032      activation_314[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_323 (Conv2D)             (None, 12, 12, 192)  172032      activation_319[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_324 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_30[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_312 (BatchN (None, 12, 12, 192)  576         conv2d_315[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_315 (BatchN (None, 12, 12, 192)  576         conv2d_318[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_320 (BatchN (None, 12, 12, 192)  576         conv2d_323[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_321 (BatchN (None, 12, 12, 192)  576         conv2d_324[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_312 (Activation)     (None, 12, 12, 192)  0           batch_normalization_312[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_315 (Activation)     (None, 12, 12, 192)  0           batch_normalization_315[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_320 (Activation)     (None, 12, 12, 192)  0           batch_normalization_320[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_321 (Activation)     (None, 12, 12, 192)  0           batch_normalization_321[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_312[0][0]             \n",
            "                                                                 activation_315[0][0]             \n",
            "                                                                 activation_320[0][0]             \n",
            "                                                                 activation_321[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_329 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_326 (BatchN (None, 12, 12, 160)  480         conv2d_329[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_326 (Activation)     (None, 12, 12, 160)  0           batch_normalization_326[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_330 (Conv2D)             (None, 12, 12, 160)  179200      activation_326[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_327 (BatchN (None, 12, 12, 160)  480         conv2d_330[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_327 (Activation)     (None, 12, 12, 160)  0           batch_normalization_327[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_326 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_331 (Conv2D)             (None, 12, 12, 160)  179200      activation_327[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_323 (BatchN (None, 12, 12, 160)  480         conv2d_326[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_328 (BatchN (None, 12, 12, 160)  480         conv2d_331[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_323 (Activation)     (None, 12, 12, 160)  0           batch_normalization_323[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_328 (Activation)     (None, 12, 12, 160)  0           batch_normalization_328[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_327 (Conv2D)             (None, 12, 12, 160)  179200      activation_323[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_332 (Conv2D)             (None, 12, 12, 160)  179200      activation_328[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_324 (BatchN (None, 12, 12, 160)  480         conv2d_327[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_329 (BatchN (None, 12, 12, 160)  480         conv2d_332[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_324 (Activation)     (None, 12, 12, 160)  0           batch_normalization_324[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_329 (Activation)     (None, 12, 12, 160)  0           batch_normalization_329[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_31 (AveragePo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_325 (Conv2D)             (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_328 (Conv2D)             (None, 12, 12, 192)  215040      activation_324[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_333 (Conv2D)             (None, 12, 12, 192)  215040      activation_329[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_334 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_31[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_322 (BatchN (None, 12, 12, 192)  576         conv2d_325[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_325 (BatchN (None, 12, 12, 192)  576         conv2d_328[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_330 (BatchN (None, 12, 12, 192)  576         conv2d_333[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_331 (BatchN (None, 12, 12, 192)  576         conv2d_334[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_322 (Activation)     (None, 12, 12, 192)  0           batch_normalization_322[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_325 (Activation)     (None, 12, 12, 192)  0           batch_normalization_325[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_330 (Activation)     (None, 12, 12, 192)  0           batch_normalization_330[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_331 (Activation)     (None, 12, 12, 192)  0           batch_normalization_331[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_322[0][0]             \n",
            "                                                                 activation_325[0][0]             \n",
            "                                                                 activation_330[0][0]             \n",
            "                                                                 activation_331[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_339 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_336 (BatchN (None, 12, 12, 160)  480         conv2d_339[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_336 (Activation)     (None, 12, 12, 160)  0           batch_normalization_336[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_340 (Conv2D)             (None, 12, 12, 160)  179200      activation_336[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_337 (BatchN (None, 12, 12, 160)  480         conv2d_340[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_337 (Activation)     (None, 12, 12, 160)  0           batch_normalization_337[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_336 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_341 (Conv2D)             (None, 12, 12, 160)  179200      activation_337[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_333 (BatchN (None, 12, 12, 160)  480         conv2d_336[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_338 (BatchN (None, 12, 12, 160)  480         conv2d_341[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_333 (Activation)     (None, 12, 12, 160)  0           batch_normalization_333[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_338 (Activation)     (None, 12, 12, 160)  0           batch_normalization_338[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_337 (Conv2D)             (None, 12, 12, 160)  179200      activation_333[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_342 (Conv2D)             (None, 12, 12, 160)  179200      activation_338[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_334 (BatchN (None, 12, 12, 160)  480         conv2d_337[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_339 (BatchN (None, 12, 12, 160)  480         conv2d_342[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_334 (Activation)     (None, 12, 12, 160)  0           batch_normalization_334[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_339 (Activation)     (None, 12, 12, 160)  0           batch_normalization_339[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_32 (AveragePo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_335 (Conv2D)             (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_338 (Conv2D)             (None, 12, 12, 192)  215040      activation_334[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_343 (Conv2D)             (None, 12, 12, 192)  215040      activation_339[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_344 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_32[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_332 (BatchN (None, 12, 12, 192)  576         conv2d_335[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_335 (BatchN (None, 12, 12, 192)  576         conv2d_338[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_340 (BatchN (None, 12, 12, 192)  576         conv2d_343[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_341 (BatchN (None, 12, 12, 192)  576         conv2d_344[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_332 (Activation)     (None, 12, 12, 192)  0           batch_normalization_332[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_335 (Activation)     (None, 12, 12, 192)  0           batch_normalization_335[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_340 (Activation)     (None, 12, 12, 192)  0           batch_normalization_340[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_341 (Activation)     (None, 12, 12, 192)  0           batch_normalization_341[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_332[0][0]             \n",
            "                                                                 activation_335[0][0]             \n",
            "                                                                 activation_340[0][0]             \n",
            "                                                                 activation_341[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_349 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_346 (BatchN (None, 12, 12, 192)  576         conv2d_349[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_346 (Activation)     (None, 12, 12, 192)  0           batch_normalization_346[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_350 (Conv2D)             (None, 12, 12, 192)  258048      activation_346[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_347 (BatchN (None, 12, 12, 192)  576         conv2d_350[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_347 (Activation)     (None, 12, 12, 192)  0           batch_normalization_347[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_346 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_351 (Conv2D)             (None, 12, 12, 192)  258048      activation_347[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_343 (BatchN (None, 12, 12, 192)  576         conv2d_346[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_348 (BatchN (None, 12, 12, 192)  576         conv2d_351[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_343 (Activation)     (None, 12, 12, 192)  0           batch_normalization_343[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_348 (Activation)     (None, 12, 12, 192)  0           batch_normalization_348[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_347 (Conv2D)             (None, 12, 12, 192)  258048      activation_343[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_352 (Conv2D)             (None, 12, 12, 192)  258048      activation_348[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_344 (BatchN (None, 12, 12, 192)  576         conv2d_347[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_349 (BatchN (None, 12, 12, 192)  576         conv2d_352[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_344 (Activation)     (None, 12, 12, 192)  0           batch_normalization_344[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_349 (Activation)     (None, 12, 12, 192)  0           batch_normalization_349[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_33 (AveragePo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_345 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_348 (Conv2D)             (None, 12, 12, 192)  258048      activation_344[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_353 (Conv2D)             (None, 12, 12, 192)  258048      activation_349[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_354 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_33[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_342 (BatchN (None, 12, 12, 192)  576         conv2d_345[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_345 (BatchN (None, 12, 12, 192)  576         conv2d_348[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_350 (BatchN (None, 12, 12, 192)  576         conv2d_353[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_351 (BatchN (None, 12, 12, 192)  576         conv2d_354[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_342 (Activation)     (None, 12, 12, 192)  0           batch_normalization_342[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_345 (Activation)     (None, 12, 12, 192)  0           batch_normalization_345[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_350 (Activation)     (None, 12, 12, 192)  0           batch_normalization_350[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_351 (Activation)     (None, 12, 12, 192)  0           batch_normalization_351[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_342[0][0]             \n",
            "                                                                 activation_345[0][0]             \n",
            "                                                                 activation_350[0][0]             \n",
            "                                                                 activation_351[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_357 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_354 (BatchN (None, 12, 12, 192)  576         conv2d_357[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_354 (Activation)     (None, 12, 12, 192)  0           batch_normalization_354[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_358 (Conv2D)             (None, 12, 12, 192)  258048      activation_354[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_355 (BatchN (None, 12, 12, 192)  576         conv2d_358[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_355 (Activation)     (None, 12, 12, 192)  0           batch_normalization_355[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_355 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_359 (Conv2D)             (None, 12, 12, 192)  258048      activation_355[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_352 (BatchN (None, 12, 12, 192)  576         conv2d_355[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_356 (BatchN (None, 12, 12, 192)  576         conv2d_359[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_352 (Activation)     (None, 12, 12, 192)  0           batch_normalization_352[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_356 (Activation)     (None, 12, 12, 192)  0           batch_normalization_356[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_356 (Conv2D)             (None, 5, 5, 320)    552960      activation_352[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_360 (Conv2D)             (None, 5, 5, 192)    331776      activation_356[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_353 (BatchN (None, 5, 5, 320)    960         conv2d_356[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_357 (BatchN (None, 5, 5, 192)    576         conv2d_360[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_353 (Activation)     (None, 5, 5, 320)    0           batch_normalization_353[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_357 (Activation)     (None, 5, 5, 192)    0           batch_normalization_357[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling2D) (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_353[0][0]             \n",
            "                                                                 activation_357[0][0]             \n",
            "                                                                 max_pooling2d_18[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_365 (Conv2D)             (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_362 (BatchN (None, 5, 5, 448)    1344        conv2d_365[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_362 (Activation)     (None, 5, 5, 448)    0           batch_normalization_362[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_362 (Conv2D)             (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_366 (Conv2D)             (None, 5, 5, 384)    1548288     activation_362[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_359 (BatchN (None, 5, 5, 384)    1152        conv2d_362[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_363 (BatchN (None, 5, 5, 384)    1152        conv2d_366[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_359 (Activation)     (None, 5, 5, 384)    0           batch_normalization_359[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_363 (Activation)     (None, 5, 5, 384)    0           batch_normalization_363[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_363 (Conv2D)             (None, 5, 5, 384)    442368      activation_359[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_364 (Conv2D)             (None, 5, 5, 384)    442368      activation_359[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_367 (Conv2D)             (None, 5, 5, 384)    442368      activation_363[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_368 (Conv2D)             (None, 5, 5, 384)    442368      activation_363[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_34 (AveragePo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_361 (Conv2D)             (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_360 (BatchN (None, 5, 5, 384)    1152        conv2d_363[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_361 (BatchN (None, 5, 5, 384)    1152        conv2d_364[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_364 (BatchN (None, 5, 5, 384)    1152        conv2d_367[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_365 (BatchN (None, 5, 5, 384)    1152        conv2d_368[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_369 (Conv2D)             (None, 5, 5, 192)    245760      average_pooling2d_34[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_358 (BatchN (None, 5, 5, 320)    960         conv2d_361[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_360 (Activation)     (None, 5, 5, 384)    0           batch_normalization_360[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_361 (Activation)     (None, 5, 5, 384)    0           batch_normalization_361[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_364 (Activation)     (None, 5, 5, 384)    0           batch_normalization_364[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_365 (Activation)     (None, 5, 5, 384)    0           batch_normalization_365[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_366 (BatchN (None, 5, 5, 192)    576         conv2d_369[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_358 (Activation)     (None, 5, 5, 320)    0           batch_normalization_358[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_360[0][0]             \n",
            "                                                                 activation_361[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 5, 5, 768)    0           activation_364[0][0]             \n",
            "                                                                 activation_365[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_366 (Activation)     (None, 5, 5, 192)    0           batch_normalization_366[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_358[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_6[0][0]              \n",
            "                                                                 activation_366[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_374 (Conv2D)             (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_371 (BatchN (None, 5, 5, 448)    1344        conv2d_374[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_371 (Activation)     (None, 5, 5, 448)    0           batch_normalization_371[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_371 (Conv2D)             (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_375 (Conv2D)             (None, 5, 5, 384)    1548288     activation_371[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_368 (BatchN (None, 5, 5, 384)    1152        conv2d_371[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_372 (BatchN (None, 5, 5, 384)    1152        conv2d_375[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_368 (Activation)     (None, 5, 5, 384)    0           batch_normalization_368[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_372 (Activation)     (None, 5, 5, 384)    0           batch_normalization_372[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_372 (Conv2D)             (None, 5, 5, 384)    442368      activation_368[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_373 (Conv2D)             (None, 5, 5, 384)    442368      activation_368[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_376 (Conv2D)             (None, 5, 5, 384)    442368      activation_372[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_377 (Conv2D)             (None, 5, 5, 384)    442368      activation_372[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_35 (AveragePo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_370 (Conv2D)             (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_369 (BatchN (None, 5, 5, 384)    1152        conv2d_372[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_370 (BatchN (None, 5, 5, 384)    1152        conv2d_373[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_373 (BatchN (None, 5, 5, 384)    1152        conv2d_376[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_374 (BatchN (None, 5, 5, 384)    1152        conv2d_377[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_378 (Conv2D)             (None, 5, 5, 192)    393216      average_pooling2d_35[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_367 (BatchN (None, 5, 5, 320)    960         conv2d_370[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_369 (Activation)     (None, 5, 5, 384)    0           batch_normalization_369[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_370 (Activation)     (None, 5, 5, 384)    0           batch_normalization_370[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_373 (Activation)     (None, 5, 5, 384)    0           batch_normalization_373[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_374 (Activation)     (None, 5, 5, 384)    0           batch_normalization_374[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_375 (BatchN (None, 5, 5, 192)    576         conv2d_378[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_367 (Activation)     (None, 5, 5, 320)    0           batch_normalization_367[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_369[0][0]             \n",
            "                                                                 activation_370[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 5, 5, 768)    0           activation_373[0][0]             \n",
            "                                                                 activation_374[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_375 (Activation)     (None, 5, 5, 192)    0           batch_normalization_375[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_367[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_7[0][0]              \n",
            "                                                                 activation_375[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_3 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 512)          1049088     global_average_pooling2d_3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 2)            1026        dense_8[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 22,852,898\n",
            "Trainable params: 22,818,466\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dC4KT0HjTqe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36b0e0f8-9637-4a4c-f6e8-8d3f5d59c044"
      },
      "source": [
        "# load training data, extract features and save to npy files\n",
        "file_num = 9\n",
        "for i in range(file_num):\n",
        "  # myData = DR_resized(True, i, 32, 0.1, (224, 224))\n",
        "  myData = DR_resized(True, i, 32, 0.1)\n",
        "  feature = my_model_pretrained.extract_feature(myData.train_images)\n",
        "  # feature = myModel.extract_feature(myData.train_images)\n",
        "  np.save(os.path.join(project_root, \"features\", parameter_version, \"Xtrain_feature%d.npy\" % i), feature)\n",
        "  print(\"Xtrain_feature%d.npy\" % i)\n",
        "  print(feature.shape)\n",
        "  myData.clear()\n",
        "  gc.collect()\n",
        "\n",
        "# load testing data, extract features and save to npy files\n",
        "file_num = 2\n",
        "for i in range(file_num):\n",
        "  # myData = DR_resized(False, i, 32, 0.1, (224, 224))\n",
        "  myData = DR_resized(False, i, 32, 0.1)\n",
        "  feature = my_model_pretrained.extract_feature(myData.test_images)\n",
        "  np.save(os.path.join(project_root, \"features\", parameter_version, \"Xtest_feature%d.npy\" % i), feature)\n",
        "  print(\"Xtest_feature%d.npy\" % i)\n",
        "  print(feature.shape)\n",
        "  myData.clear()\n",
        "  gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Xtrain_feature0.npy\n",
            "(124, 512)\n",
            "Xtrain_feature1.npy\n",
            "(124, 512)\n",
            "Xtrain_feature2.npy\n",
            "(124, 512)\n",
            "Xtrain_feature3.npy\n",
            "(124, 512)\n",
            "Xtrain_feature4.npy\n",
            "(124, 512)\n",
            "Xtrain_feature5.npy\n",
            "(124, 512)\n",
            "Xtrain_feature6.npy\n",
            "(124, 512)\n",
            "Xtrain_feature7.npy\n",
            "(124, 512)\n",
            "Xtrain_feature8.npy\n",
            "(124, 512)\n",
            "Xtest_feature0.npy\n",
            "Xtest_feature1.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZNI9AB1lpPM"
      },
      "source": [
        "# confusion matrix\n",
        "file_num = 2\n",
        "y_true_array = None\n",
        "y_pred_array = None\n",
        "\n",
        "for i in range(file_num):\n",
        "  myData = DR_resized(False, i, 32, 0.1, (224, 224))\n",
        "  # myData = DR_resized(False, i, 32, 0.1)\n",
        "  res = myModel.predict(myData.test_images)\n",
        "  if(i == 0):\n",
        "    y_true_array = np.squeeze(myData.test_labels, axis=1)\n",
        "    y_pred_array = res.argmax(axis=1)\n",
        "  else:\n",
        "    y_true_array = np.hstack((y_true_array, np.squeeze(myData.test_labels, axis=1)))\n",
        "    y_pred_array = np.hstack((y_pred_array, res.argmax(axis=1)))\n",
        "\n",
        "  myData.clear()\n",
        "  gc.collect()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eenuXBools9S",
        "outputId": "7356ef69-fa2d-4a5e-9711-66bf8df3de76"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "target_names = ['class 0', 'class 1']\n",
        "print(classification_report(y_true_array, y_pred_array, target_names=target_names))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.41      0.40      0.40       150\n",
            "     class 1       0.41      0.41      0.41       150\n",
            "\n",
            "    accuracy                           0.41       300\n",
            "   macro avg       0.41      0.41      0.41       300\n",
            "weighted avg       0.41      0.41      0.41       300\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}